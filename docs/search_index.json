[["index.html", "Theory Construction and Statistical Modeling A guide to structural equation modeling in R Course", " Theory Construction and Statistical Modeling A guide to structural equation modeling in R Caspar J. van Lissa¹ ¹Utrecht University, Methodology &amp; Statistics Course In this course you will learn how to translate a social scientific theory into a statistical model, how to analyze your data with these models, and how to interpret and report your results following APA standards. Course overview You do not need a book for this course. Most information is contained within this GitBook and the course readings. Optionally, if you want to expand your learning, you can follow the excellent lavaan tutorial. The analyses will be executed using the statistical programming environment R, and in particular using the structural equation modeling package lavaan. "],["staff.html", "0.1 Staff", " 0.1 Staff Coordinator: dr. Caspar J. van Lissa Lecturers dr. Caspar J. van Lissa Computer labs Danielle McCool Laura Hofstee "],["learning-goals.html", "0.2 Learning goals", " 0.2 Learning goals After completing the course, you will be able to do the following: Translate a verbal theory into a conceptual model, and translate a conceptual model into a statistical model Independently analyze data using the free, open-source statistical software R (a marketable job skill) Apply the latent variable model to a real-life problem, where observed variables do not directly measure, but are indicators of, an unobserved social scientific construct. Use the path model to describe how several variables are causally related to one another, including complex relationships such as mediation and moderation Explain to a fellow student that the technique structural equation modeling combines latent variable models with path models, and allows you to test an entire theory in one go Reflect critically on decisions in the analysis of structural equation models, both your own, and in published research "],["theory-construction-and-statistical-modeling.html", "0.3 Theory Construction and Statistical Modeling", " 0.3 Theory Construction and Statistical Modeling In order to test a theory, we must express the theory as a statistical model and then test this model on quantitative (numeric) data. This course uses existing tutorial datasets to practice the process of translating verbal theories into testable statistical models. Those who are interested in the methods of acquiring high quality data for your own theory, we refer to the course Conducting a Survey which is taught from November  January. In this course we will use datasets from different disciplines within the social sciences (educational sciences, psychology and sociology) to explain and illustrate theories and practices that are used in all social science disciplines to statistically model social science theories. Most information about the course is available in this GitBook. Communication about the course occurs through https://uu.blackboard.nl (Login with your student ID and password). "],["course-overview.html", "0.4 Course overview", " 0.4 Course overview The course consists of three parts, each of which is assessed with an assignment: Factor analysis, in which you learn different ways of capturing unobserved constructs. Path analysis, in which you learn how to model regression and ANOVA as a structural equation model with observed variables. Structural equation modeling, in which you put together the first two topics. "],["adaptations-related-to-the-coronavirus-measures.html", "0.5 Adaptations related to the coronavirus measures", " 0.5 Adaptations related to the coronavirus measures The corona crisis is challenging all of us to rethink how we teach and learn. But aside from the challenges, it also offers opportunities. In adapting this course, we kept two goals in mind: increasing the alignment between the way of teaching and the learning goals, and ensuring high-quality interaction among students and between the students and teachers while still using online communication. Based on these goals, we made the following changes: During the course, you will be working in learning teams to promote interaction among students and peer support The two in-person exams (4 hours each) are replaced with take-home assignments: Two group assignments, and one individual assignment. 0.5.1 Why not in-person meetings? When the courses were scheduled, it was not yet clear what direction the university wanted to take. Every teacher could make a choice: Online-only, or hybrid education. At that time, I chose the online format, because: Last year, the online version of this course was very successful This elective course attracts diverse students with complex schedules; many expressed a preference for the flexibility of an online course Due to the 75 student maximum on lecture halls, it is very difficult to schedule courses. Doing this course in person would mean that we have meetings on varying days at different times. That would likely create scheduling conflicts for many of you. 0.5.2 Why learning in groups? Contact with fellow students is a key aspect of the university experience. During this time of social distancing, it is important to find new ways to stay in touch with fellow students. There are also aspects of learning in groups that can really improve your knowledge, like peer feedback. The groups are made randomly when the course starts, but you can switch with a consenting member of another group in the first week. 0.5.3 Why use take home assignments for assessment? Assignments are a suitable form of assessment for a skills-based course like TCSM. It also takes a lot of the pressure off because you can work at your own pace. This course used to have two 4-hour exams; not exactly corona-proof. Using take-home assignments entrusts you with the responsibility to make this assignment in good faith, without instrumental assistance or plagiarism, so I kindly ask you to make good on this trust, and hand in original work to show what youve learned. "],["grading.html", "0.6 Grading", " 0.6 Grading Your grade for the course is based on your portfolio composed of the three take-home assignments. The first assignment (deadline: 05-10-2021) assesses your understanding of the latent variable model. This is a group assignment, made with your learning team. The exam counts towards 25% of your grade. The second graded assignment (deadline: 26-10-2021) assesses your understanding of path models. This is a group assignment, made with your learning team. The exam counts towards 25% of your grade. The final assignment (deadline: 09-11-2021) assesses your ability to independently analyse data, combining the skills you learned during this course. This is an individual assignment, which counts towards 50% of your grade. "],["assignments.html", "0.7 Assignments", " 0.7 Assignments A description of the assignments follows below. For each assignment, every element labeled with a lower case letter is graded fail (0 points), pass (1 point), or excellent (1.5 points). Grades are summed for each assignment, and rescaled from 1-10. The final grade is a weighted average across assignments of the rescaled grades (weights in %). Note that the assignments are not intended to be full-blown papers! You only get 200 words to justify your theoretical model, and 300 words to discuss the results. The focus should be on your analysis; how it relates to theory (introduction), and what you have learned from it and how you might improve it (discussion). Apply the latent variable model to a real-life problem, where observed variables do not directly measure, but are indicators of, an unobserved social scientific construct (G, 25%) Find a suitable dataset, for example: Data you have collected for a previous course Open data, provided with a published paper The Coping with COVID-19 dataset (if you cant find anything) Describe the dataset, and introduce the theoretical latent variable model (200 words) Estimate the latent variable model (PCA, EFA, CFA) and conduct reliability analysis, provide relevant output in a suitable format Explain your rationale for important modeling decisions (300 words) Motivate your choice for the type of latent variable model Discuss assumptions Discuss other important decisions, as discussed in the course reading materials Report and interpret the results in APA style Discuss the results in max 300 words Devote attention to strengths and limitations Use the path model to describe how several variables are causally related to one another (G, 25%) Find a suitable dataset, for example: Data you have collected and analyzed for a previous course Open data, provided with a published paper The Coping with COVID-19 dataset (if you cant find anything) Describe the dataset, and introduce the theoretical path model (200 words) Conduct a SEM path model to answer the theoretical questions This can be a re-analysis of a question that had been tested using regression, ANOVA, or t-test analysis in the original paper Explain your rationale for important modeling decisions (300 words) Fit between theory and model Model assumptions Difference/similarity between the path model and the (original) regression, ANOVA, or t-test analysis Why you use standardized or unstandardized coefficients Report and interpret the results in APA style Include measures of explained variance for the dependent variables. Discuss the results (max 300 words) Devote attention to strengths and limitations Independently analyze data using the free, open-source statistical software R (I, 50%) Find a suitable dataset, for example: Data you have collected for a previous course Open data, provided with a published paper The Coping with COVID-19 dataset (if you cant find anything) Describe the dataset, and introduce a theory involving at least 3 variables that can be tested using these data (300 words) Translate the theory to lavaan syntax and estimate the model (could be multiple models if you think its necessary) Use at least: One latent variable Moderation (continuous or multi-group) Mediation Explain your rationale for important modeling decisions (300 words) Fit between theory and model Model assumptions Difference/similarity between the path model and the (original) regression, ANOVA, or t-test analysis Why you use standardized or unstandardized coefficients Report and interpret your results in APA style Discuss your results in maximum 500 words "],["rules-for-the-take-home-assignments.html", "0.8 Rules for the take-home assignments", " 0.8 Rules for the take-home assignments  For all three graded assignments, you are allowed to use all course materials, including the GitBook, and search engines  The first two assignments are made in groups. o For these assignments, it is not allowed to work together with other groups.  The final assignment is made individually. o For this assignment, it is not allowed to recruit outside help  In all cases, you are obligated to hand in original work conducted by you or your group. Failure to do so constitutes fraud.  You also have a moral obligation to obey the rules. For this course, I have chosen a form of examination that allows you to showcase what you have learned flexibly. This spares you the stress of long exams (the two exams for this course used to be 4 hours each) and cramming all course material. It also assumes that you make the assignment in good faith, so I simply ask that you hold up your end of the bargain, and hand in your original work to show what youve learned.  The final assignment also helps you assess your ability to independently analyse data, which is important to know for your future courses and/or career. "],["statement-on-fair-grading-during-corona.html", "0.9 Statement on fair grading during corona", " 0.9 Statement on fair grading during corona We, the lecturers, are committed to offering distance learning and assessment to ensure that you can continue your studies. The final assignment is therefore a check at the end of the course, for both you and your lecturers, of whether you are ready for subsequent courses in your study programme. You will be completing this assignment remotely, instead of making a test at the university under the supervision of lecturers. For most students this will make no difference, but of course remote assessment is more susceptible to fraud. By handing in your final assignment, you therefore explicitly confirm that you have made this assignment by yourself and are submitting work you have written yourself, that you will be using your own login details, and that you have not had instrumental help in making the assignment. All assignments are submitted via SafeAssign in Blackboard and are checked for plagiarism. If fraud or plagiarism is detected or suspected, the Board of Examiners will be informed in the usual manner, and in the event of fraud, the sanctions referred to in Article 5.14 of the Education and Examination Regulations (EER) will apply (download from https://students.uu.nl/files/fsw-ba-oer-engelstalig-2019-2020pdf). Note that the sanctions may apply to the person committing fraud, to the person(s) making fraud possible, and to the test as a whole. Lecturers also have the option of administering additional oral tests if they have reasons to do so. Thank you for your cooperation, we will only be able to get through this period together! "],["attendance.html", "0.10 Attendance", " 0.10 Attendance Attendance is not mandatory, but we highly recommend everyone to attend all lectures and the Thursday practicals. In our experience, students who actively participate tend to pass the course, whereas those who do not tend to drop out or fail. The lectures and practicals build on each other, so in the unfortunate event that you have to miss either one, please make sure you have caught up with the materials before the next session. The practicals on Monday are for troubleshooting  to be sure that everyone can keeps up with the course  and they are no substitute for the Thursday practicals. "],["literature.html", "0.11 Literature", " 0.11 Literature All literature is available on the Internet, as long as you are within the UU-domain. See the course site on Blackboard for direct links to all following articles. For some articles, we are not allowed to post direct URLs. Searching through either Google Scholar or the University Library will work wonders. "],["reading-questions.html", "0.12 Reading questions", " 0.12 Reading questions Along with every article, we will provide reading questions. You will not be graded on the reading questions, but it is important to prepare the reading questions before every lecture. The purpose of the reading questions is as follows: to provide relevant background knowledge for the lecture; to explain the key terms and concepts; to be aware of important publications that shaped the field; to help you to prepare for the exam; it is not necessary to learn the answers to the reading questions by heart, but the reading questions will help you extract the relevant insights from the literature. We will post standard answers to the reading questions online before the exam, but their most valuable role is to guide your understanding during the course, not while preparing the exam. "],["preparations.html", "0.13 Preparations", " 0.13 Preparations Before every meeting you need to do the assigned homework (see detailed program). We assume you have basic knowledge about multivariate statistics before entering this course. You do not need any prior experience working with R. If you feel unsure about your knowledge about statistics, and in particular ANOVA and multiple regression analysis, please e-mail the course coordinator. If you wish to refresh your knowledge, we recommend the chapters on ANOVA, multiple regression and Exploratory Factor Analysis from Fields Discovering Statistics using R. London; Sage. Read the chapters on multiple regression and exploratory factor analysis if you want to prepare for the first meeting. If you do not have this book, many other statistics textbooks usually discuss these topics equally well. You do not need to buy any book for this course. "],["preparing-for-the-course.html", "Chapter 1 Preparing for the course", " Chapter 1 Preparing for the course This Chapter helps you prepare for the course. It shows how to install R and RStudio on your computer. Well also provide some general information on R, and how you can get help if you get error messages. If youre already using R, all of this might be nothing new for you. You may skip this chapter then. If you have never used R before, this Chapter is essential, as it gives you some input on how R works, and how we can use it for our data analyses. "],["installing-software.html", "1.1 Installing software", " 1.1 Installing software Before we start the course, we have to install three things: R, a free program for statistical programming RStudio, a user interface which makes it easier to work with R; overlook our data, packages and output. Several packages, which are add-ons for R with functions to do specific analyses. They also include the documentation (help files) that describes how to use them, and sample data. 1.1.1 1. Installing R The latest R Version is available here Based on your operating system (Linux, Mac, Windows), click Download. If you use Windows, click Download R for Windows: Find base under subdirectories -&gt; Click install R for the first time -&gt; Click Download R 3.6.3 (or another version) for Windows If you use Mac, click Download R for (Mac) OS X: Find the header Latest release -&gt; Click R-3.6.3.pkg (or another version) If you use Linux, click Download R for Linux: Choose your Linux distribution (debian/, redhat/, suse/, ubuntu/) -&gt; Open the terminal -&gt; Run the installation command 1.1.2 2. Installing RStudio Download RStudio on the RStudio Website (Link). Its free! 1.1.3 3. Installing packages As a prerequisite for this guide, you need to have a few essential R packages installed. Open RStudio Inside RStudio, find the window named Console on the bottom left corner of your screen (it might fill the entire left side of the screen). We will now install a few packages using R Code. Heres an overview of the packages, and why we need them: Package Description lavaan A sophisticated and user-friendly package for structural equation modeling ggplot2 A flexible and user-friendly package for making graphs tidySEM Plotting and tabulating the output of SEM-models semTools Comparing models, establishing measurement invariance across groups psych Descriptive statistics foreign Loading data from SPSS .sav files readxl Loading data from Excel .xslx files 4. To install these packages, we use the install.packages() function in R. One package after another, our code should look like this: install.packages(&quot;tidySEM&quot;, dependencies = TRUE) Dont forget to put the package names in \"\". Otherwise, you will get an error message. 1.1.4 Get started 1.1.5 Starting a new project in Rstudio To keep all your work organized, you should use a project. In Rstudio, click on the New project button: In the pop-up dialog, click New directory, and again New project. type the desired directory name in the dialog (give it a meaningful name, e.g. TCSM_course), and use Browse if you need to change the directory where you store your projects. Now, in your project, click File &gt; New file &gt; R script. This script file works just like notepad, or the syntax editor in SPSS: You type plain text, but you can run it any time you want. Conduct all of the exercises in this script file. 1.1.6 Code conventions Throughout the guide, a consistent set of conventions is used to refer to code: Functions are in a code font and followed by parentheses, like sum() or mean(). Other R objects (like data or function arguments) are in a code font, without parentheses, like seTE or method.tau. Sometimes, well use the package name followed by two colons, like lavaan::sem(). This is valid R code and will run. The lavaan:: part indicates that the function sem() comes from the package lavaan. 1.1.7 Getting Help As you start to apply the techniques described in this guide to your data you will soon find questions that the guide does not answer. This section describes a few tips on how to get help. Every function in R has documentation (a help file). To see it, select the name of the function and press F1, or run the command ? followed by the name of the function, e.g.: ?aov. I have been using R for 10 years, and I still press F1 all the time to see how a function works. Andy Field, the book used for our undergraduate statistics courses (Field, Miles, and Field 2012), is also available for R. Many basic analyses are explained for R in this book. If you get stuck, start with Google. Typically, adding R to a search is enough to restrict it to relevant results, e.g.: exploratory factor analysis R. Google is particularly useful for error messages. If you get an error message and you have no idea what it means, try googling it. Chances are that someone else has been confused by it in the past, and there will be help somewhere on the web. (If the error message isnt in English, run Sys.setenv(LANGUAGE = \"en\") and re-run the code; youre more likely to find help for English error messages.) If Google doesnt help, try stackoverflow. Start by spending a little time searching for an existing answer; including [R] restricts your search to questions and answers that use R. Lastly, if you stumble upon an error (or typos!) in this guides text or R syntax, feel free to contact Caspar van Lissa at c.j.vanlissa@uu.nl. References "],["getting-the-course-data.html", "1.2 Getting the course data", " 1.2 Getting the course data All of the course data files are available on a GitHub repository. You can download them all at once by going to https://github.com/cjvanlissa/TCSM_student, clicking the green button labeled Code, and downloading a ZIP archive of the repository. After unzipping the archive, you can open the RStudio project TCSM_student.Rproj, and the script run_me.R. This script contains a few lines of code to help you install the required R-packages for the course. "],["r-tutorial-for-beginners-optional.html", "1.3 R tutorial for beginners (optional)", " 1.3 R tutorial for beginners (optional) Welcome to the world of R! This tutorial is based on the tutorial R: How to get started by Ihnwhi Heo, Duco Veen, and Rens van de Schoot, and adapted for TCSM. 1.3.1 Who R you? R is Free programming software for statistical computation and graphics Open source: everyone (even you!) can improve, develop, and contribute to R The official manual by the R Core Team: An introduction to R R itself looks a bit old-fashioned and tedious: 1.3.2 RStudio Thankfully, we have a great user interface for R, called RStudio! RStudio helps users to use and learn R easier If you are using RStudio, this means you are using R. From now on, all tutorials will go with RStudio. 1.3.2.1 No pane, no gain! When you open RStudio, the screen may look like this. You may notice that the screen is divided into A panes (a pane is a division of a window): Before we explain these three panes - I want you to add the fourth one, which you will see if you open an R script. An R script is like a new document in Microsoft Word. When you open an R script, the fourth pane appears. 1.3.2.2 Create a new R script Click the icon with a plus sign on the paper. Click the icon highlighted by the red square: When you click the icon, a new script appears in a fourth pane on the upper left side of the screen The four panes really help become organized. In RStudio, you can do everything all together on one screen. Thus, four panes make the work efficient (indeed, no pain!). 1.3.2.3 What do the four panes do? Out of four panes, the two on the left side are the panes you will use a lot. Source pane: located at the top left side of the screen. It is also called the editor, because this is where we edit scripts. We will usually type our code in the source pane. Console pane: located at the bottom left side of the screen. This panel is for direct communication with R. We can type commands here that are immediately evaluated (whereas a script is only evaluated when we run it). Furthermore, all output of our commands is printed in this console pane. The panels on the right side of the screen contain various tabs. Among those tabs, it is worth looking at the Environment tab at the upper pane and the Plots tab at the lower pane. The Environment tab contains all the objects currently loaded in your R session. In SPSS, you can have only one data file open. In R, you can have as many data objects as you like. They will be listed here. You can always check what objects are loaded under the environment tab. The environment is also called the workspace. The Plots tab shows various graphs and figures we draw. If you click Zoom with the magnifying glass, you can see plots in a bigger size. 1.3.3 Loading data Statistical analysis cannot happen without data. In R, you can load data in various ways. Lets see the easiest way. To download the dataset (LifeSat) for this tutorial, see the Chapter Getting the course data. 1.3.3.1 Mouse clicks Click File -&gt; Import Dataset -&gt; Choose the type of dataset. In this tutorial, we will use the SPSS dataset. Thus, click From SPSS. Suddenly, you may encounter an Install Required Packages pop-up with a message that asks you whether you want to install the haven package now. A package is an enhancement for R; in this case, an enhancement to allow it to read SPSS files. Click Yes. Then, the Import Statistical Data pop-up appears -&gt; See File/URL -&gt; Click Browse at the right end -&gt; Open your file You will see your data in the Data Preview. If you look at the Import Options, you can set the name of your data file and the format of it. All of your mouse-clicking is being translated to the R-code required to load your file. In the Code Preview, the steps required for loading the data are expressed in terms of code. Now, its time to load your data to R. How? Just click Import at the lower right side of the pop-up. In our example, the name of the dataset is LifeSat. 1.3.3.2 Loading data with R code Lets try to load the data with R code. In this course, we use the read.spss function from the library(foreign). It works best with all exercises. Write the following code in an R-script: library(foreign) LifeSat &lt;- read.spss(&quot;LifeSat.sav&quot;, to.data.frame = TRUE, use.value.labels = FALSE) Select these lines with the mouse. Press the Ctrl and Enter buttons together. The lines of code are now evaluated by R, and R is telling you the result of its actions in the console pane. There are many different ways to load data into R. During this course, we will see a few of them. 1.3.4 Explore your data As you saw, you can type some R codes in the source pane and run the codes by pressing Ctrl and Enter together to make R work. If you look at the R codes we used in loading the data, you see the instructions read_sav() and View(). These are called functions. A functions is an instruction for R to perform a task. When you use functions, you should type certain comments or inputs in the parentheses, which make the functions work. Those comments or inputs are called arguments. Lets learn three new functions with their arguments. They are used in understanding the data. 1.3.4.1 head() The data consist of many rows. If you would like to inspect the first several rows (to see how the data look), the head() function achieves your purpose. For the head() function, you will use only one argument: The name of the dataset. # Inspect the first several rows head(LifeSat) Wait, what is the hash tag (#) doing there? Dont be surprised. The hash tag creates a comment; a bit of text that will not be evaluated by R. This is useful because we can write notes to help us remember what we are doing when there are many lines of code. Writing comments also helps when you have someone else review your code. Lets run the code by pressing Ctrl and Enter together. R shows you the first six rows of the dataset in the console pane. You may be curious about some NAs in the output. NA refers to Not Available. Those are missing values. 1.3.4.2 Extracting one variable It is possible to extract a variable from the data using the dollar sign, $. In R, the dollar sign means: Take this object (a variable) out of another object (the data). In the example below, we ask R to take the variable LifSat out of the data.frame LifeSat: LifeSat$LifSat ## [1] 13 18 19 24 24 24 30 33 33 33 33 33 35 35 37 37 41 41 41 ## [20] 43 43 43 44 44 44 45 47 48 48 48 50 51 51 52 53 53 53 53 ## [39] 54 55 55 56 56 56 57 58 58 58 58 58 58 59 59 60 61 61 63 ## [58] 63 63 65 66 67 67 67 67 68 68 68 69 69 69 69 69 70 70 70 ## [77] 71 72 74 74 76 77 77 78 78 79 79 79 81 81 82 83 85 86 87 ## [96] 91 99 100 We see all 98 unique values. 1.3.4.3 Extracting rows and columns It is possible to extract rows or columns from the data using data[row_numbers, col_numbers]. For example, the first four rows of the first two columns: LifeSat[1:4, 1:2] By leaving either rows or columns empty, we get all rows or columns: LifeSat[ , 1:2] LifeSat[1:2, ] We can refer to columns by name, too: LifeSat[1:2, c(&quot;age&quot;, &quot;educ&quot;)] 1.3.4.4 str() It is of interest to know what types of variables are in the dataset. For example, if you want to run an analysis of variance (ANOVA), the independent variable should be categorical, and we should check if it is the case. For this purpose, you can use the str() function; where str is short for structure. In running this function, you need one argument, which is again the name of the dataset. # Structure of the dataset str(LifeSat) ## &#39;data.frame&#39;: 98 obs. of 8 variables: ## $ LifSat : num 13 18 19 24 24 24 30 33 33 33 ... ## $ age : num 75 75 72 72 70 73 72 72 68 73 ... ## $ educ : num 6 5 5 6 5 6 6 5 7 6 ... ## $ gender : num 2 2 2 2 1 2 1 2 1 1 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:2] &quot;2&quot; &quot;1&quot; ## .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;male&quot; &quot;female&quot; ## $ female : num 0 0 0 0 1 0 1 0 1 1 ... ## $ ChildSup: num 4 6 6 6 6 8 8 7 4 8 ... ## $ SpouSup : num 2 5 5 4 5 6 4 6 2 8 ... ## $ SES : num 3 1 1 1 1 1 1 2 2 2 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:3] &quot;3&quot; &quot;2&quot; &quot;1&quot; ## .. ..- attr(*, &quot;names&quot;)= chr [1:3] &quot;high SES&quot; &quot;middle SES&quot; &quot;low SES&quot; ## - attr(*, &quot;variable.labels&quot;)= Named chr [1:8] &quot;&quot; &quot;&quot; &quot;Years of education&quot; &quot;&quot; ... ## ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;LifSat&quot; &quot;age&quot; &quot;educ&quot; &quot;gender&quot; ... ## - attr(*, &quot;codepage&quot;)= int 1252 According to the output in the console pane, the dataset consists of 98 observations and 8 variables. variables. This means that our dataset has 98 rows and 8 columns. It is written that respnr: num 1 2 3 4 5 6 7 8 9 10  It means that the respnr variable is a number (abbreviated as num), and 1 is the value in the first row, 2 is the value in the second row, 3 is the value in the third row, and so on. 1.3.4.5 summary() How can we know about the mean, median, minimum, and maximum of the variables of interest? You can get the descriptive statistics of the variables with the summary() function. Again, you only need one argument, which is the name of the dataset. summary(LifeSat) Lets look at the output in the console pane. The descriptive statistics per variable is given. For example, for the variable LifSat, the minimum value is 1.455, the median is 3.636, and the mean is 3.628. This summary is a bit messy; you can get a nicer summary using the describe() function from the psych package. We will learn more about this in the course. "],["plotting-the-data-optional.html", "1.4 Plotting the data (optional)", " 1.4 Plotting the data (optional) It is always a good idea to look into your data visually. For example, you would like to know the relationship between two specific variables in your data, the distribution of values, and more. We will introduce three basic functions for plotting data. After you run these functions, the output appears in the Plots tab at the lower right pane. For plots, we use the ggplot2 package. If the package will not load when you run the code below, you may have skipped some essential steps in 1.1.3. library(ggplot2) 1.4.1 A histogram Are you curious about how the values of a continuous variable are distributed? Drawing a histogram is one way of examining the distribution. # Set up the data for the plot and select the variable to plot using aes: ggplot(data = LifeSat, aes(x = LifSat)) + geom_histogram() # Add a histgram 1.4.2 A boxplot A boxplot shows you how the data are dispersed from the median and whether the outliers exist. Lets draw the boxplot of the variable, LifSat. Can you guess how to do this? # Same set up as in the previous example: ggplot(data = LifeSat, aes(x = LifSat)) + geom_boxplot() # Add a boxplot 1.4.3 Scatterplot What if we are interested in visually investigating the relationship between two variables, LifSat and age, in the data? One possible solution is to draw a scatterplot. In addition to the x variable from the previous examples, we can also specify a y variable: # Set up the data for the plot and select the variable to plot using aes: ggplot(data = LifeSat, aes(x = LifSat, y = age)) + geom_point() # Add scatter This code gives you the scatterplot of the two variables, LifSat and age. The variable, LifSat, is at the x-axis and the variable, age, is at the y-axis. 1.4.3.1 Analyze your data One of the strengths of R is its flexibility in running statistical analyses and producing graphical outputs. In the first week of the course, we will perform some standard analyses in R that you are already familiar with from previous courses. "],["getting-your-data-into-r.html", "Chapter 2 Getting your data into R", " Chapter 2 Getting your data into R This optional chapter will tell you about how you can import data in RStudio. We will also show you a few commands to manipulate data directly in R. "],["using-r-projects.html", "2.1 Using R projects", " 2.1 Using R projects One advantage of using an R project is that the project directory is automatically set as the working directory. Just copy your data file to the folder that contains the .Rproj file, and you will be able to load files by name. "],["importing-excel-files.html", "2.2 Importing Excel Files", " 2.2 Importing Excel Files One way to get Excel files directly into R is by using the readxl package. Install the package, and try using the read_excel() function to load the data, and assign it to an object called df: # Run this only once, to download and install the package: install.packages(&quot;readxl&quot;) # Load the package: library(readxl) # Read an Excel file into &#39;df&#39;: df &lt;- read_excel(&quot;your_file.xlsx&quot;, sheet = 1) 2.2.1 Inspect the data R does not work with a single spreadsheet (SPSS or Excel). Instead, it can keep many objects in memory. The object df is a data.frame; an object that behaves similar to a spreadsheet. To see a description of the object, look at the Environment tab in the top right of Rstudio, and click the arrow next to df. As you can see, the on the top-right pane Environment, your file is now listed as a data set in your RStudio environment. You can make a quick copy of this data set by assigning the df object to a new object. This way, you can edit one, and leave the other unchanged. Assign the object df to a new object called df_backup: df_backup &lt;- df You can also have a look at the contents of df by clicking the object in the Environment panel, or running the command head(df). "],["importing-spss-files.html", "2.3 Importing SPSS Files", " 2.3 Importing SPSS Files SPSS files can be loaded using the foreign package. All SPSS files for this course are available for download here. # Install the package, run this only once install.packages(&quot;foreign&quot;) # Load the `foreign` library library(foreign) # Read the SPSS data df &lt;- read.spss(&quot;sesam2.sav&quot;, to.data.frame = TRUE) "],["data-manipulation-optional.html", "2.4 Data manipulation (optional)", " 2.4 Data manipulation (optional) Now that we have the Meta-Analysis data in RStudio, lets do a few manipulations with the data. These functions might come in handy when were conducting analyses later on. Going back to the output of the str() function, we see that this also gives us details on the type of column data we have stored in our data. There a different abbreviations signifying different types of data. Abbreviation Type Description num Numerical This is all data stored as numbers (e.g. 1.02) chr Character This is all data stored as words log Logical These are variables which are binary, meaning that they signify that a condition is either TRUE or FALSE factor Factor Factors are stored as numbers, with each number signifying a different level of a variable. A possible factor of a variable might be 1 = low, 2 = medium, 3 = high 2.4.1 Converting to factors Lets look at the variable df$VIEWCAT. This is a categorical variable, coded as a numerical one. We can have a look at this variable by typing the name of our dataset, then adding the selector $ and then adding the variable we want to have a look at. This variable is currently a numeric vector. We want it to be a factor: Thats a categorical variable. To convert this to a factor variable now, we use the factor() function. df$VIEWCAT &lt;- factor(df$VIEWCAT) We now see that the variable has been converted to a factor with the levels 1, 2, 3, and 4. We can assign different value labels as follows: df$VIEWCAT &lt;- factor(df$VIEWCAT, labels = c(&quot;Rarely&quot;, &quot;Sometimes&quot;, &quot;Regularly&quot;, &quot;Often&quot;)) 2.4.2 Selecting specific cases It may often come in handy to select certain cases for further analyses, or to exclude some studies in further analyses (e.g., if they are outliers). To do this, we can use the [] operator to index our data. Lets say we want to get only the first 5 cases. We can select them like so: df[1:5, ] Or lets say we only want the children younger than 36 months in the dataset. In this case, we can use boolean indexing: We create a TRUE / FALSE statement, and select the cases that are TRUE: df[df$AGE &lt; 36, ] Note that this approach can be used for any other type of data and variable. We can also use it to e.g., only select studies where VIEWCAT was equal to Often typical: df[df$VIEWCAT == &quot;Often&quot;, ] 2.4.3 Changing cell values Sometimes, even when preparing your data in EXCEL, you might want to change values in RStudio once you have imported your data. To do this, we have to select a cell in our data frame in RStudio. This can be done by adding [x,y] to our dataset name, where x signifies the number of the row we want to select, and y signifies the number of the column. To see how this works, lets select a variable using this command first: df[8,1] ## [1] 8 We now see the 8th study in our dataframe, and the value of this study for Column 1 (participant ID) is displayed. Lets say we had a typo in this name and want to have it changed. In this case, we have to give this exact cell a new value. df[8,1] &lt;- 1001 Lets check if the value has changed. df[8,1] ## [1] 1001 You can also use this function to change any other type of data, including numericals and logicals. Only for characters, you have to put the values you want to insert in \"\". "],["week-1-overview.html", "Chapter 3 Week 1 - Overview", " Chapter 3 Week 1 - Overview Lecture Download slides The first lecture will be used to introduce the concept of fitting models to data and explain some important concepts and notation that will be used during this course. Homework for the lecture Introduction on Tuesday: Work your way through the first two chapters of the GitBook online: https://cjvanlissa.github.io/TCSM/index.html. This will help you install the software required for the course, and get the data into R. You can skip the optional sections if you are already familiar with R. Read the article by Smaldino (skip the red sections; the yellow section is optional). Answer the reading questions (on Blackboard). Plan a call with your learning team to discuss the second question. Reference: Smaldino, P. E. (2017). Models are stupid, and we need more of them. Computational social psychology, 311-331. Lecture Introduction: We start with a brief introduction to the course, its goals and rules and the idea of statistical modelling. In this lecture we will introduce the type of models that will come across in this course. We will shortly discuss the concepts of model simplicity/complexity, model fit, the graphical display and the interpretation of different model parameters. Homework for the practical Introduction on Thursday: Perform the take-home exercise Regression (Chapter 3, Week 1 Home) before coming to the practical. Practical Introduction: During the practical you will work on the class exercise about regression and SEM models. "],["week-1-reading-questions.html", "Chapter 4 Week 1 - Reading questions", " Chapter 4 Week 1 - Reading questions Reference Smaldino, P. E. (2017). Models are stupid, and we need more of them. Computational social psychology, 311-331. SKIP PAGES 322 - 327 Questions What are the differences between a verbal model and a formal model? As explained in the paragraph A Brief Note on Statistical Models, formal models are not the same as statistical models. Still, we can learn a lot from Smaldinos approach. Write down three insights from this paper that you would like to apply to your statistical modelling during this course, and discuss with your learning group. "],["week-1-home.html", "Chapter 5 Week 1 - Home", " Chapter 5 Week 1 - Home Open the data file LifeSat.sav. library(foreign) data &lt;- read.spss(&quot;LifeSat.sav&quot;, to.data.frame = TRUE) 5.0.1 Question 1.a Make a table with descriptive statistics for the variables: LifSat, educ, ChildSup, SpouSup, and age. What is the average age in the sample? And the range (youngest and oldest child)? Hint: Use library(tidySEM); descriptives(); [] Click for explanation The package tidySEM contains a function to describe data. Install and load the package, then use the descriptives() function. Alternatively, you can also use the describe() function in the psych package. library(tidySEM) descriptives(data[, c(&quot;LifSat&quot;, &quot;educ&quot;, &quot;ChildSup&quot;, &quot;SpouSup&quot;, &quot;age&quot;)]) &lt;&gt; 5.0.2 Question 1.b Perform a simple regression with LifSat as the dependent variable and educ as the independent variable. Hint: The function lm() (short for linear model) conducts linear regression. The functions summary() provides relevant summary statistics for the model. It can be helpful to store the results of your analysis in an object, too. Click for explanation results &lt;- lm(LifSat ~ educ, data) summary(results) ## ## Call: ## lm(formula = LifSat ~ educ, data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -43.781 -11.866 2.018 12.418 43.018 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 35.184 7.874 4.469 2.15e-05 *** ## educ 3.466 1.173 2.956 0.00392 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 17.64 on 96 degrees of freedom ## Multiple R-squared: 0.08344, Adjusted R-squared: 0.0739 ## F-statistic: 8.74 on 1 and 96 DF, p-value: 0.003918 &lt;&gt; 5.0.3 Question 1.c. Do the same with age as the independent variable. Click for explanation results &lt;- lm(LifSat ~ age, data) summary(results) ## ## Call: ## lm(formula = LifSat ~ age, data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -35.321 -14.184 3.192 13.593 40.626 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 200.2302 52.1385 3.840 0.00022 *** ## age -2.0265 0.7417 -2.732 0.00749 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 17.75 on 96 degrees of freedom ## Multiple R-squared: 0.07215, Adjusted R-squared: 0.06249 ## F-statistic: 7.465 on 1 and 96 DF, p-value: 0.007487 &lt;&gt; 5.0.4 Question 1.d. Again with ChildSup as the independent variable. Click for explanation results &lt;- lm(LifSat ~ ChildSup, data) summary(results) ## ## Call: ## lm(formula = LifSat ~ ChildSup, data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -37.32 -12.14 0.66 12.41 44.68 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 37.559 8.342 4.502 1.89e-05 *** ## ChildSup 2.960 1.188 2.492 0.0144 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 17.86 on 96 degrees of freedom ## Multiple R-squared: 0.06076, Adjusted R-squared: 0.05098 ## F-statistic: 6.211 on 1 and 96 DF, p-value: 0.01441 &lt;&gt; 5.0.5 Question 1.e. Perform a multiple regression with LifSat as the dependent variable and educ, age and ChildSup as the independent variables. Hint: You can use the + sign to add multiple variables to a model. Click for explanation results &lt;- lm(LifSat ~ educ + age + ChildSup, data) summary(results) ## ## Call: ## lm(formula = LifSat ~ educ + age + ChildSup, data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -32.98 -12.56 2.68 11.03 41.91 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 134.9801 53.2798 2.533 0.0130 * ## educ 2.8171 1.1436 2.463 0.0156 * ## age -1.5952 0.7188 -2.219 0.0289 * ## ChildSup 2.4092 1.1361 2.121 0.0366 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 16.92 on 94 degrees of freedom ## Multiple R-squared: 0.1741, Adjusted R-squared: 0.1477 ## F-statistic: 6.603 on 3 and 94 DF, p-value: 0.0004254 &lt;&gt; 5.0.6 Question 1.f. Compare the results under 1.e with those obtained under 1.b-1.d. What do you notice when you compare the regression parameter for each of the three predictors in the multiple regression with the corresponding regression parameters obtained in the simple regressions? "],["week-1-class.html", "Chapter 6 Week 1 - Class", " Chapter 6 Week 1 - Class During the practical you will work on some exercises about ANOVA and ANCOVA using regression and path modeling. Note that ANOVA and ANCOVA are special cases of regression, as discussed during MTS3 or a similar course. How to perform an ANOVA/ANCOVA as a regression analysis is prerequisite knowledge. This practical we will work on these topics (ANOVA, ANCOVA, regression and how they are related). If you need to refresh your knowledge you could use the internet to find information or you could look it up in a book on statistics, for example Field, Miles, and Field (2012) (The chapters on ANOVA, Factorial ANOVA, and ANCOVA (11.6)). We start with two exercises in which you have to explore your data and perform a regression analysis, ANOVA and an ANCOVA. You will also practice with performing an ANCOVA as a regression analysis in exercise 3 today. References "],["loading-data-1.html", "6.1 Loading data", " 6.1 Loading data Open the file Sesam.sav: # Library for reading SPSS files: library(foreign) # Load the data and put them in the object called &quot;data&quot; data &lt;- read.spss(&quot;sesam.sav&quot;, to.data.frame = TRUE, use.value.labels = FALSE) This file is part of a larger dataset that evaluates the impact of the first year of the Sesame Street television series. Sesame Street is mainly concerned with teaching preschool related skills to children in the 3-5 year age range. The following variables will be used in this exercise: age measured in months prelet knowledge of letters before watching Sesame Street (range 0-58) prenumb knowledge of numbers before watching Sesame Street (range 0-54) prerelat knowledge of relations before watching Sesame Street (range 0-17) peabody vocabulary maturity before watching Sesame Street (range 20-120) postnumb knowledge of numbers after a year of Sesame Street (range 0-54) "],["section-1.html", "6.2 Section 1", " 6.2 Section 1 6.2.1 Question 1.a What is the level of measurement of each of the variables? Click for explanation In the Environment panel in the top right corner of the screen, click the arrow in the next to the object called data. Alternatively, run the rode: head(data). 6.2.2 Question 1.b What is the average age in the sample? And the range (youngest and oldest child)? Hint: Use library(tidySEM); descriptives() Click for explanation As in the take home exercises, use the function descriptives() from the tidySEM package to describe the data: library(tidySEM) descriptives(data) 6.2.3 Question 1.c What is the average gain in knowledge of numbers? Provide both the mean and the standard deviation. Hint: Use the &lt;- operator to assign to a new variable in data. You can use descriptives(), or the functions mean() and sd(). Click for explanation Create a new variable that represents the difference between pre- and post-test scores: data$dif &lt;- data$postnumb - data$prenumb There are specialized functions to obtain the mean and sd: mean(data$dif) ## [1] 9.158333 sd(data$dif) ## [1] 9.682401 6.2.4 Question 1.d Choose an appropriate graph to present the gain scores. What did you choose and why? Hint: As explained in the introductory chapters, you can use ggplot and add a histogram, density plot, or boxplot: geom_histogram(); geom_density(); geom_boxplot() Click for explanation library(ggplot2) p &lt;- ggplot(data, aes(x = dif)) p + geom_histogram() p + geom_density() p + geom_boxplot() 6.2.5 Question 1.e Can you think of a graph based on two variables that is informative? What is it and how is it informative? Hint: A useful plotting function for a bivariate distribution is the scatterplot: geom_point() Click for explanation #Possible variables would be the pre- and post measurement ggplot(data, aes(x = prenumb, y = postnumb)) + geom_point() 6.2.6 Question 1.f Which of the variables age, prelet, prenumb, prerelat and peabody are related to postnumb? Use Pearsons correlations (cor()). You dont need to check assumptions. If you want p-values for the correlations, use the function corr.test() from the psych package instead. Hint: The function corr.test() from the psych package provides Pearsons correlationsand p-values (the base R function cor() does not provide p-values). Select variables by name from a data.frame object (like data) using the following syntax: data[, c(\"each\", \"variable\", \"name\")]. Click for explanation library(psych) corr.test(data[, c(&quot;age&quot;, &quot;prelet&quot;, &quot;prenumb&quot;, &quot;prerelat&quot;, &quot;peabody&quot;, &quot;postnumb&quot;)]) ## Call:corr.test(x = data[, c(&quot;age&quot;, &quot;prelet&quot;, &quot;prenumb&quot;, &quot;prerelat&quot;, ## &quot;peabody&quot;, &quot;postnumb&quot;)]) ## Correlation matrix ## age prelet prenumb prerelat peabody postnumb ## age 1.00 0.33 0.43 0.44 0.29 0.34 ## prelet 0.33 1.00 0.72 0.47 0.40 0.50 ## prenumb 0.43 0.72 1.00 0.72 0.61 0.68 ## prerelat 0.44 0.47 0.72 1.00 0.56 0.54 ## peabody 0.29 0.40 0.61 0.56 1.00 0.52 ## postnumb 0.34 0.50 0.68 0.54 0.52 1.00 ## Sample Size ## [1] 240 ## Probability values (Entries above the diagonal are adjusted for multiple tests.) ## age prelet prenumb prerelat peabody postnumb ## age 0 0 0 0 0 0 ## prelet 0 0 0 0 0 0 ## prenumb 0 0 0 0 0 0 ## prerelat 0 0 0 0 0 0 ## peabody 0 0 0 0 0 0 ## postnumb 0 0 0 0 0 0 ## ## To see confidence intervals of the correlations, print with the short=FALSE option The use of data[,] follows the conventions of matrix indexation: You can select rows (the horizontal lines) like this, data[i, ], and columns (the vertical lines) like this, data[ ,j], where i are the rows and j are the columns you want to select. As you can see in the example, you can select multiple columns using c(  ,  ). 6.2.7 Question 1.g Can age and prenumb be used to predict postnumb? If so, discuss the substantial importance of the model and the significance and substantial importance of the separate predictors. Hint: The function lm() (short for linear model) conducts linear regression. The functions summary() provides relevant summary statistics for the model. It can be helpful to store the results of your analysis in an object, too. Click for explanation results &lt;- lm(formula = postnumb ~ age + prenumb, data = data) summary(results) ## ## Call: ## lm(formula = postnumb ~ age + prenumb, data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -38.130 -6.456 -0.456 5.435 22.568 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 7.4242 5.1854 1.432 0.154 ## age 0.1225 0.1084 1.131 0.259 ## prenumb 0.7809 0.0637 12.259 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 9.486 on 237 degrees of freedom ## Multiple R-squared: 0.4592, Adjusted R-squared: 0.4547 ## F-statistic: 100.6 on 2 and 237 DF, p-value: &lt; 2.2e-16 6.2.8 Question 1.h Provide the null hypotheses and the alternative hypotheses of the model in 1.g. Click for explanation The null-hypotheses of the model pertain to the variance explained: \\(\\rho^2\\) (thats Greek letter rho, for the population value of \\(\\rho^2\\)). \\(H_0: \\rho^2 = 0\\) \\(H_a: \\rho^2 &gt; 0\\) 6.2.9 Question 1.i Consider the path model below. How many regression coefficients are estimated in this model? And how many variances? And how many covariances? How many degrees of freedom does this model have? (\\(df = N_{obs}  N_{par}\\), see slides Lecture 1). 6.2.10 Question 1.j Consider a multiple regression analysis with three continuous independent variables, tests in language, history and logic, and one continuous dependent variable, a score on a math test. We want to know whether the various tests can predict the math score. Sketch a path model for this analysis (there are examples in the lecture slides of week 1). How many regression parameters are there? How many variances could you estimate? How many covariances could you estimate? How many degrees of freedom does this model have? "],["section-2.html", "6.3 Section 2", " 6.3 Section 2 Open the file Drivers.sav: # Load the data and put them in the object called &quot;data&quot; data &lt;- read.spss(&quot;Drivers.sav&quot;, to.data.frame = TRUE) 6.3.1 Research question 1 (ANOVA): Does talking on the phone interfere with peoples driving skills? The IV for this reseach question is condition, with conditions: hand-held phone hands-free phone control The DV is reaction time in milliseconds in a driver simulation test, in variable RT. 6.3.2 Question 2.a Perform the ANOVA. You can use lm(y ~ -1 + x) to remove the intercept from a regression with dummies, and get a separate mean for each group. The function aov() is an alternate interface for lm() that reports results in a way that matches the conventions for ANOVA analyses more closely. Click for explanation You can use summary(lm(y ~ -1 + x)) to get the means for each group: results &lt;- lm(formula = RT ~ -1 + condition, data = data) summary(results) ## ## Call: ## lm(formula = RT ~ -1 + condition, data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -317.50 -71.25 2.97 89.55 243.45 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## conditionhand-held 654.50 29.08 22.51 &lt;2e-16 *** ## conditionhands-free 617.55 29.08 21.24 &lt;2e-16 *** ## conditioncontrol 553.75 29.08 19.04 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 130.1 on 57 degrees of freedom ## Multiple R-squared: 0.9586, Adjusted R-squared: 0.9564 ## F-statistic: 440 on 3 and 57 DF, p-value: &lt; 2.2e-16 And you can use aov() to get the sum of squares for the factor: results &lt;- aov(formula = RT ~ condition, data = data) summary(results) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## condition 2 103909 51954 3.072 0.0541 . ## Residuals 57 964082 16914 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 6.3.3 Question 2.b What are the assumptions you need to check? Click for explanation We can check several assumptions: Presence of outliers Normality of residuals Homogeneity of residuals Lets deal with them in order. 6.3.3.1 Presence of outliers: In Y-space We can check the range of the standardized (scale()) residuals for outliers in Y-space. The residuals are inside of the results object, so we can just extract them, standardize them, and get the range: range(scale(results$residuals)) ## [1] -2.483778 1.904491 What is your conclusiong about the outliers? 6.3.3.2 Normality of residuals We can check the normality of residuals using a QQplot. qqnorm(results$residuals) qqline(results$residuals) There appears to be some mild deviation from normality at the extremes. You can also test for normality with the shapiro.test(x) function: shapiro.test(results$residuals) ## ## Shapiro-Wilk normality test ## ## data: results$residuals ## W = 0.98367, p-value = 0.6013 6.3.3.3 Homogeneity of Variances The bartlett.test() function provides a parametric K-sample test of the equality of variances. This test has the same hypotheses as the Levenes test. bartlett.test(formula = RT~condition, data = data) ## ## Bartlett test of homogeneity of variances ## ## data: RT by condition ## Bartlett&#39;s K-squared = 2.7203, df = 2, p-value = 0.2566 It can also be nice to use a paneled boxplot to visualize the distributions. For this, we will use ggplot2. This time, we introduce a new command, theme_bw(): A theme for the plot that conforms to APA standards. We can apply this theme to any figure created using ggplot(): library(ggplot2) ggplot(data, aes(y = RT, group = condition)) + geom_boxplot() + theme_bw() 6.3.4 Question 2.c Explain for each of the assumptions why they are important to check. 6.3.5 Question 2.d What are your conclusions regarding the assumption checks? Click for explanation There are no outliers in X-space, no evidence for (severe) deviations from normality of residuals, and no evidence for (severe) heteroscedasticity. 6.3.6 Question 2.e Answer the research question. Hint: Use summary() and TukeyHSD(). Click for explanation We can examine the overall F-test, which is significant: summary(results) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## condition 2 103909 51954 3.072 0.0541 . ## Residuals 57 964082 16914 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 TukeyHSD(results) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = RT ~ condition, data = data) ## ## $condition ## diff lwr upr p adj ## hands-free-hand-held -36.95 -135.917 62.017041 0.6434900 ## control-hand-held -100.75 -199.717 -1.782959 0.0451401 ## control-hands-free -63.80 -162.767 35.167041 0.2750829 Post-hoc tests with Bonferroni correction can be obtained using TukeyHSD(results). We notice that none of these comparisons are significant. However, the research question was Does talking on the phone interfere with peoples driving skills? There are two conditions for talking on the phone. We could thus test a planned contrast of these two conditions against the control condition, instead of all possible post-hoc tests: The standard contrasts are dummy coded: contrasts(data$condition) ## hands-free control ## hand-held 0 0 ## hands-free 1 0 ## control 0 1 We can replace these with planned contrasts for phone vs control, and hand-held vs hands-free: contrasts(data$condition) &lt;- cbind(phoneVcontrol = c(-1, -1, 2), handVfree = c(-1, 1, 0)) results &lt;- aov(RT ~ condition, data) # Ask for the lm summary, which gives you t-tests for the planned contrasts: summary.lm(results) ## ## Call: ## aov(formula = RT ~ condition, data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -317.50 -71.25 2.98 89.55 243.45 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 608.60 16.79 36.248 &lt;2e-16 *** ## conditionphoneVcontrol -27.42 11.87 -2.310 0.0245 * ## conditionhandVfree -18.47 20.56 -0.898 0.3727 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 130.1 on 57 degrees of freedom ## Multiple R-squared: 0.09729, Adjusted R-squared: 0.06562 ## F-statistic: 3.072 on 2 and 57 DF, p-value: 0.05408 6.3.7 Research question 2 (ANCOVA): Are there differences in reaction time between the conditions when controlling for age? 6.3.8 Question 2.f What are the assumptions you need to check? Click for explanation Assumptions for ANCOVA are the same as for ANOVA (no outliers, normality of residuals, homoscedasticity). ANCOVA has the following additional assumptions: Homogeneity of regression slopes for the covariate (no interaction between factor variable and covariate) The covariate is independent of the treatment effects. I.e. there is no difference in the covariate between the groups of the independent variable. 6.3.9 Question 2.g Explain for each of the assumptions why they are important to check. 6.3.10 Question 2.h Check the assumptions of ANCOVA. Hint: Within formulas, you can use * instead of + to include interaction effects. Click for explanation 6.3.10.1 Homogeneity of regression slopes Add the interaction to the model and test whether the interaction is significant: results_age &lt;- aov(RT ~ condition + age, data) results_age_int &lt;- aov(RT ~ condition * age, data) summary(results_age_int) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## condition 2 103909 51954 4.532 0.0151 * ## age 1 320454 320454 27.955 2.3e-06 *** ## condition:age 2 24622 12311 1.074 0.3488 ## Residuals 54 619005 11463 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #Or you could use `anova()` to compare two different models anova(results_age, results_age_int) What would your conclusion be about this assumption? Click for explanation The interaction is NOT significant; no evidence for violation of the assumption. 6.3.10.2 The covariate is independent of the treatment effects results_indep &lt;- aov(age ~ condition, data) summary(results_indep) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## condition 2 137 68.55 0.659 0.521 ## Residuals 57 5926 103.97 What would your conclusion be about this assumption? Click for explanation The covariate is not significantly related to treatment effect. The assumption is met. 6.3.11 Question 2.i Answer the research question. (Do you have to include the interaction or not?) Click for explanation results &lt;- aov(formula = RT ~ condition + age, data = data) TukeyHSD(results) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = RT ~ condition + age, data = data) ## ## $condition ## diff lwr upr p adj ## hands-free-hand-held -36.95 -118.5708 44.67082 0.5242511 ## control-hand-held -100.75 -182.3708 -19.12918 0.0119407 ## control-hands-free -63.80 -145.4208 17.82082 0.1533777 The handheld-condition has a significant higher reaction time than the control condition "],["section-3.html", "6.4 Section 3", " 6.4 Section 3 Open the file Sesam2.sav. # Load the data and put them in the object called &quot;data&quot; data &lt;- read.spss(&quot;Sesam2.sav&quot;, to.data.frame = TRUE) Use postnumb as the dependent variable in all the following analyses. 6.4.1 Question 3.a Viewcat is a factor variable, but is not coded as such in the data. Turn it into a factor. Afterwards, make sure that viewcat=1 is the reference group in the contrasts, i.e., the group that is identified by zero scores on all the associated dummy variables. Hint: Use &lt;- factor() and contrasts(). Click for explanation data$VIEWCAT &lt;- factor(data$VIEWCAT) contrasts(data$VIEWCAT) ## 2 3 4 ## 1 0 0 0 ## 2 1 0 0 ## 3 0 1 0 ## 4 0 0 1 6.4.2 Question 3.b Perform a multiple regression analysis with just the viewcat dummies as predictors. Click for explanation results &lt;- lm(POSTNUMB ~ VIEWCAT, data) summary(results) ## ## Call: ## lm(formula = POSTNUMB ~ VIEWCAT, data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -25.474 -7.942 0.240 8.526 25.240 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 18.760 2.316 8.102 8.95e-14 *** ## VIEWCAT2 9.331 2.900 3.218 0.00154 ** ## VIEWCAT3 14.714 2.777 5.298 3.49e-07 *** ## VIEWCAT4 18.032 2.809 6.419 1.24e-09 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 11.58 on 175 degrees of freedom ## Multiple R-squared: 0.2102, Adjusted R-squared: 0.1967 ## F-statistic: 15.53 on 3 and 175 DF, p-value: 5.337e-09 6.4.3 Question 3.c What do the regression coefficients represent? How can you determine the average postnumb score for each of the viewcat categories, based on the regression parameters? 6.4.4 Question 3.d Make a coloured scatter plot with age on the x-axis and postnumb on the y-axis. Colour the dots according to the their viewcat category. How do you interpret the differences in slopes of these four fit lines? Hint: Use ggplot() and geom_point(); use the argument aes(colour = ) to map colour to a certain variable. A new command is geom_smooth() : This plots a smooth line (like a regression line). Click for explanation We will use ggplot again: ggplot(data, aes(x = AGE, y = POSTNUMB, colour = VIEWCAT)) + geom_point() + # For scatterplot geom_smooth(method = &quot;lm&quot;, se = FALSE) + # For regression lines theme_bw() # For a pretty theme 6.4.5 Question 3.e Add an interaction between age and viewcat to the regression analysis. Hint: An interaction is created by multiplying two variables. You can multiply with * in the formula of lm(). Click for explanation results_interaction &lt;- lm(POSTNUMB ~ VIEWCAT*AGE, data) summary(results_interaction) ## ## Call: ## lm(formula = POSTNUMB ~ VIEWCAT * AGE, data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -23.8371 -8.2387 0.6158 8.7988 22.5611 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -18.7211 15.5883 -1.201 0.2314 ## VIEWCAT2 9.9741 20.6227 0.484 0.6293 ## VIEWCAT3 23.5825 19.3591 1.218 0.2248 ## VIEWCAT4 34.3969 19.3600 1.777 0.0774 . ## AGE 0.7466 0.3074 2.429 0.0162 * ## VIEWCAT2:AGE -0.0175 0.4060 -0.043 0.9657 ## VIEWCAT3:AGE -0.1930 0.3782 -0.510 0.6104 ## VIEWCAT4:AGE -0.3416 0.3770 -0.906 0.3663 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 10.99 on 171 degrees of freedom ## Multiple R-squared: 0.3046, Adjusted R-squared: 0.2762 ## F-statistic: 10.7 on 7 and 171 DF, p-value: 3.79e-11 6.4.6 Question 3.f Perform a sequential multiple regression. Include age and viewcat as the predictors in the first analysis. Add the interaction term in the second analysis. Make sure to obtain information about the change in R-square! Hint: Use anova() to compare two regression models. Click for explanation results_main &lt;- lm(POSTNUMB ~ VIEWCAT + AGE, data) anova(results_main, results_interaction) 6.4.7 Question 3.g Sketch path models of both steps of the regression analysis (on paper). Click for explanation Step 1: Step 2: 6.4.8 Question 3.h Write down the regression equations of both steps of the sequential analysis. Click for explanation \\(Postnumb_i = b_0 + b_1D_{view2i} + b_2D_{view3i} + b_3D_{view4i} + b_4Age_i + \\epsilon_i\\) \\[ \\begin{aligned} Postnumb_i = b_0 + &amp;b_1D_{view2i} + b_2D_{view3i} + b_3D_{view4i} + b_4Age_i +\\\\ &amp;b_5D_{view2i}Age_i + b_6D_{view3i}Age_i + b_7D_{view4i}Age_i + \\epsilon_i \\end{aligned} \\] 6.4.9 Question 3.i Write down the null hypothesis that is tested to determine whether there is an interaction between age and viewcat. Click for explanation \\(H_0: b_5 = b_6 = b_7 = 0\\) 6.4.10 Question 3.j Indicate for each parameter in the second regression model what it means. Also write down the regression equation for each of the four categories of viewcat separately. Click for explanation Parameter Meaning b_0 Intercept; the predicted value of postnumb for someone of age 0 in viewcat 1 b_1 Slope of the dummy for viewcat 2; difference in the predicted value of postnumb for someone aged 0 in category 2, compared to category 1 b_4 The effect of age for someone in viewcat 1 b_5 Difference in the effect of age for someone in viewcat 2, compared to viewcat 1 b_7 Difference in the effect of age for someone in viewcat 4, compared to viewcat 1 For viewcat 1: \\(Postnumb_i = b_0 + b_4Age_i + \\epsilon_i\\) For viewcat 2: \\(Postnumb_i = b_0 + b_4Age_i + b_1D_{view2i} + b_4Age_i + b_5D_{view2i}Age_i + \\epsilon_i\\) Etc. 6.4.11 Question 3.k What do you conclude about the interaction between age and viewcat? 6.4.12 Question 3.l Note that you can also look at this problem as an ANCOVA. What are the research question and null hypothesis in this case? Click for explanation RQ: Is there a significant difference between the marginal means of postnumb by viewcat, after controlling for age? \\(H_0:\\) After controling for age, the mans of postnumb are equal in all groups. 6.4.13 Question 3.m Perform this analysis as an ANCOVA. Hint: Add -1 to a formula to drop the intercept. Click for explanation To drop the intercept from the analysis, and estimate the marginal means for all viewcat categories, we can add -1 (minus the intercept) to the formula: results_ancov &lt;- aov(POSTNUMB~AGE+VIEWCAT-1, data) Examine the parameter estimates of the ANCOVA. What do the parameter estimates represent? Click for explanation We use summary.lm() again to obtain the parameter estimates: summary.lm(results_ancov) ## ## Call: ## aov(formula = POSTNUMB ~ AGE + VIEWCAT - 1, data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -23.680 -8.003 -0.070 8.464 22.635 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## AGE 0.5750 0.1221 4.708 5.08e-06 *** ## VIEWCAT1 -10.1056 6.5091 -1.553 0.122 ## VIEWCAT2 -0.9603 6.3865 -0.150 0.881 ## VIEWCAT3 3.7546 6.4760 0.580 0.563 ## VIEWCAT4 6.8159 6.5414 1.042 0.299 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 10.94 on 174 degrees of freedom ## Multiple R-squared: 0.8973, Adjusted R-squared: 0.8943 ## F-statistic: 304 on 5 and 174 DF, p-value: &lt; 2.2e-16 The parameter estimates are the means of each VIEWCAT category when age = 0. "],["week-1-formative-test.html", "Chapter 7 Week 1 - Formative test", " Chapter 7 Week 1 - Formative test A formative test helps you assess your progress in the course, and helps you address any blind spots in your understanding of the material. If you get a question wrong, you will receive a hint on how to improve your understanding of the material. Complete the formative test ideally after youve seen the lecture, but before the lecture meeting in which we can discuss any topics that need more attention. Question 1: In the equation \\(Y_i = a + bX_i + e_i\\), what are the model parameters? \\(Y_i, X_i\\) and \\(e_i\\) \\(a\\) and \\(b\\) \\(Y\\) and \\(X\\) \\(a\\) and \\(bX_i\\) Question 2: Multiple regression and ANCOVA are statistically equivalent. FALSE TRUE Question 3: The error term (\\(\\epsilon_i\\)) in regression equations reflects how much the observed scores of individuals differ from their predicted scores. FALSE TRUE Question 4: A model with more degrees of freedom is more complex more simple Question 5: What kind of model is depicted above? A measurement model ANOVA with dummies Multiple regression A path model Question 6: What are degrees of freedom? The number of unique pieces of information minus number of parameters Number of participants minus number of parameters The number of unique pieces of information The number of parameters Question 7: A psychologist administers a test intended to measure intelligence. Participants complete different puzzles and answer different questions. From a measurement theory point of view, what kind of variable is intelligence in this context? A measurement variable An observed variable A dependent variable A latent variable Question 8: A model with more degrees of freedom will fit the data better fit the data worse Question 9: In OLS regression, a model is fit to the individual participant data. By contrast, regression in structural equation modeling fits a model to the observed covariance matrix. FALSE TRUE "],["week-2-overview.html", "Chapter 8 Week 2 - Overview", " Chapter 8 Week 2 - Overview Lecture Download slides How do I test whether I measure what I intend to measure? In the social sciences we often try to measure things indirectly. For example, someones IQ or socio-economic status cannot be measured with just one question; we need more questions that each measure different aspects of these constructs. The method that is used in the social sciences to evaluate the quality of our measurements, and combine different questions or items to form the variables were interested in, are factor analysis and reliability analysis. Homework for the lecture Exploratory Factor Analysis: Read this weeks literature and finish the reading questions before coming to the lecture (see Blackboard for direct URLs) Make sure to also answer the reading questions (on Blackboard). Preacher, Kristopher J. and MacCullum, Robert C. (2003) Repairing Tom Swifts Electric Factor Analysis Machine, Understanding Statistics 2(1) 13-43. Kestilä, Elina (2006) Is There Demand for Radical Right Populism in the Finnish Electorate? Scandinavian Political Studies 29(3),169-191 Lecture Exploratory Factor Analysis: This lecture forms an introduction to latent variables and scaling procedures. Different aspects of exploratory factor analysis will be discussed. Most notably we focus on the differences between Principal Component Analyses (PCA) and Factor Analysis, estimation and extraction methods, and factor axes rotations. The researcher has to take decisions on all these aspects when (s)he wants to analyse whether questions form a scale or not. Furthermore, reliability and factor scores are discussed as methods to construct and evaluate the properties of a scale. Homework for the practical Exploratory Factor Analysis: Perform the take home exercise Exploratory Factor Analysis (EFA) before coming to the practical. Practical Exploratory Factor Analysis: During the practical, the take home exercise EFA is shortly discussed. After this, students can work on the class exercise EFA. "],["week-2-reading-questions.html", "Chapter 9 Week 2 - Reading questions", " Chapter 9 Week 2 - Reading questions Reference Preacher, Kristopher J. and MacCullum, Robert C. (2003) Repairing Tom Swifts Electric Factor Analysis Machine, Understanding Statistics 2(1) 13-43. Questions What is a latent variable? What is factor analysis and what can you investigate using this method? In the introduction, Preacher and Maccallum talk about a little jiffy method of doing factor analysis. Can you shortly list what this litlle jiffy  or bad practice  method of factor analysis is? What are in short the differences between Principal Component Analyses and Exploratory Factor Analyses? What is the purpose of factor rotation? Reference Kestilä, Elina (2006) Is There Demand for Radical Right Populism in the Finnish Electorate? Scandinavian Political Studies 29(3),169-191 Questions What is the research question that the author tries to answer? Describe shortly the characteristics of the Radical Right Parties (RRP) in Europe. What are the two main explanations of support for RRP that this paper focuses on? Does the empirical part of the paper reflect the theoretical framework well? Is Finland very different from other European countries in on the main dependent variables according to the author? What is the conclusion by the author; i.e. what is the answer to the research question? "],["week-2-home.html", "Chapter 10 Week 2 - Home", " Chapter 10 Week 2 - Home This exercise is based on: Kestilä, Elina (2006). Is There Demand for Radical Right Populism in the Finnish Electorate? Scandinavian Political Studies 29(3),169-191 You have read and answered questions about the article in the reading questions. In this exercise, as well as in the second class practical, we will analyze these data ourselves. The data for this practical stem from the first round of the European Social Survey (ESS). This is a repeated cross-sectional survey across 32 European countries. The first round was held in 2002, and since then, subsequent rounds of data-collection are held bi- anually. More info, as well as access to all data -&gt; www.europeansocialsurvey.org. The raw, first round data can also be found here. The file is called ESSround1- a.sav. This file contains data for all respondents, but only those variables are included that you will need in this exercise. 10.0.1 Question 1.a Download the file, and import it in R. Inspect the file (no. of cases and no. of variables) to see if the file opened well. For a description of all variables in the dataset, click here! Variable Description name Title of dataset essround ESS round edition Edition proddate Production date cntry Country idno Respondents identification number trstlgl Trust in the legal system trstplc Trust in the police trstun Trust in the United Nations trstep Trust in the European Parliament trstprl Trust in countrys parliament stfhlth State of health services in country nowadays stfedu State of education in country nowadays stfeco How satisfied with present state of economy in country stfgov How satisfied with the national government stfdem How satisfied with the way democracy works in country pltinvt Politicians interested in votes rather than peoples opinions pltcare Politicians in general care what people like respondent think trstplt Trust in politicians imsmetn Allow many/few immigrants of same race/ethnic group as majority imdfetn Allow many/few immigrants of different race/ethnic group from majority eimrcnt Allow many/few immigrants from richer countries in Europe eimpcnt Allow many/few immigrants from poorer countries in Europe imrcntr Allow many/few immigrants from richer countries outside Europe impcntr Allow many/few immigrants from poorer countries outside Europe qfimchr Qualification for immigration: christian background qfimwht Qualification for immigration: be white imwgdwn Average wages/salaries generally brought down by immigrants imhecop Immigrants harm economic prospects of the poor more than the rich imtcjob Immigrants take jobs away in country or create new jobs imbleco Taxes and services: immigrants take out more than they put in or less imbgeco Immigration bad or good for countrys economy imueclt Countrys cultural life undermined or enriched by immigrants imwbcnt Immigrants make country worse or better place to live imwbcrm Immigrants make countrys crime problems worse or better imrsprc Richer countries should be responsible for accepting people from poorer countries pplstrd Better for a country if almost everyone share customs and traditions vrtrlg Better for a country if a variety of different religions shrrfg Country has more than its fair share of people applying refugee status rfgawrk People applying refugee status allowed to work while cases considered gvrfgap Government should be generous judging applications for refugee status rfgfrpc Most refugee applicants not in real fear of persecution own countries rfggvfn Financial support to refugee applicants while cases considered rfgbfml Granted refugees should be entitled to bring close family members gndr Gender yrbrn Year of birth edulvl Highest level of education eduyrs Years of full-time education completed polintr How interested in politics lrscale Placement on left right scale 10.0.2 Question 1.b The ESS-file contains much more information than we need to re-analyze the paper by Kestilä. We need to reduce the number of cases to make sure our results pertain to the relevant target population. Kestilä only uses data from ten countries: c(\"Austria\", \"Belgium\", \"Denmark\", \"Finland\", \"France\", \"Germany\", \"Italy\", \"Netherlands\", \"Norway\", \"Sweden\"). As explained in the tutorial chapters at the beginning of this GitBook, it is possible to select rows from the data. In this case, we will select only rows from these countries by means of boolean indexing, using the %in% function to check if the value of $cntry is in the list. Hint: Use []; %in% Click for explanation 10.0.3 Question 1.c Inspect the data file again to see whether step 1b went ok. 10.0.4 Question 1.d Before we can start the analyses, we first need to screen the data. What are the things we need to watch for? (think about your earlier statistics-courses)? Click for explanation This question is open to interpretation. One thing you might notice is that all variables the authors used are currently coded as factor variables (e.g., Factor w/ 11 levels): ## [1] &quot;No trust at all&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; ## [5] &quot;4 &quot; &quot;5&quot; &quot;6&quot; &quot;7&quot; ## [9] &quot;8&quot; &quot;9&quot; &quot;Complete trust&quot; In keeping with conventions, we could treat ordinal Likert scales with &gt;5 levels as continuous. We can either re-code the data, or prevent read.spss() from coding these variables as factors when it reads the data. Here is code for both approaches. 10.0.4.1 Re-coding factors to numeric We can convert a factor to numeric using the function as.numeric(). However, in this case, we have 38 variables to convert - thats a lot of code. Thankfully, there is a function to apply this transformation to each column of the data: lapply(), short for list apply. This function takes each list element (column of the data.frame), and applies the function as.numeric() to it: 10.0.4.2 Reading data without coding factors An alternative solution is to prevent the function read.spss() from using value labels to code variables as factors when the data are loaded. However, were not going to use this right now, so the information below is merely illustrative: 10.0.5 Question 1.e Aside from screening variables by looking at summary statistics, we can also plot their distributions. You already know how to do this for one single variable. Yet it is not very difficult to plot all variables in a data.frame. To do this, we need to turn the data from wide format (one column per variable) into long format (one column with the variable names, one column with the values). The package tidyr has a convenient function to reshape data to long format: pivot_longer(). First, make a long data.frame containing variables 7:44. Next, we can plot the data - using geom_histogram(), geom_density() or geom_boxplot() as before. A new additional function allows us to make separate plots for each variable: + facet_wrap(~name, scales = \"free_x\"). Click for explanation Notice the fact that you can see that the scales are actually categorical (because of the gaps between bars), and that most variables look relatively normally distributed despite being categorical. Its probably fine to treat them as continuous. 10.0.6 Question 1.f Check the scale descriptives table again. Are there any incorrectly coded missing value labels, or other inexplicable values? 10.0.7 Question 1.g The first step in re-analyzing data is replicating the results from the paper by Kestilä. Run a Principal Component Analysis using psych::principal(), and choose the exact same specification as Kestilä concerning estimation method, rotation etc. Do two analyses: one for trust in politics, and one for attitudes towards immigration. Remember that you can view the help file for psych::principal() by running ?psych::principal. Hint: Use psych::principal() Click for explanation 10.0.7.1 Trust in politics Kestilä extracted three components, with VARIMAX rotation. When we print the results, we can hide all factor loadings smaller than the smallest one in their table, to make it easier to read: ## Principal Components Analysis ## Call: principal(r = df[, 7:19], nfactors = 3, rotate = &quot;varimax&quot;) ## Standardized loadings (pattern matrix) based upon correlation matrix ## RC3 RC2 RC1 h2 u2 com ## trstlgl 0.779 0.669 0.331 1.21 ## trstplc 0.761 0.633 0.367 1.18 ## trstun 0.675 0.556 0.444 1.44 ## trstep 0.651 0.332 0.549 0.451 1.57 ## trstprl 0.569 0.489 0.650 0.350 2.49 ## stfhlth 0.745 0.567 0.433 1.04 ## stfedu 0.750 0.603 0.397 1.14 ## stfeco 0.711 0.300 0.616 0.384 1.44 ## stfgov 0.634 0.377 0.587 0.413 1.88 ## stfdem 0.369 0.568 0.325 0.564 0.436 2.38 ## pltinvt 0.817 0.695 0.305 1.08 ## pltcare 0.811 0.695 0.305 1.11 ## trstplt 0.510 0.611 0.716 0.284 2.40 ## ## RC3 RC2 RC1 ## SS loadings 2.942 2.668 2.490 ## Proportion Var 0.226 0.205 0.192 ## Cumulative Var 0.226 0.432 0.623 ## Proportion Explained 0.363 0.329 0.307 ## Cumulative Proportion 0.363 0.693 1.000 ## ## Mean item complexity = 1.6 ## Test of the hypothesis that 3 components are sufficient. ## ## The root mean square of the residuals (RMSR) is 0.07 ## with the empirical chi square 15240.94 with prob &lt; 0 ## ## Fit based upon off diagonal values = 0.967 For attitude towards immigration, Kestilä extracted five components, with VARIMAX rotation: ## Principal Components Analysis ## Call: principal(r = df[, 20:44], nfactors = 5, rotate = &quot;varimax&quot;) ## Standardized loadings (pattern matrix) based upon correlation matrix ## RC2 RC1 RC5 RC3 RC4 h2 u2 com ## imsmetn 0.80 0.72 0.28 1.3 ## imdfetn 0.78 0.79 0.21 1.7 ## eimrcnt 0.83 0.71 0.29 1.1 ## eimpcnt 0.80 0.79 0.21 1.5 ## imrcntr 0.83 0.75 0.25 1.1 ## impcntr 0.78 0.78 0.22 1.6 ## qfimchr 0.82 0.70 0.30 1.1 ## qfimwht 0.76 0.65 0.35 1.3 ## imwgdwn 0.81 0.71 0.29 1.2 ## imhecop 0.75 0.67 0.33 1.4 ## imtcjob 0.57 0.34 0.48 0.52 2.0 ## imbleco 0.70 0.55 0.45 1.3 ## imbgeco 0.70 0.60 0.40 1.5 ## imueclt 0.57 -0.34 0.54 0.46 2.4 ## imwbcnt 0.67 0.63 0.37 1.9 ## imwbcrm 0.66 0.48 0.52 1.2 ## imrsprc 0.61 0.44 0.56 1.3 ## pplstrd 0.33 -0.54 0.46 0.54 2.2 ## vrtrlg -0.35 0.46 0.41 0.59 2.8 ## shrrfg 0.37 -0.35 0.42 0.58 4.1 ## rfgawrk 0.61 0.40 0.60 1.1 ## gvrfgap 0.69 0.56 0.44 1.3 ## rfgfrpc -0.39 0.33 0.67 3.3 ## rfggvfn 0.58 0.42 0.58 1.5 ## rfgbfml 0.60 0.46 0.54 1.6 ## ## RC2 RC1 RC5 RC3 RC4 ## SS loadings 4.38 3.40 2.78 2.19 1.72 ## Proportion Var 0.18 0.14 0.11 0.09 0.07 ## Cumulative Var 0.18 0.31 0.42 0.51 0.58 ## Proportion Explained 0.30 0.24 0.19 0.15 0.12 ## Cumulative Proportion 0.30 0.54 0.73 0.88 1.00 ## ## Mean item complexity = 1.7 ## Test of the hypothesis that 5 components are sufficient. ## ## The root mean square of the residuals (RMSR) is 0.05 ## with the empirical chi square 29520.06 with prob &lt; 0 ## ## Fit based upon off diagonal values = 0.98 10.0.8 Question 1.h Extract the PCA factor scores from the results objects, and add them to the data.frame. Give the PCA scores informative names, based on your interpretation of the factor loadings, so that you understand what they summarize. Hint: Use $; colnames(); cbind() Click for explanation Extracting factor scores The factor scores are inside of the results objects. Use the $ operator to access them: ## RC2 RC1 RC5 RC3 RC4 ## 1 1.9920289 1.3140238 -0.8305392 -0.06329775 -0.08837693 ## 4 0.1708174 -1.2167781 -0.4974957 -0.23766146 0.67364069 ## 7 -0.3580985 0.3236336 -1.5094405 -0.53052720 -2.20637993 ## 14 NA NA NA NA NA ## 17 -0.1136716 -0.7869911 -1.4664715 -0.07112144 0.41078167 ## 20 -0.9188606 2.8264230 -0.3477484 -0.73788338 -1.32089442 Were going to give these factor scores some informative names, and add them to our data.frame. You should give them different, informative names based on the meaning of the factors! ## [1] &quot;RC2&quot; &quot;RC1&quot; &quot;RC5&quot; &quot;RC3&quot; &quot;RC4&quot; 10.0.9 Question 1.i Are you able to replicate her results? Click for explanation No, probably not. The team of teachers was unable to reproduce this analysis, even though it should be pretty easy to do so 10.0.10 Question 1.j Save your syntax and bring your data and syntax to the practical on Thursday. "],["week-2-class.html", "Chapter 11 Week 2 - Class", " Chapter 11 Week 2 - Class In the unlikely event that you were able to replicate the results of Kestilä in the take-home exercise, rerun your analysis script. If you did not manage to replicate the results, load the dataset ESSround1-b.csv into RStudio. 11.0.1 Loading the data If you dont know how to load the data, click below. Click for explanation 11.0.2 Question 1 Kestilä states that running a Principal Components Analysis is a good way to test whether the survey questions in the ESS measure attitudes towards immigration and trust in politics. Based on your reading of Preacher and MacCallum (2003), do you agree with this position? 11.0.3 Question 2 If you would have to choose a method for constructing the trust in politics and attitude towards immigration scales based on the theory and background information in the Kestilä article, what type of factor analysis would you choose? What key factors influence your decision? Click for information Key factors include: Theory-driven or exploratory? Estimation method Rotation method Method to establish how many factors are needed 11.0.4 Question 3 Run two factor analyses, one for each PCA of the original article. Inspect the number of factors necessary, evaluate the rotation method, and if necessary, run the factor analysis again with adapted settings (rotation method and/or different number of factors). How many factors are there? Hint: Examing the help file for ?psych::fa Click for explanation To perform an exploratory factor analysis, you can use the function fa of the package psych. You will have to specify the data, and the variables that you want to include in the factor analyses. Furthermore, you will have to specify the number of factors that you want to extract, the rotation method and the estimation method. In order to determine the number of factors to extract, you might want to look at the eigenvalues of the factors, which can be accessed by using the following code: ## [1] 5.054 0.874 0.687 0.304 0.185 0.076 0.014 0.008 -0.060 -0.078 ## [11] -0.123 -0.149 -0.191 Another common approach is to make a scree plot. All that is required for this, is to pass the eigenvalues to the qplot() function and add a geom_path: You can do the same for the attitude variables: ## [1] 8.016 1.702 1.051 0.697 0.500 0.389 0.218 0.162 0.091 0.046 ## [11] 0.043 0.028 0.022 0.008 -0.018 -0.028 -0.032 -0.056 -0.066 -0.083 ## [21] -0.089 -0.119 -0.132 -0.146 -0.266 As recommended in the lecture, a better and more quantified way to establish the number of factors is parallel analysis (Horn, 1965). Heres how to do it in R: ## Parallel analysis suggests that the number of factors = 6 and the number of components = 3 Note that, in this case, parallel analysis recommends as many as 6 factors. However, in order to be able to compare our results with those from Kestilä, we might consider aligning ourselves with the literature and choosing the same number of factors for our analyses as components in the article. 11.0.5 Question 4 Apart from the number of factors, you also want to look at the factor loadings. They can be found in the pattern matrix. The higher the factor loadings are, the more indicative an item is for the latent factor. If you find some items to have only very low loadings (indicating that the items do not provide much information about the factor), you may choose not to include them in your analysis. This means you have to rerun the analysis under question 3. Click for explanation You can find the factor loadings by means of the print-function used in the take-home exercise, or you can search for the variable loadings, which is inside the results object, to end up with just the information you are searching for. ## ## Loadings: ## ML1 ML2 ML3 ## pltcare 0.784 -0.126 ## pltinvt 0.783 -0.131 ## trstprl 0.528 0.101 0.258 ## trstlgl 0.827 ## trstplc -0.157 0.800 ## trstplt 0.713 0.116 ## trstep 0.432 0.303 ## trstun 0.343 0.366 ## stfeco 0.128 0.725 -0.129 ## stfgov 0.270 0.640 -0.132 ## stfdem 0.201 0.479 0.129 ## stfedu -0.166 0.665 0.104 ## stfhlth -0.137 0.632 ## ## ML1 ML2 ML3 ## SS loadings 2.518 2.035 1.725 ## Proportion Var 0.194 0.157 0.133 ## Cumulative Var 0.194 0.350 0.483 ## ## Loadings: ## ML3 ML1 ML5 ML4 ML2 ## imsmetn 0.479 0.403 ## imdfetn 0.321 0.563 ## eimrcnt 1.110 -0.187 ## eimpcnt 0.345 0.665 ## imrcntr 0.798 ## impcntr 0.259 0.727 ## qfimchr 0.126 0.867 ## qfimwht 0.114 0.749 ## imwgdwn 0.511 0.182 ## imhecop 0.560 0.153 ## imtcjob 0.712 0.138 ## imbleco 0.702 0.162 ## imbgeco 0.740 ## imueclt 0.470 -0.166 -0.166 ## imwbcnt 0.639 -0.169 ## imwbcrm 0.515 -0.177 0.101 ## imrsprc 0.534 0.159 ## pplstrd 0.245 -0.365 ## vrtrlg -0.115 0.186 0.270 ## shrrfg 0.302 -0.280 ## rfgawrk 0.474 ## gvrfgap 0.752 ## rfgfrpc 0.219 -0.255 ## rfggvfn 0.489 ## rfgbfml 0.632 ## ## ML3 ML1 ML5 ML4 ML2 ## SS loadings 3.271 2.397 2.061 1.648 1.549 ## Proportion Var 0.131 0.096 0.082 0.066 0.062 ## Cumulative Var 0.131 0.227 0.309 0.375 0.437 The matrix of loadings indicates how strongly each factor (columns) is associated with the items (rows). Below the matrix of loadings, we see a second matrix, which indicates (amongst other things) the proportion var: How much variance in the items is explained by each of the factors. Each subsequent factor explains slightly less variance than the ones before it (this is a property of exploratory factor analysis). The cumulative var indicates how much variance the factors explain, in total. If you estimated as many factors as items, then the last value for cumulative var would be 1.00 (100%). The factor loading matrix is slightly hard to read, due to the jumble of factor loadings. To create more clarity, it is convenient to suppress the factor loadings that are lower than .30. ## ## Loadings: ## ML1 ML2 ML3 ## pltcare 0.78 ## pltinvt 0.78 ## trstprl 0.53 ## trstlgl 0.83 ## trstplc 0.80 ## trstplt 0.71 ## trstep 0.43 0.30 ## trstun 0.34 0.37 ## stfeco 0.73 ## stfgov 0.64 ## stfdem 0.48 ## stfedu 0.67 ## stfhlth 0.63 ## ## ML1 ML2 ML3 ## SS loadings 2.52 2.03 1.72 ## Proportion Var 0.19 0.16 0.13 ## Cumulative Var 0.19 0.35 0.48 Furthermore, if you want to perform a factor analysis without, say, stfedu, while you want all other variables included in your factor analysis, you can simply leave the column number of stfedu, which is 13, out of the command: 11.0.6 Question 5 Give the factor scores an appropriate name. You can do this by inspecting the items that load on one factor. What do these items have in common substantively? The goal of a factor analysis usually is to create interpretable factors. If you have trouble interpreting the factors, you can choose to tweak the analysis by changing the options, or including/excluding more items. Furthermore, after you named the factor scores accordingly, extract them from the results object and add them to the data.frame. Hint: If you do not know how to do this, have a look at question 1.h from the take-home exercise of week 2. Please note that the colnames will be specified from left to right, and not, for example, from ML1 to ML5. 11.0.7 Question 6 The next step is to assert whether the items that together form one factor, also form a reliable scale. Run separate reliability analyses by means of the function alpha for the items that together form one factor, and evaluate Cronbachs alpha to see whether the scales are internally consistent. The Reliability if an item is dropped (alpha.drop) information may be handy to inspect what would happen if you would delete one item; you can find it inside the reliability analysis object. If Cronbachs alpha is not ok, deselect one survey item and run the analyses under question 4 and question 5 again. Hint: Cronbachs alpha &gt; .7 are deemed to be ok, &gt; .8 is good. If Cronbachs alpha is not ok, deselect one survey item and run the analyses under question 4 and question 5 again. Click for explanation If you want to assess the reliability of the variables pltcare, pltinvt, trstprl, trstplt, and trstep you can run a reliability analysis as follows. Hint: name the new objects substantively, instead of numbering them. ## ## Reliability analysis ## Call: psych::alpha(x = df_with_scores[, c(7, 8, 9, 12, 13)]) ## ## raw_alpha std.alpha G6(smc) average_r S/N ase mean sd median_r ## 0.8 0.83 0.82 0.49 4.8 0.0019 4.4 1.4 0.52 ## ## lower alpha upper 95% confidence boundaries ## 0.8 0.8 0.81 ## ## Reliability if an item is dropped: ## raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r med.r ## pltcare 0.79 0.80 0.77 0.50 4.0 0.0021 0.017 0.52 ## pltinvt 0.80 0.81 0.78 0.51 4.2 0.0021 0.016 0.53 ## trstprl 0.73 0.78 0.76 0.47 3.6 0.0027 0.018 0.52 ## trstplt 0.70 0.75 0.73 0.43 3.1 0.0031 0.014 0.43 ## trstep 0.78 0.82 0.80 0.53 4.6 0.0021 0.010 0.52 ## ## Item statistics ## n raw.r std.r r.cor r.drop mean sd ## pltcare 17975 0.66 0.75 0.67 0.56 2.6 1.1 ## pltinvt 17971 0.64 0.74 0.65 0.54 2.4 1.1 ## trstprl 17753 0.84 0.80 0.74 0.69 6.3 2.3 ## trstplt 17966 0.88 0.86 0.83 0.77 5.3 2.2 ## trstep 16390 0.77 0.70 0.59 0.57 5.6 2.3 Sometimes, the table Reliability if an item is dropped will indicate that Cronbachs alpha increases when you drop a variable out of the analysis. Note, however, that doing so is an exploratory approach to analysis, and it may make your work incomparable to other publications using the same scale. 11.0.8 Question 7 Now you can analyze the differences between the factor scores for the PCA analysis (take-home exercise 2) and the EFA by plotting them in a series of scatterplots (bivariate) using ggplot2. The PCA factor scores are already stored in the dataset ESSround1-b.csv in columns 45 through 52 (df[, 45:52]). Plot the scores for one of your new factors on the x axis, and try to match it with a corresponding PCA component in the dataset. Note that if you went with a different number of factors than Kestiläs components (5 for trust in politics and 3 for attitudes towards immigration), you may find little correlation between any factors. Click for explanation Make sure to adjust the arguments x = EFA_trust1 and y = PCA_Trust1 to align with your own EFA factor column name and a PCA component column name from the data respectively 11.0.9 Question 8 Examine the correlations between the PCA and EFA scales for the trust in politics scores, and for the immigration scores. What is your conclusion: is there a difference between them? Click for explanation Hint: Name the new objects substantively once again. Example for trust in politics: ## Call:corr.test(x = df_with_scores$trustinstEFA, y = df_with_scores$trustinst, ## use = &quot;complete.obs&quot;) ## Correlation matrix ## [1] 0.94 ## Sample Size ## [1] 14778 ## These are the unadjusted probability values. ## The probability values adjusted for multiple tests are in the p.adj object. ## [1] 0 ## ## To see confidence intervals of the correlations, print with the short=FALSE option 11.0.10 Question 9 Kestila uses the PCA factor scores to evaluate country level differences in 1. Attitudes towards immigration and 2. Political trust. Repeat her analyses using the factor scores you saved in step 5. Think about the statistical test you would like to use. Do you draw similar or different conclusions? Click for explanation We can use an ANOVA to test whether the countries differ in the amount of political trust the participants have. ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## cntry 8 1740 217.55 199.6 &lt;2e-16 *** ## Residuals 14769 16100 1.09 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## 3409 observations deleted due to missingness In which trustinstEFA is the dependent variable, cntry is the grouping variable, and df is the name of the dataset; summary will provide the results. However, it will only indicate whether the variable cntry is significant or not, so you will be unable to tell which countries differ in terms of their political trust. To tell which countries differ, you can do a pairwise comparison test, with a Bonferroni adjustment for multiple testing. ## Austria Belgium Denmark Finland Germany Italy Netherlands Norway ## Belgium 0.000 NA NA NA NA NA NA NA ## Denmark 0.000 0 NA NA NA NA NA NA ## Finland 0.000 0 0.085 NA NA NA NA NA ## Germany 0.033 0 0.000 0 NA NA NA NA ## Italy 1.000 0 0.000 0 1 NA NA NA ## Netherlands 0.000 0 0.000 0 0 0.000 NA NA ## Norway 0.000 0 0.000 0 0 0.000 0 NA ## Sweden 0.231 0 0.000 0 0 0.144 0 0.005 11.0.11 Question 10 The second goal of Kestilä is to show how socio-demographic characteristics affect attitudes towards immigrants and trust in politics in Finland. Select only the Finnish cases using the variable cntry. Click for explanation To select the Finnish cases only, select rows for which $cntry is equal to (==) Finland: After selecting the Finnish cases, we have to prepare our variables for analysis. Thanks to the factor analyses above, our dependent variables are taken care of. However, we should examine the independent variables to make sure there are no surprises, and do any recoding necessary before we can run multiple regression. The independent variables are c(\"gndr\", \"yrbrn\", \"eduyrs\", \"polintr\", \"lrscale\"). Click for explanation Note that we still have to do some recoding. For example, the data contains participants year of birth instead of their age. We have to recode this variable. The data were collected in 2002, so we can simply subtract the year of birth of every participant from the year 2002. Furthermore, the variables polintr and lrscale are currently coded as character variables. If you analyze them like that, R will make dummies for all distinct values on these variables. Lets recode those, too! The main challenge is to get the levels of these variables in the correct order, and convert them to numbers. We demonstrate two ways to do this, one way for each of the two variables. For political interest, we convert the character variable to an ordered categorical variable, and we specify the correct order of labels. Then, we convert it to a numeric variable. ## ## Hardly interested Not at all interested Quite interested ## 842 228 785 ## Very interested ## 144 ## ## Not at all interested Hardly interested Quite interested ## 228 842 785 ## Very interested ## 144 For political orientation, only the two extreme values of the scale are labeled as text. Thus, we can replace these labels with numbers, and then convert the entire variable to numeric. ## ## 1 2 3 4 5 6 7 8 9 Left Right ## 25 62 148 183 599 199 296 217 79 24 59 Furthermore, Kestilä recoded polintr in such a way that there are only two categories. The lowest two and highest two categories were combined. Here is how to do this in R, so you can replicate their analysis: Next, run a number of multiple linear regression analyses with the (sub-)scales of attitudes towards immigrants and political trust as subsequent dependent variables, and the same predictors as Kestilä. Inspect your output. Compare your results with the results from Kestilä. How do your results differ or agree with the results by Kestilä? ## ## Call: ## lm(formula = trustinstEFA ~ gndr + age + eduyrs + polintr_dummy + ## lrscale, data = df_finland, na.action = na.omit) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.0364 -0.4740 0.1394 0.6379 2.3394 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.100441 0.125066 -0.803 0.4220 ## gndrMale 0.010228 0.044386 0.230 0.8178 ## age -0.001053 0.001356 -0.776 0.4377 ## eduyrs 0.027904 0.006277 4.445 9.34e-06 *** ## polintr_dummyQuite or very interested 0.090948 0.045642 1.993 0.0465 * ## lrscale 0.051650 0.011037 4.680 3.10e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9159 on 1734 degrees of freedom ## (260 observations deleted due to missingness) ## Multiple R-squared: 0.03377, Adjusted R-squared: 0.03099 ## F-statistic: 12.12 on 5 and 1734 DF, p-value: 1.454e-11 11.0.12 Question 11 Save your syntax and your data, you will need it next week. "],["week-2-formative-test.html", "Chapter 12 Week 2 - Formative test", " Chapter 12 Week 2 - Formative test A formative test helps you assess your progress in the course, and helps you address any blind spots in your understanding of the material. If you get a question wrong, you will receive a hint on how to improve your understanding of the material. Complete the formative test ideally after youve seen the lecture, but before the lecture meeting in which we can discuss any topics that need more attention. Question 1: With PCA, you must indicate the number of factors to extract a-priori. FALSE TRUE Question 2: When conducting an exploratory factor analysis, cross-loadings are assumed to be zero. TRUE FALSE Question 3: Order these methods for determining the number of factors from least subjective to most subjective: 1) Kaisers criterion, 2) Scree plot, 3) Parallel analysis. 3, 2, 1 1, 2, 3 3, 1, 2 2, 1, 3 Question 4: What kind of model is displayed above? Exploratory Factor Analysis Confirmatory Factor Analysis An Item Response Theory Analysis Principal Components Analysis Question 5: EFA models the covariances among items; PCA describes the total variance of items. FALSE TRUE Question 6: Factor analysis is a statistical technique aimed at data reduction. TRUE FALSE Question 7: What is the maximum number of latent variables when conducting Exploratory Factor Analysis with 5 items? No limit; you can keep adding latent variables, but they will explain ever decreasing amounts of variance. Two; you need 3 indicators for one latent variable, but the model is still identified due to the covariance between latent variables. Five; the same as the number of indicators. Only one; you need at least 3 indicators per latent variable. Question 8: Promax rotation in factor analysis is a specific form of orthogonal rotation. TRUE FALSE Question 9: Which of these is not a valid method for choosing the correct number of factors? Kaisers criterion Ability to predict a criterion scale. Scree plot Parallel analysis Theory Question 10: Varimax is a form of orthogonal rotation in factor analysis TRUE FALSE "],["week-3-overview.html", "Chapter 13 Week 3 - Overview", " Chapter 13 Week 3 - Overview Lecture Download slides Often researchers use scales that have been used and tested before. Because of this, they have clear ideas of the number of factors to expect and they can also indicate which specific questions belong to which factor. Instead of doing Exploratory Factor Analysis (EFA), methods have been developed that allow us to test whether a presupposed factor structure is there (Confirmatory Factor Analysis or CFA). Read this weeks literature and finish the reading questions before coming to the lecture. Byrne, Barbara (2005) Factor Analytic Models: Viewing the Structure of an Assessment Instrument From Three Perspectives, Journal of Personality Assessment 85(1), 17-32 Lecture Confirmatory Factor Analysis: Introduction into Confirmatory Factor Analysis (CFA), and differences with exploratory Factor Analysis Methods. Furthermore, the general idea of model fit is discussed and an introduction into the R-package lavaan is given. Homework for the practical Confirmatory Factor Analysis Complete the tutorial for the lavaan package. Perform the take home exercise before coming to the practical. Practical Confirmatory Factor Analysis: During the practical, the take home exercise CFA will be discussed briefly. In the remainder of the practical, students can work on class exercise CFA (measurement and scaling) "],["week-3-reading-questions.html", "Chapter 14 Week 3 - Reading questions", " Chapter 14 Week 3 - Reading questions Reference Byrne, Barbara (2005) Factor Analytic Models: Viewing the Structure of an Assessment Instrument From Three Perspectives, Journal of Personality Assessment 85(1), 17-32 Questions What are the main differences between exploratory factor analysis (EFA) and confirmatory factor analysis (CFA)? In what circumstances should a researcher use EFA and when CFA? What are the 5 main limitations of EFA, that CFA models overcome? In what circumstances can a second order CFA be useful? Compare the four factor analysis techniques we have now discussed: PCA (see last week) and the models on page 21 (EFA), page 19/24 (CFA) and page 26 (second order CFA). Consider the following three research situations: which factor analysis technqiue would you prefer for each situation and why? A researcher has developed a new questionnaire that should measure someones personality and wants to know how many factors there are. A researcher has used seven items that have been used since the 1960 to measure one concept: authoritarianism A researcher has recorded someons highest completed education, the number of years of education someone has taken and highest education followed for all respondents in a survey, and is unsure which variable to use to measure the concept education "],["week-3-home.html", "Chapter 15 Week 3 - Home", " Chapter 15 Week 3 - Home Last week, you have worked on the data used by Kestilä in a paper that discussed two possible reasons why there is no Radical Right party in Finland. You have attempted to 1) replicate her study by doing a Principal Component Analysis and 2) a factor analysis (exploratory) of the same data. This week you also learned that it is possible to do Confirmatory Factor Analysis within the structural equation modeling (SEM) framework. We use the R-package lavaan to fit these kinds of models. Before we will analyze the Kestilä data, you first need to learn some of the basic principles of doing analyses using lavaan. Using syntax, you need to tell lavaan exactly what kind of model you want it to estimate This opens up many more possibilities to do Theory Construction and then subsequently test your theory using Statistical Modeling. As a preparation for the next practical, work your way through this tutorial (part of which consists of the official lavaan tutorial). You will find that lavaan is a very user-friendly software package. 15.0.1 Get started with lavaan To get started with lavaan, read and run the following two chapters of the official lavaan tutorial: Installing lavaan Lavaan syntax (you just have to read this one) 15.0.2 Regression models in lavaan Download the data file Hamilton.csv, or Hamilton.xls here. The data are as follows: Hamilton (1990) provided several measurements on each of 21 states. Three of the measurements will be used in this tutorial: Average SAT score Per capita income expressed in $1,000 units Median education for residents 25 years of age or older Load the data from the .csv or .xls file into R. Hint: Use read.csv() or readxl::read_excel() Click for explanation Or 15.0.3 Conceptual model The following path diagram shows a model for these data: This is a simple regression model where one observed variable, SAT, is predicted as a linear combination of the other two observed variables, Education and Income. As with nearly all empirical data, the prediction will not be perfect. The variable Other represents variables other than Education and Income that affect SAT. Each single-headed arrow represents a regression weight. The number 1 in the figure specifies that Other must have a weight of 1 in the prediction of SAT. This constraint is imposed by default in lavaan. 15.0.4 Lavaan syntax Based on the lavaan tutorial, write down (just as text) the model syntax that describes the model in the picture. How many regressions are there? How many covariances? Click for explanation The syntax for this model is: Or, equivalently: This syntax specifies two regression equations and one covariance. However, three more parameters are included by lavaan per default: The residual (unexplained) variance in SAT The variance of Income The variance of Education So, strictly speaking, if you dont want to rely on the default settings, the syntax would be: 15.0.5 Performing the analysis In lavaan, models are fit using the sem() function. Run the command ?sem to open the help file for this function. Try to figure out how to take the syntax you wrote for the previous question, and fit it to the Hamilton data. Click for explanation This will result in a warning about the variances. You can ignore this. 15.0.6 Viewing the output Most of the relevant output of a lavaan analysis can be extracted using the summary() function. Get a summary for the analysis now. Do either of the predictors have a significant effect on SA? By specifying the option rsquare = TRUE in the summary() function, you can additionally get squared multiple correlations for the dependent variables. Click for explanation ## lavaan 0.6-9 ended normally after 48 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 6 ## ## Number of observations 21 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## SAT ~ ## Income 2.156 3.050 0.707 0.480 ## Education 136.022 29.819 4.562 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## Income ~~ ## Education 0.127 0.064 2.000 0.046 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .SAT 382.736 118.115 3.240 0.001 ## Income 2.562 0.791 3.240 0.001 ## Education 0.027 0.008 3.240 0.001 ## ## R-Square: ## Estimate ## SAT 0.603 15.0.7 Plotting the output The package semPlot can automatically plot simple SEM models, like path models and CFA models. To visualize this SEM model, install the semPlot package, and use the function semPaths: The default plot can be improved upon, for example, by plotting the parameter estimates onto the paths, and rotating it to match our initial conceptual model at the start of this tutorial: "],["week-3-class.html", "Chapter 16 Week 3 - Class", " Chapter 16 Week 3 - Class This week, we will analyze the data from the European social survey, and the paper by Kestilä for the last time. Last week, you first replicated the results by Kestilä, and then ran your own set of factor analyses. Hopefully you experienced yourself that it matters quite a bit what type of factor analysis method you choose; both for the interpretation of your factors, and analyses that incorporate factor scores. Instead of doing Exploratory Factor Analysis, another way of analyzing the data from the European Social Survey would be to use Confirmatory Factor Analysis. During this practical, you will conduct a CFA and compare your results to earlier EFA and PCA results and the article by Kestilä. 16.0.1 Question 1 Load the ESS data into R, into an object called df. The data are in the file \"week3_class.csv\". You can load it into R using the syntax: Furthermore, you will have to load the package lavaan before starting with the exercises. Click for explanation Furthermore, we want to work with numeric variables instead of factors once again, and with the countries of interest only. Click for explanation 16.0.2 Question 2 First, review your EFA-results for the trust in politics items, as well as the question wordings of the items. How many factors do you expect? 16.0.3 Question 3 Build a CFA model for the trust in politics items by means of the R-package lavaan. A tutorial example is available here: http://lavaan.ugent.be/tutorial/cfa.html Make sure to ask for model fit statistics. What do you find for the value of Chi-square, df, RMSEA and CFI? Any idea why you find this Chi-square value? Does the model fit the data? Click for explanation ## lavaan 0.6-9 ended normally after 45 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 27 ## ## Used Total ## Number of observations 15448 18187 ## ## Model Test User Model: ## ## Test statistic 9188.922 ## Degrees of freedom 51 ## P-value (Chi-square) 0.000 ## ## Model Test Baseline Model: ## ## Test statistic 75675.049 ## Degrees of freedom 66 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.879 ## Tucker-Lewis Index (TLI) 0.844 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -357923.209 ## Loglikelihood unrestricted model (H1) -353328.748 ## ## Akaike (AIC) 715900.419 ## Bayesian (BIC) 716106.840 ## Sample-size adjusted Bayesian (BIC) 716021.036 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.108 ## 90 Percent confidence interval - lower 0.106 ## 90 Percent confidence interval - upper 0.110 ## P-value RMSEA &lt;= 0.05 0.000 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.058 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## trustpol =~ ## pltcare 1.000 ## pltinvt 0.981 0.015 65.449 0.000 ## trstplt 2.848 0.035 80.855 0.000 ## satcntry =~ ## stfeco 1.000 ## stfgov 1.039 0.013 81.895 0.000 ## stfdem 0.979 0.012 80.257 0.000 ## stfedu 0.780 0.012 64.344 0.000 ## stfhlth 0.706 0.012 58.239 0.000 ## trustinst =~ ## trstlgl 1.000 ## trstplc 0.777 0.012 64.538 0.000 ## trstun 0.861 0.013 66.949 0.000 ## trstprl 1.123 0.013 85.721 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## trustpol ~~ ## satcntry 0.793 0.016 48.672 0.000 ## trustinst 0.950 0.018 51.888 0.000 ## satcntry ~~ ## trustinst 2.046 0.040 51.736 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .pltcare 0.651 0.008 77.811 0.000 ## .pltinvt 0.680 0.009 78.658 0.000 ## .trstplt 1.103 0.029 38.414 0.000 ## .stfeco 2.671 0.038 70.723 0.000 ## .stfgov 2.287 0.035 66.172 0.000 ## .stfdem 2.266 0.033 68.444 0.000 ## .stfedu 3.378 0.042 79.725 0.000 ## .stfhlth 3.721 0.045 81.846 0.000 ## .trstlgl 2.997 0.040 74.548 0.000 ## .trstplc 3.178 0.040 80.410 0.000 ## .trstun 3.443 0.043 79.405 0.000 ## .trstprl 1.746 0.030 57.842 0.000 ## trustpol 0.450 0.011 41.572 0.000 ## satcntry 2.751 0.058 47.286 0.000 ## trustinst 2.690 0.059 45.613 0.000 16.0.4 Question 4 As an alternative model, build a 1-factor model, with the same items as you used before, and one trust in politics factor. Evaluate the Chi-square, df, RMSEA and CFI again. Does the one factor-model fit better or worse than the factor model you previously estimated? Note, there is also a formal way to test whether a difference between two chi-square values is significant; more on that in the practicals of week 4. Click for explanation ## lavaan 0.6-9 ended normally after 38 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 26 ## ## Used Total ## Number of observations 14778 18187 ## ## Model Test User Model: ## ## Test statistic 17667.304 ## Degrees of freedom 65 ## P-value (Chi-square) 0.000 ## ## Model Test Baseline Model: ## ## Test statistic 81699.096 ## Degrees of freedom 78 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.784 ## Tucker-Lewis Index (TLI) 0.741 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -374912.206 ## Loglikelihood unrestricted model (H1) -366078.555 ## ## Akaike (AIC) 749876.413 ## Bayesian (BIC) 750074.036 ## Sample-size adjusted Bayesian (BIC) 749991.410 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.135 ## 90 Percent confidence interval - lower 0.134 ## 90 Percent confidence interval - upper 0.137 ## P-value RMSEA &lt;= 0.05 0.000 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.080 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## political_trust =~ ## pltcare 1.000 ## pltinvt 0.966 0.018 55.075 0.000 ## trstprl 2.986 0.043 70.171 0.000 ## trstplt 2.988 0.042 71.755 0.000 ## stfeco 2.262 0.039 57.544 0.000 ## stfgov 2.489 0.040 62.079 0.000 ## stfdem 2.522 0.039 64.095 0.000 ## stfedu 1.756 0.036 48.642 0.000 ## stfhlth 1.554 0.035 43.930 0.000 ## trstlgl 2.526 0.041 61.195 0.000 ## trstplc 1.956 0.036 54.052 0.000 ## trstun 2.350 0.040 59.017 0.000 ## trstep 2.296 0.038 60.160 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .pltcare 0.743 0.009 81.579 0.000 ## .pltinvt 0.775 0.009 82.043 0.000 ## .trstprl 1.938 0.027 70.877 0.000 ## .trstplt 1.548 0.023 67.052 0.000 ## .stfeco 3.565 0.044 81.289 0.000 ## .stfgov 3.044 0.038 79.326 0.000 ## .stfdem 2.631 0.034 78.072 0.000 ## .stfedu 3.941 0.047 83.419 0.000 ## .stfhlth 4.201 0.050 84.093 0.000 ## .trstlgl 3.370 0.042 79.787 0.000 ## .trstplc 3.410 0.041 82.311 0.000 ## .trstun 3.451 0.043 80.749 0.000 ## .trstep 3.019 0.038 80.272 0.000 ## political_trst 0.360 0.010 36.350 0.000 16.0.5 Question 5 Similarly, can you think of a 2-factor model that would explain political trust? Build this model as well, and compare Chi-square, df, RMSEA and CFI to both the 1-factor and the 3-factor model. Which of the models is the best in your opinion? By now, you should be able to perform your own two-factor CFA, based on substantive grounds. If you do not know how to do this immediately, please have a look at question 3. Note: None of the models fit really well. In practice, this would mean that you would have to change the model. For now, stick with the best model you have. 16.0.6 Question 6 Choose your best model, and ask for the standardized estimates by means of the addition standardized = TRUE in the summary command. Which item is the best predictor of the first factor? Click for explanation ## lavaan 0.6-9 ended normally after 45 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 27 ## ## Used Total ## Number of observations 15448 18187 ## ## Model Test User Model: ## ## Test statistic 9188.922 ## Degrees of freedom 51 ## P-value (Chi-square) 0.000 ## ## Model Test Baseline Model: ## ## Test statistic 75675.049 ## Degrees of freedom 66 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.879 ## Tucker-Lewis Index (TLI) 0.844 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -357923.209 ## Loglikelihood unrestricted model (H1) -353328.748 ## ## Akaike (AIC) 715900.419 ## Bayesian (BIC) 716106.840 ## Sample-size adjusted Bayesian (BIC) 716021.036 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.108 ## 90 Percent confidence interval - lower 0.106 ## 90 Percent confidence interval - upper 0.110 ## P-value RMSEA &lt;= 0.05 0.000 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.058 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## trustpol =~ ## pltcare 1.000 0.671 0.639 ## pltinvt 0.981 0.015 65.449 0.000 0.658 0.624 ## trstplt 2.848 0.035 80.855 0.000 1.911 0.876 ## satcntry =~ ## stfeco 1.000 1.659 0.712 ## stfgov 1.039 0.013 81.895 0.000 1.724 0.752 ## stfdem 0.979 0.012 80.257 0.000 1.624 0.733 ## stfedu 0.780 0.012 64.344 0.000 1.294 0.576 ## stfhlth 0.706 0.012 58.239 0.000 1.171 0.519 ## trustinst =~ ## trstlgl 1.000 1.640 0.688 ## trstplc 0.777 0.012 64.538 0.000 1.275 0.582 ## trstun 0.861 0.013 66.949 0.000 1.411 0.605 ## trstprl 1.123 0.013 85.721 0.000 1.842 0.812 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## trustpol ~~ ## satcntry 0.793 0.016 48.672 0.000 0.712 0.712 ## trustinst 0.950 0.018 51.888 0.000 0.863 0.863 ## satcntry ~~ ## trustinst 2.046 0.040 51.736 0.000 0.752 0.752 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .pltcare 0.651 0.008 77.811 0.000 0.651 0.591 ## .pltinvt 0.680 0.009 78.658 0.000 0.680 0.611 ## .trstplt 1.103 0.029 38.414 0.000 1.103 0.232 ## .stfeco 2.671 0.038 70.723 0.000 2.671 0.493 ## .stfgov 2.287 0.035 66.172 0.000 2.287 0.435 ## .stfdem 2.266 0.033 68.444 0.000 2.266 0.462 ## .stfedu 3.378 0.042 79.725 0.000 3.378 0.668 ## .stfhlth 3.721 0.045 81.846 0.000 3.721 0.731 ## .trstlgl 2.997 0.040 74.548 0.000 2.997 0.527 ## .trstplc 3.178 0.040 80.410 0.000 3.178 0.662 ## .trstun 3.443 0.043 79.405 0.000 3.443 0.633 ## .trstprl 1.746 0.030 57.842 0.000 1.746 0.340 ## trustpol 0.450 0.011 41.572 0.000 1.000 1.000 ## satcntry 2.751 0.058 47.286 0.000 1.000 1.000 ## trustinst 2.690 0.059 45.613 0.000 1.000 1.000 16.0.7 Question 7 Byrne (2005) states that under certain conditions, a second order CFA can be specified. Would the political trust model qualify for a second order factor model? 16.0.8 Question 8 Specify a second-order factor model and run this model. What do you conclude when you evaluate model fit? Is this model better than your model that you selected in question 6? Click for explanation To run a second-order factor model, you can simply add an additional line within the single quotes containing the factors that you want in the second-order factor model, like in the example below. ## lavaan 0.6-9 ended normally after 46 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 29 ## ## Used Total ## Number of observations 14778 18187 ## ## Model Test User Model: ## ## Test statistic 10116.996 ## Degrees of freedom 62 ## P-value (Chi-square) 0.000 ## ## Model Test Baseline Model: ## ## Test statistic 81699.096 ## Degrees of freedom 78 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.877 ## Tucker-Lewis Index (TLI) 0.845 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -371137.053 ## Loglikelihood unrestricted model (H1) -366078.555 ## ## Akaike (AIC) 742332.105 ## Bayesian (BIC) 742552.531 ## Sample-size adjusted Bayesian (BIC) 742460.372 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.105 ## 90 Percent confidence interval - lower 0.103 ## 90 Percent confidence interval - upper 0.106 ## P-value RMSEA &lt;= 0.05 0.000 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.058 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## trustpol =~ ## pltcare 1.000 ## pltinvt 0.973 0.016 60.793 0.000 ## trstprl 2.825 0.037 75.592 0.000 ## trstplt 2.943 0.037 78.957 0.000 ## satcntry =~ ## stfeco 1.000 ## stfgov 1.046 0.013 80.774 0.000 ## stfdem 0.976 0.012 78.465 0.000 ## stfedu 0.779 0.012 63.067 0.000 ## stfhlth 0.705 0.012 57.172 0.000 ## trustinst =~ ## trstlgl 1.000 ## trstplc 0.799 0.012 66.870 0.000 ## trstun 0.930 0.013 72.417 0.000 ## trstep 0.875 0.012 71.768 0.000 ## trust =~ ## trustpol 1.000 ## trustinst 2.391 0.042 56.391 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## satcntry ~~ ## trust 0.797 0.016 48.523 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .pltcare 0.687 0.009 79.196 0.000 ## .pltinvt 0.718 0.009 79.838 0.000 ## .trstprl 1.834 0.028 64.765 0.000 ## .trstplt 1.166 0.023 50.203 0.000 ## .stfeco 2.648 0.038 68.975 0.000 ## .stfgov 2.255 0.035 64.065 0.000 ## .stfdem 2.295 0.034 67.280 0.000 ## .stfedu 3.376 0.043 77.978 0.000 ## .stfhlth 3.700 0.046 80.021 0.000 ## .trstlgl 2.770 0.041 67.151 0.000 ## .trstplc 2.940 0.039 74.828 0.000 ## .trstun 2.935 0.042 70.714 0.000 ## .trstep 2.699 0.038 71.292 0.000 ## .trustpol 0.035 0.004 9.165 0.000 ## satcntry 2.761 0.059 46.436 0.000 ## .trustinst 0.722 0.030 24.029 0.000 ## trust 0.381 0.011 36.203 0.000 16.0.9 Question 9 Build a new one-factor model, only using the 3 items that ask about the respondents trust in institutions with 1) trust in the legal system, 2) trust in the police and 3) trust in the UN (see below). You can also take the full model you specified in either question 6 and question 9, but you might experience that the model becomes complicated due to the large amount of arrows. After doing this, add as predictors of the latent factor: gender, age, education in years, political interest and self-placement on the left right scale. Estimate the model. The model doesnt fit very well, but for now, we will stick with this model. Write down the regression coefficients (standardized and unstandardized) and relevant test statistics. Hint: Once you add predictions to your model, you should use sem() instead of cfa(). Click for explanation We will first have to do some recoding again. You might want to make an age variable instead of a yearborn variable, which eases the interpretation. Furthermore, a dummy for gender is more informative than just the variable gndr, although this will be treated as a dummy. You will also have to recode the variables eduyrs and lrscale to numerical variables, and you will have to make a two-category dummy for the variable polintr. ## lavaan 0.6-9 ended normally after 41 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 11 ## ## Used Total ## Number of observations 15524 18187 ## ## Model Test User Model: ## ## Test statistic 615.470 ## Degrees of freedom 10 ## P-value (Chi-square) 0.000 ## ## Model Test Baseline Model: ## ## Test statistic 11664.434 ## Degrees of freedom 18 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.948 ## Tucker-Lewis Index (TLI) 0.906 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -99125.659 ## Loglikelihood unrestricted model (H1) -98817.925 ## ## Akaike (AIC) 198273.319 ## Bayesian (BIC) 198357.470 ## Sample-size adjusted Bayesian (BIC) 198322.513 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.062 ## 90 Percent confidence interval - lower 0.058 ## 90 Percent confidence interval - upper 0.067 ## P-value RMSEA &lt;= 0.05 0.000 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.025 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## trustinst =~ ## trstlgl 1.000 1.989 0.836 ## trstplc 0.802 0.014 56.879 0.000 1.596 0.731 ## trstun 0.584 0.012 50.257 0.000 1.162 0.503 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## trustinst ~ ## gndr 0.101 0.036 2.821 0.005 0.051 0.025 ## age 0.000 0.001 0.084 0.933 0.000 0.001 ## eduyrs 0.065 0.005 12.303 0.000 0.033 0.120 ## polintr -0.147 0.023 -6.357 0.000 -0.074 -0.061 ## lrscale 0.087 0.009 10.046 0.000 0.044 0.090 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .trstlgl 1.700 0.065 26.040 0.000 1.700 0.301 ## .trstplc 2.213 0.047 46.640 0.000 2.213 0.465 ## .trstun 3.996 0.050 79.266 0.000 3.996 0.747 ## .trustinst 3.833 0.085 44.906 0.000 0.969 0.969 16.0.10 Optional You can plot the resulting model using semPaths(): 16.0.11 Question 10 Now, replace the latent score trust in institutions with the EFA factor score trust in institutions. Delete the separate indicators, so you end up with the model below. Click for explanation ## lavaan 0.6-9 ended normally after 20 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 6 ## ## Used Total ## Number of observations 13829 18187 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Model Test Baseline Model: ## ## Test statistic 575.844 ## Degrees of freedom 5 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 1.000 ## Tucker-Lewis Index (TLI) 1.000 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -19582.755 ## Loglikelihood unrestricted model (H1) -19582.755 ## ## Akaike (AIC) 39177.510 ## Bayesian (BIC) 39222.717 ## Sample-size adjusted Bayesian (BIC) 39203.649 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.000 ## 90 Percent confidence interval - lower 0.000 ## 90 Percent confidence interval - upper 0.000 ## P-value RMSEA &lt;= 0.05 NA ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.000 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## trustinstEFA ~ ## gndr 0.146 0.017 8.537 0.000 0.146 0.072 ## age -0.000 0.001 -0.443 0.658 -0.000 -0.004 ## eduyrs 0.017 0.003 6.686 0.000 0.017 0.060 ## polintr 0.012 0.011 1.075 0.282 0.012 0.010 ## lrscale 0.087 0.004 20.970 0.000 0.087 0.176 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .trustinstEFA 0.994 0.012 83.153 0.000 0.994 0.959 Compare the results. Does it matter whether we use a CFA or EFA to predict trust in institutions? "],["week-4-overview.html", "Chapter 17 Week 4 - Overview", " Chapter 17 Week 4 - Overview Lecture Download slides Homework for the lecture General Linear Model: Often, the analyses in lavaan are focused on the analysis of relations between variables, or in statistical terms: covariances. Sometimes, we are interested in testing for differences in means between groups. This is also possible in lavaan. As an example, we will revisit the ANCOVA-model as being an example of moderation. When using ANCOVA and regression analysis, researchers often indicate that they are controlling for certain variables. Controlling for variables (by including them as covariates or predictors) may change your results. There is some controversy about when one is allowed to control for variables and what this actually means. A thorough understanding of the General Linear Model is helpful for appreciating the discussion. Read this weeks literature and finish the reading questions before coming to the lecture. - Miller, G. A., &amp; Chapman, J. P. (2001). Misunderstanding analysis of covariance. Journal of Abnormal Psychology, 110(1), 40-48. Lecture General Linear Model (GLM): In this lecture we focus on the General Linear Model and discuss specific cases such as ANOVA, ANCOVA and regression models (with or without dummies). Homework for the practical General Linear Model &amp; SEM: Perform the take home exercise GLM &amp; SEM before coming to the practical. Practical General Linear Model: During the practical, we will discuss the take home exercise. In the remainder of the practical, students can work on class exercise GLM &amp; SEM. "],["week-4-reading-questions.html", "Chapter 18 Week 4 - Reading questions", " Chapter 18 Week 4 - Reading questions Reference Miller, G. A., &amp; Chapman, J. P. (2001). Misunderstanding analysis of covariance. Journal of Abnormal Psychology, 110(1), 40-48. Questions: What was the original purpose of ANCOVA? In the intro two problems are mentioned which may arise when ANCOVA is used in the context of existing groups. Which problems are these, and why are these problems? On p. 44 a hypothetical statistician is discussed (introduced by Lord) who uses ANCOVA to compare the weight of boys and girls, while using initial weight as a covariate. How does this statistician use ANCOVA exactly, and why is this wrong? Why is comparing young women to old men problematic (p. 44)? In the example discussed on p. 46 (first column), what is the DV, the covariate(s) and the grouping variable? Is this a good example of the problem the authors try to point out, and why do you think it is/is not? "],["week-4-home.html", "Chapter 19 Week 4 - Home", " Chapter 19 Week 4 - Home Load the data file SocialRejection.sav into R. It contains three variables: Condition (IV), SelfEst (IV), and Spent (DV). 19.0.1 Question 1 Check the assumption of homogeneous regression lines (no interaction) first. What is your conclusion? Hint: You need to estimate a model with, and one without an interaction, and compare them using the anova() function. Click for explanation The lines are homogeneous, the assumption is met (interaction is not significant). 19.0.2 Question 2 What should you do when this assumption is violated? 19.0.3 Question 3 Before you can do an ANCOVA, you should also check the assumption of homogeneity. What does homogeneity imply, and is the assumption met? Hint: You did this in the Week 1 class exercise. Click for explanation We can do a test of homogeneity of the variances of Spent across conditions: ## ## Bartlett test of homogeneity of variances ## ## data: Spent by Condition ## Bartlett&#39;s K-squared = 0.16678, df = 2, p-value = 0.92 However, note that the assumption of homogeneity actually requires the residual variance, after controlling for the covariate SelfEst, to be the same across conditions. We can extract these residuals from a regression with only SelfEst as a predictor: Then, we can test the null hypothesis that the error variance of the dependent variable is equal across groups: ## ## Bartlett test of homogeneity of variances ## ## data: residuals_selfest and data$Condition ## Bartlett&#39;s K-squared = 0.92603, df = 2, p-value = 0.6294 The test is not significant, meaning that the error variances are indeed equal, the assumption is met. 19.0.4 Question 4 What should you do when this assumption is violated? Click for explanation You cannot really solve this problem in classical regression or ANCOVA, because only one parameter is estimated for the error variance. In SEM, however, you can estimate different error variance parameters for each group. 19.0.5 Question 5 Run the actual ANCOVA (or use previous output). What are your conclusions about the effects of the factor and the covariate? Click for explanation ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Condition 2 126.8 63.4 4.402 0.0169 * ## SelfEst 1 419.5 419.5 29.118 1.49e-06 *** ## Residuals 55 792.4 14.4 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Self esteem is significant, F (1, 55) = 29.118, p &lt; .001, the level of self esteem of the respondent is related to the amount spent. Condition is significant after controlling for the effect of self-esteem, F (2, 55) = 4.402, p = .017, the amount spent differs between the three conditions. 19.0.6 Question 6 Lets examine the differences in conditional means between the three conditions. In order to do so, we can use several approaches. 19.0.6.1 Approach 1: Conditional means We can obtain the conditional means of the three groups by asking for the predicted (expected) value, based on the model, for each of the three conditions, keeping the covariate constant at 0. For this, we apply the predict() function to the object containing our analysis. We make a small new dataset for the values that we want predictions for: ## 1 2 3 ## 12.449100 10.265532 9.152918 What are your conclusions about the three conditions (i.e., how do they differ)? 19.0.6.2 Approach 2: Testing significance We can test the significance for these differences using TukeyHSD() again, but to get the conditional means, we need to use the residuals from a model that includes only SelfEst, which we obtained before: ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = residuals_selfest ~ data$Condition) ## ## $`data$Condition` ## diff lwr upr p adj ## neutral-rejection -2.174775 -5.076198 0.7266467 0.1773921 ## confirming-rejection -3.296276 -6.197698 -0.3948536 0.0223500 ## confirming-neutral -1.121500 -3.985483 1.7424826 0.6157693 Respondents in the rejection condition spent more, than respondents in the neutral condition and the confirming condition. These differences are not tested on significance between two groups. 19.0.6.3 Approach 3: Plotting the difference This is where R really shines: We can quickly put together a plot that shows the difference between groups, along with the raw data. We use the package ggplot2 19.0.7 Question 7 An AN(C)OVA can also be specified as a regression analysis. R automatically creates dummies. Use the lm() function instead of aov(), and compare the results. Click for explanation ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Condition 2 126.8 63.4 4.402 0.0169 * ## SelfEst 1 419.5 419.5 29.118 1.49e-06 *** ## Residuals 55 792.4 14.4 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Call: ## lm(formula = Spent ~ Condition + SelfEst, data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -6.9987 -2.5886 -0.4841 1.9772 10.6503 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 12.44910 1.98050 6.286 5.54e-08 *** ## Conditionneutral -2.18357 1.22451 -1.783 0.08007 . ## Conditionconfirming -3.29618 1.21599 -2.711 0.00894 ** ## SelfEst -0.52406 0.09712 -5.396 1.49e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.796 on 55 degrees of freedom ## Multiple R-squared: 0.4081, Adjusted R-squared: 0.3758 ## F-statistic: 12.64 on 3 and 55 DF, p-value: 2.142e-06 You can get the conditional means directly from this lm() model by dropping the intercept, using -1 (which means: minus the intercept) in the formula: ## ## Call: ## lm(formula = Spent ~ -1 + Condition + SelfEst, data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -6.9987 -2.5886 -0.4841 1.9772 10.6503 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## Conditionrejection 12.44910 1.98050 6.286 5.54e-08 *** ## Conditionneutral 10.26553 2.10191 4.884 9.35e-06 *** ## Conditionconfirming 9.15292 1.96952 4.647 2.14e-05 *** ## SelfEst -0.52406 0.09712 -5.396 1.49e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.796 on 55 degrees of freedom ## Multiple R-squared: 0.4218, Adjusted R-squared: 0.3797 ## F-statistic: 10.03 on 4 and 55 DF, p-value: 3.616e-06 19.0.8 Question 8 To perform this analysis as a structural equation model, we need to manually compute dummy variables. We can use the function model.matrix() to expand a factor variable into dummies: ## Conditionrejection Conditionneutral Conditionconfirming ## 1 1 0 0 ## 2 1 0 0 ## 3 1 0 0 ## 4 1 0 0 ## 5 1 0 0 ## 6 1 0 0 We can then bind these columns with dummies to our original data using cbind() (column bind): Begin by specifying the model in lavaan like this: Click for explanation ## lavaan 0.6-9 ended normally after 21 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 4 ## ## Number of observations 59 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## Spent ~ ## SelfEst -0.524 0.094 -5.589 0.000 ## Conditionrjctn 2.184 1.182 1.847 0.065 ## Conditncnfrmng -1.113 1.167 -0.953 0.341 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .Spent 13.430 2.473 5.431 0.000 To obtain a plot of these results and compare it to our picture above, use SemPlot: 19.0.9 Additional options Note: When you are doing an ANCOVA (even as a regression model with dummies), you want to analyze both the covariance structure AND the mean structure. To include the latter in your analysis, you have to tell lavaan to include this by adding the argument meanstructure = TRUE in the fitting function: ## lavaan 0.6-9 ended normally after 35 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 5 ## ## Number of observations 59 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## Spent ~ ## SelfEst -0.524 0.094 -5.589 0.000 ## Conditionrjctn 2.184 1.182 1.847 0.065 ## Conditncnfrmng -1.113 1.167 -0.953 0.341 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .Spent 10.266 2.029 5.058 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .Spent 13.430 2.473 5.431 0.000 To obtain the standardized results and the proportion of explained variance (= squared multiple correlation, i.e., R2), you can use the options in the summary() function: ## lavaan 0.6-9 ended normally after 35 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 5 ## ## Number of observations 59 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Spent ~ ## SelfEst -0.524 0.094 -5.589 0.000 -0.524 -0.565 ## Conditionrjctn 2.184 1.182 1.847 0.065 2.184 0.214 ## Conditncnfrmng -1.113 1.167 -0.953 0.341 -1.113 -0.111 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .Spent 10.266 2.029 5.058 0.000 10.266 2.155 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .Spent 13.430 2.473 5.431 0.000 13.430 0.592 ## ## R-Square: ## Estimate ## Spent 0.408 19.0.10 Question 9 Compare your results to those obtained with the regression analysis. What is your conclusion? 19.0.11 Question 10 Check the model fit. What do you conclude? Note: Use summary() and fit.measures = TRUE Click for explanation ## lavaan 0.6-9 ended normally after 35 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 5 ## ## Number of observations 59 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Model Test Baseline Model: ## ## Test statistic 30.941 ## Degrees of freedom 3 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 1.000 ## Tucker-Lewis Index (TLI) 1.000 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -160.344 ## Loglikelihood unrestricted model (H1) -160.344 ## ## Akaike (AIC) 330.689 ## Bayesian (BIC) 341.077 ## Sample-size adjusted Bayesian (BIC) 325.353 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.000 ## 90 Percent confidence interval - lower 0.000 ## 90 Percent confidence interval - upper 0.000 ## P-value RMSEA &lt;= 0.05 NA ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.000 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## Spent ~ ## SelfEst -0.524 0.094 -5.589 0.000 ## Conditionrjctn 2.184 1.182 1.847 0.065 ## Conditncnfrmng -1.113 1.167 -0.953 0.341 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .Spent 10.266 2.029 5.058 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .Spent 13.430 2.473 5.431 0.000 Saturated model, so perfect fit. Because the number of parameters to be estimated is equal to the number of observed statistics, there is a perfect fit. Here our interest is mainly in getting the estimates, not in the model-fit. "],["week-4-class.html", "Chapter 20 Week 4 - Class", " Chapter 20 Week 4 - Class You will continue with the analysis of the Social Rejection data from the Take Home exercise. Instead of running the model as a regression model with dummy variables (as in the Take Home exercise), in lavaan you can also run the model as a regression model with multiple groups. So, when you have data with categorical and continuous independent variables, as in the data file SocialRejection.sav, you could either perform: an ANCOVA in R a regression analysis with dummy variables (in R or lavaan) or you could perform a multiple group analysis in lavaan. The advantages of performing a multiple groups analysis in lavaan in this situation are: You can allow for differences in the (residual) variances across the groups (= violation of assumption of homogeneity) You can more easily test the assumption of homogenous regression lines In a multiple group analysis you specify one model and test whether this model is correct for all the groups, or whether there are differences between the groups. 20.0.1 Specify basic model First, specify the following model as a text string, so you can later use it in lavaan: Click for explanation 20.0.2 How to run multi-group model To run this model as a multi-group model, you can specify the argument group = when running the analysis: Now, obtain the standardized estimates and the squared multiple correlations (r square) for this model. Click for explanation ## lavaan 0.6-9 ended normally after 53 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## ## Number of observations per group: ## rejection 19 ## neutral 20 ## confirming 20 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## Test statistic for each group: ## rejection 0.000 ## neutral 0.000 ## confirming 0.000 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## ## Group 1 [rejection]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Spent ~ ## SelfEst -0.449 0.145 -3.102 0.002 -0.449 -0.580 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .Spent 11.073 2.768 4.000 0.000 11.073 2.593 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .Spent 12.108 3.928 3.082 0.002 12.108 0.664 ## ## R-Square: ## Estimate ## Spent 0.336 ## ## ## Group 2 [neutral]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Spent ~ ## SelfEst -0.495 0.214 -2.315 0.021 -0.495 -0.460 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .Spent 9.690 4.331 2.237 0.025 9.690 2.095 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .Spent 16.874 5.336 3.162 0.002 16.874 0.789 ## ## R-Square: ## Estimate ## Spent 0.211 ## ## ## Group 3 [confirming]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Spent ~ ## SelfEst -0.617 0.137 -4.523 0.000 -0.617 -0.711 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .Spent 10.861 2.604 4.171 0.000 10.861 2.322 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .Spent 10.812 3.419 3.162 0.002 10.812 0.494 ## ## R-Square: ## Estimate ## Spent 0.506 20.0.3 Question 1 Report on the parameter estimates for the three groups; i.e., the regression coefficients, the intercepts (marginal means of Spent), and the residual variances (i.e., the variances of the residuals of Spent). Note: Whats missing from the model are the means and variances of SelfEst. Thats because any variable that is purely independent is not strictly considered to be part of the model. We can manually incorporate it into the model by estimating the intercept of SelfEst. This will make SelfEst part of the model, so we will also get its variance. You estimate the intercept of a variable by adding this code to your model: 20.0.4 Question 2 Which constraints would we need to impose, across the groups, in order to make this multi-group model equivalent to an ANCOVA? Click for explanation Fix regression lines of the covariate to be equal across groups Fix residual variances to be equal across groups 20.0.5 Question 3 An ANCOVA tests whether the means of several groups on the DV (Spent) are all equal (while controlling for the covariate). What are the \\(H_0\\) and \\(H_1\\) of an ANCOVA? Click for explanation \\(H_0\\): The intercepts of Spent are all equal across groups \\(H_1\\): There is a difference in intercepts of Spent across groups 20.0.6 Question 4 You could test the null-hypothesis that you formulated in the previous question by imposing one more constraint across the three groups. What is this constraint? Click for explanation Fix all intercepts to be equal. 20.0.7 Imposing constraints So, by putting constraints to these models, we can make the same model as an ANCOVA. In lavaan, we impose constraints by giving labels to parameters. You use c() to make a vector of labels that is equally long as the number of groups, and you can give any name to the labels. You then use the * symbol to assign it to a parameter. The syntax looks like this: If you use the same name multiple times, these parameters will be constrained to be equal: Constraints for variances are specified similarly: 20.0.8 Stepwise approach If you want to add several restrictions (contraints), we can impose them all at once, or in a stepwise manner. Here, we will explain the stepwise approach. But if you know which model you want to run (e.g., an ANCOVA), you can also skip these steps and just run your final model and check if the fit is good. First you test the model without the constraints and the next step is that you test the model with the first constraint, then a model with the first and second constraint, and so forth. These are all nested models. Give the models informative names, so you can easily compare them. NOTE: make sure to specify increasingly more restricted models, that is, do not release restrictions once they have been imposed). So you go from completely free to most restrictive. You can compare subsequent models using chi-square difference tests (ironically, by calling the anova() function) to ensure that the constraints you imposed are tenable. Note that if the chi-square difference test is significant, this means you CANNOT impose the constraint! In this case, we could run the following nested models: Unconstrained model. No constraints are imposed Model 1. Structural weights: constrain the regression coefficient across groups Model 2. Structural residuals: constrain the variances and covariances of the residuals of the endogenous variables (here: Spent) Model 3. Structural intercepts: constrain the intercepts of the endogenous variables across groups We can compare two of these models using the anova() function: However, with more than two models, it is convenient to compare all of them at once. For this, we can use the function compareFit() from the semTools package (which you have to install): 20.0.9 Question 5 Run the series of models (nested models) as described above. Compare the models and report the chi-square difference test of this comparison. Why does this test have the df it has? What is your conclusion about the constraints you imposed? What does this mean? Click for explanation ## The following lavaan models were compared: ## unconstrained ## regression ## residuals ## intercepts ## To view results, assign the compareFit() output to an object and use the summary() method; see the class?FitDiff help page. In model 1 we constrained the regression lines to be equal across groups. In this model there is 1 regression coefficient estimated instead of 3, so the difference in df = 3-1=2. The associated chi-square is not significant Chi2(2) = 0.74, p = .69. This means that the regression lines can be considered equal across groups, and the first assumption of Ancova holds. In model 2 we additionally constrained the residual variance of Spent to be equal across groups. In this model there is 1 residual variance estimated instead of 3, so the difference in df with the previous model is 3-1=2. The associated chi-square is not significant Chi2(2) = 1.74, p = .61. This means that the residual variances of Spent can als be considered equal across groups, and both assumptions hold. 20.0.10 Question 6 Next, compare Model 3 to Model 2. Report the chi-square difference test, what is the conclusion now? Is it the same conclusion from the ANCOVA? Report the relevant results for both the ANCOVA and the Multi-group model, compare the results. (Also think about: what would you report in an article?) Click for explanation Additionally constraining the intercepts to be equal across groups significantly deteriorated model fit, Chi2(2) = 7.61, p = .02. This means that the intercepts cannot be considered equal across groups. There is thus a significant difference in Spent between these conditions, controlled for Self-Esteem. In model 2 we see that, compared to the neutral condition (M = 10.27), the intercept is highest in the Rejection condition (M = 12.45) and lowest in the Confirming condition (M = 9.15). In the ANCOVA in SPSS we saw that the effect of Condition was significant after controlling for the effect of self-esteem, F (2, 55) = 3.784, p &lt; .05, so the amount spent differs between the three conditions. Respondents in the rejection condition spent more, than respondents in the neutral condition and the confirming condition. The two conclusions are similar. "],["week-5-overview.html", "Chapter 21 Week 5 - Overview", " Chapter 21 Week 5 - Overview Lecture Download slides Introducing means into statistical models/How can I investigate mediation? Homework for the lecture Mediation: Researchers often have theories about possible causal relationships between variables. A particularly important topic in this respect is mediation, in which variable X influences variable Y through a third variable, the mediator. For instance, psychotherapy (X), may affect thoughts (mediator), which in turn affects mood (Y). Read this weeks literature and finish the reading questions before coming to the lecture. - MacKinnen, D. P., Krull, J. L., Lockwood, C. M. (2000). Equivalence of the mediation, confounding, and suppression effect. Prevention Science, 1, 173-181. - Holbert, R. L. &amp; Stephenson, M. T. (2003). The importance of indirect effects in media effects research: Testing for mediation in structural equation modeling. Journal of Broadcasting &amp; Electronic Media, 47, 556-572. Lecture Mediation: There are two approaches to investigating mediation. The first approach is within the context of multiple linear regression analysis. The second approach is based on path models, which form a special case of Structural Equation Modeling. We consider both and discuss their advantages and weaknesses. Homework for the practical Mediation: Perform take home exercise mediation before coming to the practical. Practical Mediation: During the practical we will discuss take home exercise mediation. In the remainder of the practical an introduction into estimating mediation and path models in lavaan will be given. "],["week-5-reading-questions.html", "Chapter 22 Week 5 - Reading questions", " Chapter 22 Week 5 - Reading questions Reference Andrew F. Hayes (2009) Beyond Baron and Kenny: Statistical Mediation Analysis in the New Millennium, Communication Monographs, 76:4, 408-420. Questions: What is an indirect or mediated effect? What is the difference between the total and direct effect? What is the problem with the Barron &amp; Kenny steps? What is bootstrapping, and why is it superior to Sobels test? Explain how it is possible that effects that dont exist can be mediated. Answers The indirect effect is interpreted as the part of the effect of X on Y that is explained by the pathway through M. It is computed by multiplying the effect of X on M (a), wich the effect of M on Y (b), so: Indirect effect = a * b. The total effect is a simple bivariate regression of X on Y. The direct effect is the effect of X on Y while controlling for M; it could be obtained by running a multiple regression with X and M as predictors of Y. These steps make decisions about the existence of mediation based on the significance of coefficients in multiple consecutive regression analyses. The repeated testing causes this method to have low power. Moreover, if no significant total effect is found between X and Y, researchers might incorrectly assume that no indirect effect exists either. Bootstrapping constructs an empirical sampling distribution for a parameter by resampling the original data (e.g., 1000 times), and conducting the same analysis on each of these 1000 samples. The distribution of the estimated parameter values is used as an empirical sampling distribution. This sampling distribution can be used to derive confidence intervals (take the 2.5 and 97.5 percentiles of the distribution), compute standard errors (the standard deviation of this distribution), etc. It is superior to Sobels test because Sobels test assumes normality and this is typically violated by the product of two regression coefficients. Bootstrapping does not assume any type of distribution for the sampling distribution. Cited from the paper: That X can exert an indirect effect on Y through M in the absence of an association between X and Y becomes explicable once you consider that a total effect is the sum of many different paths of influence, direct and indirect, not all of which may be a part of the formal model. For example, it could be that two or more indirect paths carry the effect from X through Y, and those paths operate in opposite directions (cf., MacKinnon, Krull, &amp; Lockwood, 2000). Much as a main effect in 2x2 ANOVA might be nonsignificant if the simple effects are opposite in sign (i.e., a crossover interaction), two or more indirect effects with opposite signs can cancel each other out, producing a total effect and perhaps even a total indirect effect that is not detectably different from zero, in spite of the existence of specific indirect effects that are not zero. Reference Holbert, R. L. &amp; Stephenson, M. T. (2003). The importance of indirect effects in media effects research: Testing for mediation in structural equation modeling. Journal of Broadcasting &amp; Electronic Media, 47, 556-572. Questions: On p. 560 the four steps for complex mediation are discussed. The first three steps are for partial mediation. What is the difference between these two forms of mediation? What is the advantage of the Product of Coefficient approach (p. 561-562) in comparison to the Causal Step approach (p. 560-561) and the Differences in Coefficients approach (p. 561) if you want to know whether or not an effect is mediated? How does the Product of Coefficient approach work and why is it problematic? How many effects are there from Debate Viewing on Political Participation? Which effects can you easily obtain from SEM software? Answers On p. 560 the four steps for complex mediation are discussed. The first three steps are for partial mediation. What is the difference between these two forms of mediation? Step 1: X should predict Y Step 2: M should be correlated with X Step 3: M should predict Y Step 4: X is no longer a significant predictor of Y once M is included. Partial mediation: there is still a direct effect of X on Y. Full mediation: the entire effect of X on Y runs through M. What is the advantage of the Product of Coefficient approach (p. 561-562) in comparison to the Causal Step approach (p. 560-561) and the Differences in Coefficients approach (p. 561) if you want to know whether or not an effect is mediated? It leads to an actual p-value. How does the Product of Coefficient approach work and why is it problematic? Uses the product of paths, and divides this by the estimate of the standard error. Resulting quantity is then compared to a z-distribution. However, the product is not normally distributed: hence the tests (Sobel test etc.) which are based on assuming a normal distribution are incorrect. How many effects are there from Debate Viewing on Political Participation? Which effects can you easily obtain from SEM software? 1 direct effect, and 2 indirect effects. SEM will give you the direct, (total) indirect, and total (direct + all indirect) effects. "],["week-5-home.html", "Chapter 23 Week 5 - Home", " Chapter 23 Week 5 - Home The data file SelfEsteem.sav contains the following variables: Parental Attachment Peer Attachment Empathy Prosocial behavior Aggression Self-esteem Which were measured for 143 college students (mean age: 18.6 years, SD=1.61). The researcher is interested in the direct and indirect effects of parental and peer attachment on self-esteem, and the mediating roles of empathy and social behavior (i.e., prosocial behavior and aggression). Specifically, the researcher expects that having good relationships with peers will increase prosocial behavior and decrease aggressive behavior, and that this is probably mediated through empathy (since people who experience empathy are likely to want to decrease distress in others), while the relationships with parents are expected to have a more direct effect on self-esteem. 23.0.1 Specify model To investigate these research questions, you need to specify the model depicted below. Create a text string describing this model for later use with lavaan: Click for explanation 23.0.2 Question 1 How many and which paths are there from Parental Attachment to Self-esteem? And from Peer Attachment to Self-esteem? Click for explanation 3 paths each; one direct, and two indirect via Emp and Prosoc/Aggr 23.0.3 Question 2 Run this model. Discuss the fit of the model. Click for explanation ## lavaan 0.6-9 ended normally after 18 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 16 ## ## Number of observations 143 ## ## Model Test User Model: ## ## Test statistic 12.609 ## Degrees of freedom 5 ## P-value (Chi-square) 0.027 ## ## Model Test Baseline Model: ## ## Test statistic 174.959 ## Degrees of freedom 15 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.952 ## Tucker-Lewis Index (TLI) 0.857 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -1131.703 ## Loglikelihood unrestricted model (H1) -1125.399 ## ## Akaike (AIC) 2295.407 ## Bayesian (BIC) 2342.812 ## Sample-size adjusted Bayesian (BIC) 2292.185 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.103 ## 90 Percent confidence interval - lower 0.032 ## 90 Percent confidence interval - upper 0.176 ## P-value RMSEA &lt;= 0.05 0.093 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.059 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## SelfEst ~ ## ProSoc 0.312 0.084 3.721 0.000 ## Aggr 0.159 0.083 1.915 0.056 ## ParAtt 0.240 0.076 3.153 0.002 ## PeerAtt 0.083 0.089 0.935 0.350 ## ProSoc ~ ## Emp 0.520 0.071 7.285 0.000 ## Aggr ~ ## Emp -0.354 0.078 -4.528 0.000 ## Emp ~ ## ParAtt 0.078 0.075 1.045 0.296 ## PeerAtt 0.306 0.086 3.557 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## .ProSoc ~~ ## .Aggr -0.099 0.061 -1.621 0.105 ## ParAtt ~~ ## PeerAtt 0.537 0.103 5.215 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .SelfEst 0.808 0.096 8.456 0.000 ## .ProSoc 0.657 0.078 8.456 0.000 ## .Aggr 0.789 0.093 8.456 0.000 ## .Emp 0.779 0.092 8.456 0.000 ## ParAtt 1.277 0.151 8.456 0.000 ## PeerAtt 0.963 0.114 8.456 0.000 CFI is acceptable, RMSEA is not. 23.0.4 Question 3 Considering the parameter estimates, what can you say about the research questions? Click for explanation The researcher expects that having good relationships with peers will increase prosocial behavior and decrease aggressive behavior, and that this is probably mediated through empathy (since people who experience empathy are likely to want to decrease distress in others), while the relationships with parents are expected to have a more direct effect on self-esteem. Generally seems to be the case  Paratt has a significant direct effect, and ParAtt seems to have a significant effect on empathy. Need to look further at indirect effects and total effects for details. 23.0.5 Estimating indirect effects Remember that an indirect effect is the product of several chained direct effects. Therefore, to obtain an indirect effect, you can multiply the two (or more) direct effects it consists of. Based on this knowledge - and you previous experience labelling parameters - the way to estimate indirect effects may be obvious: You label the direct effects You multiply the labels There is a tutorial on this on the lavaan website: http://lavaan.ugent.be/tutorial/mediation.html Additionally, a total effect is the sum of all direct and indirect effects that connect one predictor and one outcome. So, for example, in this weeks model, two indirect effects link Empathy and Self-esteem (through prosocial and aggression). The total effect of empathy on self-esteem is therefore the sum of these two indirect effects (and no direct effect). 23.0.6 Question 4 Estimate the indirect effects of Emp on SelfEst, mediated through ProSoc and Aggr. Also estimate the total effect. Note: A new parameter is defined in lavaan using the := operator. Click for explanation ## lavaan 0.6-9 ended normally after 18 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 16 ## ## Number of observations 143 ## ## Model Test User Model: ## ## Test statistic 12.609 ## Degrees of freedom 5 ## P-value (Chi-square) 0.027 ## ## Model Test Baseline Model: ## ## Test statistic 174.959 ## Degrees of freedom 15 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.952 ## Tucker-Lewis Index (TLI) 0.857 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -1131.703 ## Loglikelihood unrestricted model (H1) -1125.399 ## ## Akaike (AIC) 2295.407 ## Bayesian (BIC) 2342.812 ## Sample-size adjusted Bayesian (BIC) 2292.185 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.103 ## 90 Percent confidence interval - lower 0.032 ## 90 Percent confidence interval - upper 0.176 ## P-value RMSEA &lt;= 0.05 0.093 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.059 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## SelfEst ~ ## ProSoc (bs_p) 0.312 0.084 3.721 0.000 ## Aggr (bs_g) 0.159 0.083 1.915 0.056 ## ParAtt 0.240 0.076 3.153 0.002 ## PeerAtt 0.083 0.089 0.935 0.350 ## ProSoc ~ ## Emp (bpr_) 0.520 0.071 7.285 0.000 ## Aggr ~ ## Emp (bgg_) -0.354 0.078 -4.528 0.000 ## Emp ~ ## ParAtt 0.078 0.075 1.045 0.296 ## PeerAtt 0.306 0.086 3.557 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## .ProSoc ~~ ## .Aggr -0.099 0.061 -1.621 0.105 ## ParAtt ~~ ## PeerAtt 0.537 0.103 5.215 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .SelfEst 0.808 0.096 8.456 0.000 ## .ProSoc 0.657 0.078 8.456 0.000 ## .Aggr 0.789 0.093 8.456 0.000 ## .Emp 0.779 0.092 8.456 0.000 ## ParAtt 1.277 0.151 8.456 0.000 ## PeerAtt 0.963 0.114 8.456 0.000 ## ## Defined Parameters: ## Estimate Std.Err z-value P(&gt;|z|) ## ind_pro 0.162 0.049 3.314 0.001 ## ind_agg -0.056 0.032 -1.764 0.078 ## total 0.106 0.051 2.066 0.039 23.0.7 Question 5 Estimate all indirect effects and the total effects of Parental Attachment and Peer Attachment on Self-esteem. Click for explanation ## lavaan 0.6-9 ended normally after 18 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 16 ## ## Number of observations 143 ## ## Model Test User Model: ## ## Test statistic 12.609 ## Degrees of freedom 5 ## P-value (Chi-square) 0.027 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## SelfEst ~ ## PrS (bse_pro) 0.312 0.084 3.721 0.000 ## Agg (bs_g) 0.159 0.083 1.915 0.056 ## PrA (bse_par) 0.240 0.076 3.153 0.002 ## PrA (bse_per) 0.083 0.089 0.935 0.350 ## ProSoc ~ ## Emp (bpr_) 0.520 0.071 7.285 0.000 ## Aggr ~ ## Emp (bgg_) -0.354 0.078 -4.528 0.000 ## Emp ~ ## PrA (bemp_par) 0.078 0.075 1.045 0.296 ## PrA (bemp_per) 0.306 0.086 3.557 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## .ProSoc ~~ ## .Aggr -0.099 0.061 -1.621 0.105 ## ParAtt ~~ ## PeerAtt 0.537 0.103 5.215 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .SelfEst 0.808 0.096 8.456 0.000 ## .ProSoc 0.657 0.078 8.456 0.000 ## .Aggr 0.789 0.093 8.456 0.000 ## .Emp 0.779 0.092 8.456 0.000 ## ParAtt 1.277 0.151 8.456 0.000 ## PeerAtt 0.963 0.114 8.456 0.000 ## ## Defined Parameters: ## Estimate Std.Err z-value P(&gt;|z|) ## ind_par_emp_pr 0.013 0.013 0.997 0.319 ## ind_peer_mp_pr 0.050 0.020 2.425 0.015 ## ind_par_emp_gg -0.004 0.005 -0.899 0.368 ## ind_peer_mp_gg -0.017 0.011 -1.580 0.114 ## total_par 0.248 0.076 3.247 0.001 ## total_peer 0.115 0.088 1.305 0.192 23.0.8 Question 6 To compare the total effect of parental attachment versus peer attachment on self esteem, should you use the standardized or unstandardized parameters? Obtain the appropriate output, and draw a conclusion. Click for explanation You should use the standardized results: ## lavaan 0.6-9 ended normally after 18 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 16 ## ## Number of observations 143 ## ## Model Test User Model: ## ## Test statistic 12.609 ## Degrees of freedom 5 ## P-value (Chi-square) 0.027 ## ## Model Test Baseline Model: ## ## Test statistic 174.959 ## Degrees of freedom 15 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.952 ## Tucker-Lewis Index (TLI) 0.857 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -1131.703 ## Loglikelihood unrestricted model (H1) -1125.399 ## ## Akaike (AIC) 2295.407 ## Bayesian (BIC) 2342.812 ## Sample-size adjusted Bayesian (BIC) 2292.185 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.103 ## 90 Percent confidence interval - lower 0.032 ## 90 Percent confidence interval - upper 0.176 ## P-value RMSEA &lt;= 0.05 0.093 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.059 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## SelfEst ~ ## PrS (bse_pro) 0.312 0.084 3.721 0.000 0.312 0.295 ## Agg (bs_g) 0.159 0.083 1.915 0.056 0.159 0.150 ## PrA (bse_par) 0.240 0.076 3.153 0.002 0.240 0.269 ## PrA (bse_per) 0.083 0.089 0.935 0.350 0.083 0.081 ## ProSoc ~ ## Emp (bpr_) 0.520 0.071 7.285 0.000 0.520 0.520 ## Aggr ~ ## Emp (bgg_) -0.354 0.078 -4.528 0.000 -0.354 -0.354 ## Emp ~ ## PrA (bemp_par) 0.078 0.075 1.045 0.296 0.078 0.093 ## PrA (bemp_per) 0.306 0.086 3.557 0.000 0.306 0.316 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .ProSoc ~~ ## .Aggr -0.099 0.061 -1.621 0.105 -0.099 -0.137 ## ParAtt ~~ ## PeerAtt 0.537 0.103 5.215 0.000 0.537 0.485 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .SelfEst 0.808 0.096 8.456 0.000 0.808 0.797 ## .ProSoc 0.657 0.078 8.456 0.000 0.657 0.729 ## .Aggr 0.789 0.093 8.456 0.000 0.789 0.875 ## .Emp 0.779 0.092 8.456 0.000 0.779 0.863 ## ParAtt 1.277 0.151 8.456 0.000 1.277 1.000 ## PeerAtt 0.963 0.114 8.456 0.000 0.963 1.000 ## ## Defined Parameters: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## ind_par_emp_pr 0.013 0.013 0.997 0.319 0.013 0.014 ## ind_peer_mp_pr 0.050 0.020 2.425 0.015 0.050 0.048 ## ind_par_emp_gg -0.004 0.005 -0.899 0.368 -0.004 -0.005 ## ind_peer_mp_gg -0.017 0.011 -1.580 0.114 -0.017 -0.017 ## total_par 0.248 0.076 3.247 0.001 0.248 0.279 ## total_peer 0.115 0.088 1.305 0.192 0.115 0.112 23.0.9 Difference between parameters To test the difference between parameters, you can constrain them to be equal and do a chi-square difference test to compare the constrained and unconstrained models. However, you can also calculate the difference between parameters, and test if its significant: 23.0.10 Bootstrapping You may have learned before that the sampling distribution of indirect effects is not normal. Consequently, you cannot use parameteric p-values to determine the significance of indirect effects because they are biased. If you want to know whether the indirect effects are significant, you can bootstrap them to obtain a 95% confidence interval. Bootstrapping means that lavaan will draw 1000 samples from the data and estimate the model on each sample. There will thus be 1000 estimates for every parameter. The lower and upper bounds of a 95% confidence interval are determined by taking the 2.5% and 97.5% quantiles of the 1000 samples for each parameter. The confidence interval is interpreted the same as a normal confidence interval: If zero lies inside the interval (e.g., lower bound is -.4 and upper bound is .9), we conclude that the parameter is not significantly different from zero, but if zero does not lie in this interval (e.g., lower bound is .4 and upper bound is 1.3), we can say the parameter differs from zero (at an alpha of .05 since we are considering a 95% confidence interval). We will get these intervals for all the parameters in the model, but we are specifically interested in the intervals for the indirect effects, because we want to know if they differ from zero (i.e., whether there is a mediated effect). In lavaan, bootstrap standard errors are requested by specifying se = bootstrap in the fitting function, and specifying the number of bootstrap samples as bootstrap = 1000. First, just get your code running by specifying a low number, like 100 or even 10. Note: To draw reliable conclusions from the results, you should always use 1000+ bootstrap samples - but it can take a long time. To obtain the confidence intervals for your model, use the following syntax: 23.0.11 Question 7 What do you conclude about the indirect and total effects of Parental attachment and Peer attachment on Self-esteem? Report your conclusions as you would report them in a paper (in words and statistics). "],["week-5-class.html", "Chapter 24 Week 5 - Class", " Chapter 24 Week 5 - Class The effect of professional child care on the cognitive, emotional, and social development of children is a much debated toping among policy makers as well as parents with young children. In particular the effect of child care during the first year of life has been of interest. The dataset WorkingMom_2014.sav describes a study in which the researchers are interested in the relationship between mothers work status during the first year of life and their childrens cognitive development by age 4.5 years, measured with the Woodcock Johnson Achievement and Cognitive Batteries (WCJ). Other variables that are considered of interest and which were included are: Mothers earnings at age 4.5; Home environment quality; Mothers sensitivity; and Mothers depression. Mothers work status has three levels: full time working moms part time working moms, and stay-at-home moms. 24.0.1 The analysis If you were to analyze these data, you could do an ANCOVA analysis, with Work (mothers working status) as factor, and the other independent variables as covariates. Here you find the results of the ANCOVA analysis (assumptions of the ANCOVA were checked and okay). ## Analysis of Variance Table ## ## Response: WCJ ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Work 2 766 382.8 1.7807 0.1691 ## MothEar 1 369 368.9 1.7160 0.1906 ## HomeEnv 1 4982 4982.0 23.1749 1.743e-06 *** ## MothSen 1 5023 5022.6 23.3638 1.584e-06 *** ## MothDep 1 4 4.0 0.0185 0.8918 ## Residuals 872 187456 215.0 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 These are the parameter estimates for that model: ## ## Call: ## lm(formula = WCJ ~ Work + MothEar + HomeEnv + MothSen + MothDep, ## data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -42.903 -9.835 -0.324 9.759 47.868 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 79.39820 5.52998 14.358 &lt; 2e-16 *** ## WorkPart time -0.84041 1.24223 -0.677 0.4989 ## Workno work 2.69758 1.33528 2.020 0.0437 * ## MothEar -0.48422 0.50179 -0.965 0.3348 ## HomeEnv 0.58431 0.12485 4.680 3.33e-06 *** ## MothSen 6.02656 1.24888 4.826 1.65e-06 *** ## MothDep -0.01705 0.12525 -0.136 0.8918 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 14.66 on 872 degrees of freedom ## Multiple R-squared: 0.05611, Adjusted R-squared: 0.04961 ## F-statistic: 8.639 on 6 and 872 DF, p-value: 3.789e-09 24.0.2 Question 1 Based on the results, what would be your advise for women with children under one year of age, and why? 24.0.3 Dummy coding Consider the other variables that were included. We may expect that these are actually influenced by mothers work status. For instance, mothers earnings by age 4.5 may depend on whether or not the mother was working during the first year, and also on whether she was working full time or part time. This implies there may be mediated or indirect effects of work status on the outcome variable. To investigate this, we can specify a SEM model in which the effects of work status are mediated through the four other variables. Note that work status is a categorical (ordinal) variable, with three categories. To include this variable as a predictor, we need to dummy-code it. lm() does this automatically; lavaan doesnt. The function dummy.code in library(psych) can help us: ## Full time Part time no work ## [1,] 1 0 0 ## [2,] 1 0 0 ## [3,] 1 0 0 ## [4,] 1 0 0 ## [5,] 1 0 0 ## [6,] 1 0 0 We need to add these variables to our data. Also, the names of the dummies include spaces, so we should rename them. One easy way to do this is to change the levels of the original variable. Then, we add the dummies to data: ## [1] &quot;Full time&quot; &quot;Part time&quot; &quot;no work&quot; If we want to use the stay-at-home moms as the reference group, we just use the other two dummies as predictors. Additionally, if we want to know the intercept of WCJ for the reference category, we need to add the argument meanstructure = TRUE to the sem() function call. 24.0.4 Question 2 We now want to specify a SEM model in which the effects of work status are mediated through the four other variables. What is the syntax of this model? Click for explanation 24.0.5 Question 3 If you had no access to lavaan, what regression analyses could you run in order to piece together this mediated path model? What else would we need to do? Click for explanation You would estimate these regression analyses: Additionally, we would have to multiply the effects of the dummies on the mediators, with the effects of the mediators on WCJ, in order to calculate the indirect effects. 24.0.6 Question 4 Add syntax to compute the indirect effects to your model from question 2, and run the analysis. Apply an appropriate solution to test whether the indirect effects are significant or not. Discuss the indirect effects of work status on the outcome variable. Taking the direct effects into account, can you explain the differences between the two dummy variables? Click for explanation First, label all regressions, and add syntax for the indirect effects: Then, estimate the model. Specify bootstrapped SEs and 1000 bootstrap samples. Remember that, to get the intercepts of dependent variables for the reference category, we should specify meanstructure = TRUE: To obtain the 95% CIs for the indirect effects, we can use the following syntax. First, I obtain the parameterestimates() and put them in an object called pars. Then, I ask for only the rows that contain my defined parameters (pars$op == \":=\"), and only the columns c(\"label\", \"est\", \"ci.upper\", \"ci.lower\"): ## label est ci.upper ci.lower ## i_earfull -0.323 0.267 -0.972 ## i_envfull 0.290 0.782 -0.086 ## i_senfull 0.436 0.971 0.089 ## i_depfull -0.014 0.222 -0.283 ## i_earpart -0.111 0.064 -0.459 ## i_envpart 0.478 1.136 0.064 ## i_senpart 0.818 1.487 0.320 ## i_deppart 0.001 0.163 -0.104 24.0.7 Question 5 If we want to determine whether working or not is harmful for childrens cognitive development, what should we consider: the direct effects, the indirect effects, or the total effects, and why? 24.0.8 Question 6 Compare the effect of the dummy variables working full time and working part time in a regression model with all control variables, to the parameters in the lavaan model. Which parameter estimates from the regression correspond to your lavaan model, and why? Click for explanation First, run the requested regression: ## ## Call: ## lm(formula = WCJ ~ workfull + workpart + MothEar + HomeEnv + ## MothSen + MothDep, data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -42.903 -9.835 -0.324 9.759 47.868 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 82.09578 5.47602 14.992 &lt; 2e-16 *** ## workfull -2.69758 1.33528 -2.020 0.0437 * ## workpart -3.53799 1.51825 -2.330 0.0200 * ## MothEar -0.48422 0.50179 -0.965 0.3348 ## HomeEnv 0.58431 0.12485 4.680 3.33e-06 *** ## MothSen 6.02656 1.24888 4.826 1.65e-06 *** ## MothDep -0.01705 0.12525 -0.136 0.8918 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 14.66 on 872 degrees of freedom ## Multiple R-squared: 0.05611, Adjusted R-squared: 0.04961 ## F-statistic: 8.639 on 6 and 872 DF, p-value: 3.789e-09 These coefficients are all identical to the direct effects on WCJ from your lavaan model. Differences are that your lavaan model ADDITIONALLY estimates the effects of the dummies on the mediators, AND computes the indirect effects. The lavaan model also uses bootstrapped standard errors. As a result, some of the conclusions about significance may differ, and our confidence intervals for the parameters differ. 24.0.9 Question 7 What are your most important conclusions about the effect of working status on cognitive development? You can use your answers to the previous questions. But a model with many variables such as this one has many possible interesting options to look at. Just look around for any interesting results! "],["week-6-overview.html", "Chapter 25 Week 6 - Overview", " Chapter 25 Week 6 - Overview Lecture Download slides How can I investigate mediation/moderation? Homework for the lecture on Moderation: In addition to mediation, researchers often have theories about moderation. Moderation implies that the effect of X on Y depends on another variable. For instance, the effect of feedback (X) on performance (Y) may depend on age (moderator), in that children who are older can more effectively process feedback than younger children. Read this weeks literature and finish the reading questions before coming to the lecture. - Baron, R.M and Kenny, D.A. (1986) The Moderator-Mediator Variable Distinction in Social Psychological Research: Conceptual, Strategic, and Statistical Considerations, Journal of Personality and Individual Differences, 51(6), p. 1173-118 - Metha, A., Chen, E, Mulvenon, S. and Dode, I. (1998) A Theoretical Model of Suicide Risk, Archives of Suicide Research, 4, p. 115-133 Lecture Moderation: Introduction into hierarchical models, moderation analysis and path models. Homework for the practical Moderation: Perform take home exercise moderation, before coming to the practical. Practical Moderation: During the practical, we will discuss take home exercise moderation. In the remainder of the practical an introduction into estimating moderation and path models in lavaan will be given. Finish the class exercise before the next meeting. "],["week-6-reading-questions.html", "Chapter 26 Week 6 - Reading questions", " Chapter 26 Week 6 - Reading questions Reference Baron, R.M and Kenny, D.A. (1986) The moderator-Mediator Variable Distinction in Social Psychological Research: Conceptual, Strategic, and Statistical Considerations, Journal of Personality and Individual Differences, 51(6), p. 1173- 1182 Questions: What is according to Baron and Kenny the nature of a moderation effect? (and can you give an example from an article or theory you had in a previous course? List the four methods hat according to Baron and Kenny are available to study interaction effects in SPSS given different levels of measurement (categorical or continuous) for the independent and moderating variable? On page 1177, Baron Kenny mention the most common approach to deal with unreliability in the mediating variable is to use multiple indicators. Thinking back to the readings and lectures about factor analysis, can you shortly explain why this is a good method? The framework that Baron and Kenny present on page 1179 is one way to study complicated models (mediating moderation, or moderating mediation). They do not discuss alternatives to this framework, but (surprise!) Structural Equation Modeling is one of them. What would you think be the main advantage of SEM over the framework of Baropn and Kenny. How can you determine whether a variable is a mediator or moderator? Answers What is according to Baron and Kenny the nature of a moderation effect? (and can you give an example from an article or theory you had in a previous course? A: A moderator is a third variable that affects the relation between two other variables. E.g. the relation between drinking a lot of alcohol while going out and trying to pick up a one night stand might be different for boys and girls. It could be that there is a relation for boys, and not for girls, but also, it might be that the relation is linear for boys, while for girls, there is a quadratic effect (indicating girls one try to pick up a one-night stand when they are really drunk), or a stepwise effect for girls (indicating that girls need to drink more than a specific amount to engage in this behavior List the four methods hat according to Baron and Kenny are available to study interaction effects in SPSS given different levels of measurement (categorical or continuous) for the independent and moderating variable? Case 1: IV dich, Mod dich -&gt; 2x2 ANOVA Case 2: IV cont, mod dich-&gt; test correlation for each level of the moderator Case 3: IV dich, mod cont -&gt; include interaction effect (with quadratic or dichotomized term term if necessary -&gt; theorize about this!) Case 4: IV cont, Mode. Cont. -&gt; include interaction effect. (with possible quadratic term) On page 1177, Baron Kenny mention the most common approach to deal with unreliability in the mediatimng variable is to use multiple indicators. Thinking back to the readings and lectures about factor analysis, can you shortly explain why this is a good method? Each variable contains measurement error. In factor analysis, scales are formed using multiple indicators. The idea is that random measurement errors here cancel eachother out, while at the same time, a better operationalization of the latent variable is achieved. In this way, measurement error in a mediating variable, would be incorporated in the model, and corrected for. The framework that Baron and Kenny present on page 1179 is one way to study complicated models (mediating moderation, or moderating mediation). They do not discuss alternatives to this framework, but (surprise!) Structural Equation Modeling is one of them. What would you think be the main advantage of SEM over the framework of Baropn and Kenny. It is much more simple (practically), and all model parameters are estimated at once, so that complex interdependencies can be modeled in a better and more sophisticated way How can you determine whether a variable is a mediator or moderator? this should not be done statistically, but theoretically. Is it a intermitting variable (mediator), or really an external variable that cannot be explained by something else (moderator)?. Statistically, one would want moderators to be unrelated to both X and Y, while in mediation, one wants a strong relation of the mediator with both X and Y Reference Weston, R. and Gore, Paul, A. (2006) A brief guide to structural equation Modeling, The Counseling Psychologist 34, p.719-752 Notes before reading: To all you non-counseling psychologists: this article is very general, dont worry this article is quite general, and you might recognize a lot of things we have discussed. This article provides an overview of things we discussed, but also adds an important aspect: the combination of factor model and path models into one Structural Equation Model skip the part on GFI (p. 741)  this index has been shown to be dependent on sample size after all and is old-fashioned (in a bad way, in statistics we dont do vintage). skip the part on missing data  there is nothing wrong with this section, but missing data is a very difficult topic, and there is a lot more to say about this. Take the course Conducting a Survey if you want to know more on missing data! Questions: The authors (Weston and Gore) state three similarities and two big differences between SEM and other multivariate statistical techniques (ANCOVA, regression). What are they? The second difference that Weston and Gore mention is presented as being a disadvantage, while some would think of it as an advantage. Tests for the model fit can indicate whether your theory can be confirmed or rejected based on your data! Along with this, the authors miss another big difference between SEM and other general linear model (ANOVA, regression). Any idea what this is? Structural Equation Models are called hybrid models when they contain a measurement and structural model. Can you explain what is meant by the terms measurement and structural model? On p. 726-726, the authors introduce the term item parcels. Look up (on the internet) what is meant with an item parcel. Can you think of an example of item parceling that you used during on of the practicals of this course? Revisit this practical, and try to thank about the disadvantages of item parceling in SEM. The authors identify 6 steps in doing SEM-analyses. What are they? Go back to the unconstrained multigroup path model estimated in the class exercise of practical 6 (question 8. last week). Try to work out for yourself how many degrees of freedom there are based on pages 732-733 of the article. On page 745 the authors mention in the 6th line from the bottom of the page, that it is a good idea to test the model using cross-validation. Look up what cross-validation in SEM is about, and explain when it is a good idea to do a cross-validation check The model that the authors use as an example does not fit the data very well (see figure 4 on page 740) and the discussion of the authors of their model. Without having the data, nor a good theories on the constructs used in this paper, can you think of a possible reason why this model might not fit? (there is no one right answer here). Hint: have a look at the results that are presented and those not presented in the paper Answers The authors (Weston and Gore) state three similarities and two big differences between SEM and other multivariate statistical techniques (ANCOVA, regression). What are they? Similarities: they are all general linear models they are only valid when the assumptions are met (PL: and many assumptions are very similar!) they cannot prove or imply causality Differences: latent constructs van be included, that provide a better operationalisation of the theoretical construct and contain less measurement error test for the model fit the second difference that Weston and Gore mention is presented as being a disadvantage, while some would think of it as an advantage. Tests for the model fit can indicate whether your theory can be confirmed or rejected based on your data! Along with this, the authors miss another big difference between SEM and other general linear model (ANOVA, regression). Any idea what this is? In SEM, more complex interdependencies between your constructs can be modeled. Structural Equation Models are called hybrid models when they contain a measurement and structural model. Can you explain what is meant by the terms measurement and structural model? measurement model = factor model, the parts where latent constructs are operationalised using two or more observed variables Structural model = the path model, the part where regression coefficients are estimated. This often includes regression coefficients between latent variables! On p. 726-726, the authors introduce the term item parcels. Look up (on the internet) what is meant with an item parcel. Can you think of an example of item parceling that you used during on of the practicals of this course? Revisit this practical, and try to thank about the disadvantages of item parceling in SEM. we used this in the first practical, where we analysed the data from the paper by Kestila. During the practical, we did EFA analysis on items in trust in politics and attitudes towardas immigrants, and saved the factor scores, which we later used in a regression model. This is a form of item parceling. The disadvantage to this approach is that the factor scores contain a lot of measurement model, which (generally) deflate (also called attenuate) the size of the regression coefficients to or from the factor scores. The authors identify 6 steps in doing SEM-analyses. What are they? data collection specification identification estimation evaluation modification Go back to the unconstrained multigroup path model estimated in the class exercise of practical 6 (question 8. last week). Try to work out for yourself how many degrees of freedom there are based on pages 732-733 of the article. 6 regression coefficients, 4 disturbances, 1 variance(depression) -&gt; 6+4+1=11 Two groups = 11 X 2 = 22 parameters to be estimated. The number of free parameters is 2x(5x(5+1)/2 = 2 x 5x6/2 = 5x6 = 30 sample moments Degrees of freedom = sample moments  estimated parameters = 30-22 = 8 On page 745 the authors mention in the 6th line from the bottom of the page, that it is a good idea to test the model using cross-validation. Look up what cross-validation in SEM is about, and explain when it is a good idea to do a cross-validation check after many alterations to the model, you might be modeling more data driven than theory driven, and you risk ending up with a theory that replicates badly (for example by blindly following modification indices). If you then check your model against a fresh (sub)sample from the same population, you can actually check whether that model fits! The model that the authors use as an example does not fit the data very well (see figure 4 on page 740) and the discussion of the authors of their model. Without having the data, nor a good theories on the concstructs used in this paper, can you think of a possible reason why this model might not fit? (there is no one right answer here). Hint: have a look at the results that are presented and those not presented in the paper it probably has to do something with the factor structure, as that is not reported in the paper "],["week-6-home.html", "Chapter 27 Week 6 - Home", " Chapter 27 Week 6 - Home Exercise based on: Metha, A., Chen, E, Mulvenon, S. and Dode, I. (1998). A Theoretical Model of Suicide Risk. Archives of Suicide Research, 4, p. 115-133. Download the dataset suiciderisk.sav here. This is a dataset that was simulated from the covariance matrices in the original paper presented on p.123. The idea behind simulation is that you can recreate the dataset from some summary statistics. The covariance matrix suffices for doing this, as it summarizes all relations between all variables (see http://en.wikipedia.org/wiki/Computer_simulation for an introduction). The new data matrix almost exactly corresponds to the data as presented in the paper, albeit that there are inconsistent data cells (negative- or our of range values for the scale of the original variables). You dont have to worry about this now. In the take home- and class exercise we will investigate the dataset on suicidesisk and test whether there is a possible moderation of gender. 27.0.1 Question 1 Baron and Kenny (1986) present four cases to illustrate how moderation can be studied. If gender is our moderator, and either depression, hopelessness, selfesteem and/or substance abuse our independent variables, what case should we use to investigate moderation? Click for explanation Case 2: dichotomous moderator, continuous independent variables 27.0.2 Question 2 First, run bivariate correlations of all continuous independent variables with suicide risk. Do you think it is useful to investigate these predictors? What if one one the correlations is non-significant. Is it then still useful to study moderation? Note: You can obtain correlations using cor() or psych::corr.test() Click for explanation A basic correlation matrix for the first 5 variables: ## suirisk subabuse hopeless selfesteem depression ## suirisk 1.0000000 0.2931462 0.3231625 -0.2751558 0.4071431 ## subabuse 0.2931462 1.0000000 0.2854853 -0.2478123 0.2991709 ## hopeless 0.3231625 0.2854853 1.0000000 -0.6266401 0.6464750 ## selfesteem -0.2751558 -0.2478123 -0.6266401 1.0000000 -0.6003697 ## depression 0.4071431 0.2991709 0.6464750 -0.6003697 1.0000000 A correlation table with p-values can be obtained using the psych::corr.test() function: ## Call:corr.test(x = data[, 1:5]) ## Correlation matrix ## suirisk subabuse hopeless selfesteem depression ## suirisk 1.00 0.29 0.32 -0.28 0.41 ## subabuse 0.29 1.00 0.29 -0.25 0.30 ## hopeless 0.32 0.29 1.00 -0.63 0.65 ## selfesteem -0.28 -0.25 -0.63 1.00 -0.60 ## depression 0.41 0.30 0.65 -0.60 1.00 ## Sample Size ## [1] 521 ## Probability values (Entries above the diagonal are adjusted for multiple tests.) ## suirisk subabuse hopeless selfesteem depression ## suirisk 0 0 0 0 0 ## subabuse 0 0 0 0 0 ## hopeless 0 0 0 0 0 ## selfesteem 0 0 0 0 0 ## depression 0 0 0 0 0 ## ## To see confidence intervals of the correlations, print with the short=FALSE option Yes, correlations are similar to those in paper, and are all significant. Even when correlations are n.s., it is still useful to investigate moderation: there might be a suppression effect 27.0.3 Question 3 Examine the relationships between suicide risk and the four continuous predictors visually. What do you think about the relations? Click for explanation 27.0.3.1 A psych solution The package `psych contains a function to help us visually check assumptions, such as linearity: 27.0.3.2 Ggplot to build plots In this case, psych is easier. But generally, we can make any plot we want using ggplot2. In ggplot, we add one plot element at a time. Here is an example for one variable: You could also add a linear trend line: This seems linear; you can check the other variables! 27.0.4 Question 4 Build the scatterplots again, but now map participants gender to the colour of the dots and smooth line. Do your conclusions differ from question 3? Click for explanation 27.0.4.1 A psych solution Again, psych has a standard solution for this situation: In ggplot, we can make the plots more detailed. We can map gender to the color of the dots and smooth line using aes(colour = gender): This seems linear; you can check the other variables! There are also some differences by gender, in range and steepness. 27.0.5 Question 5 Baron and Kenny (1986) note the correlational method (as we just used) has two serious deficiencies. We can investigate only one of them. Which? Please investigate whether this potential problem exists for the moderator gender. Note: Use psych::describeBy() or car::leveneTest Click for explanation The variances might not be equal for all levels of gender. We can do a preliminary investigation using describeBy; a version of the describe that splits the data by group. ## ## Descriptive statistics by group ## group: females ## vars n mean sd median trimmed mad min max range skew kurtosis ## suirisk 1 329 2.47 1.80 2 2.45 1.48 -2 7 9 0.09 -0.38 ## subabuse 2 329 0.94 6.45 1 0.89 7.41 -18 18 36 0.05 -0.24 ## hopeless 3 329 2.86 2.83 3 2.84 2.97 -6 12 18 0.11 0.10 ## selfesteem 4 329 31.38 5.17 31 31.37 5.93 18 45 27 0.04 -0.42 ## depression 5 329 6.07 7.60 6 6.05 7.41 -16 28 44 -0.03 -0.18 ## se ## suirisk 0.10 ## subabuse 0.36 ## hopeless 0.16 ## selfesteem 0.29 ## depression 0.42 ## ------------------------------------------------------------ ## group: males ## vars n mean sd median trimmed mad min max range skew kurtosis ## suirisk 1 192 2.75 1.84 3 2.77 1.48 -3 8 11 -0.12 0.28 ## subabuse 2 192 3.09 2.69 3 3.11 2.97 -5 9 14 -0.16 -0.12 ## hopeless 3 192 2.98 2.74 3 3.03 2.97 -5 9 14 -0.19 -0.06 ## selfesteem 4 192 32.91 5.64 33 32.81 5.93 18 47 29 0.14 -0.41 ## depression 5 192 6.39 7.75 7 6.46 7.41 -13 30 43 -0.06 0.24 ## se ## suirisk 0.13 ## subabuse 0.19 ## hopeless 0.20 ## selfesteem 0.41 ## depression 0.56 The variances turn out to be roughly the same for most variables, but there is a large difference in the variance of nartotic substance use. Lets apply Levenes test, which lives in the car package: If we want a Levenes test for all five continuous variables, it can be helpful to apply the function to the 5 columns of data. The function lapply() applies a second function (leveneTest()) to every element of a list; in this case - the five columns. The argument group stays the same for each variable: ## $suirisk ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 1 0.1234 0.7255 ## 519 ## ## $subabuse ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 1 114.51 &lt; 2.2e-16 *** ## 519 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## $hopeless ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 1 0.2901 0.5904 ## 519 ## ## $selfesteem ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 1 0.9124 0.3399 ## 519 ## ## $depression ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 1 0.0357 0.8502 ## 519 27.0.6 Question 6 Baron and Kenny also state how this problem might be resolved by looking at regression coefficients. Run a multiple regression model, with suicide risk as dependent variable, and all 4 independent variables as predictors. Run this model separately for both genders. Do you find any differences in the regression coefficients? (unstandardized) Click for explanation ## ## Call: ## lm(formula = suirisk ~ ., data = data[data$gender == &quot;females&quot;, ## 1:5]) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.0022 -1.3247 0.0047 1.2927 4.1531 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.9862150 0.8373132 2.372 0.018270 * ## subabuse 0.0587404 0.0154119 3.811 0.000165 *** ## hopeless 0.0452029 0.0458534 0.986 0.324961 ## selfesteem -0.0001569 0.0237796 -0.007 0.994741 ## depression 0.0502616 0.0162516 3.093 0.002156 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.671 on 324 degrees of freedom ## Multiple R-squared: 0.1515, Adjusted R-squared: 0.141 ## F-statistic: 14.46 on 4 and 324 DF, p-value: 7.1e-11 ## ## Call: ## lm(formula = suirisk ~ ., data = data[data$gender == &quot;males&quot;, ## 1:5]) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.9171 -1.0382 -0.0001 1.0582 3.9736 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.11735 1.11623 1.001 0.31812 ## subabuse 0.12190 0.04399 2.771 0.00615 ** ## hopeless 0.03359 0.06130 0.548 0.58441 ## selfesteem 0.01272 0.02948 0.431 0.66665 ## depression 0.11540 0.02235 5.163 6.19e-07 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.528 on 187 degrees of freedom ## Multiple R-squared: 0.3238, Adjusted R-squared: 0.3093 ## F-statistic: 22.38 on 4 and 187 DF, p-value: 4.057e-15 A small difference for substance use (.12 males, .06 females) and depression (.05 females, .115 males)? Other than that, they are similar. 27.0.7 Question 7 What do you think, does it make sense to study the moderating role of gender in a model that explains suicide risk? Click for explanation Yes, all assumptions hold, so fine to do it. 27.0.8 Question 8 One way to study moderation (and this is something you might have done in an earlier statistics course), is to compute interaction terms of the moderator variable with the independent variables. R does this automatically, if you use the multiplication symbol * in your regression equation. Run a hierarchical regression analysis: Build two regression models, and include all independent variables and gender in the first model, and add the interaction terms in the second model. Then, compare the fit of the two models using anova() Do you find that the interaction variables explain part of the variance in suicide risk over and above that of the independent variables? Click for explanation ## ## Call: ## lm(formula = suirisk ~ ., data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.7146 -1.1199 -0.0062 1.1489 4.2356 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.971013 0.659121 2.990 0.00292 ** ## subabuse 0.057529 0.014136 4.070 5.45e-05 *** ## hopeless 0.045793 0.036721 1.247 0.21296 ## selfesteem -0.003881 0.018508 -0.210 0.83399 ## depression 0.071918 0.013132 5.477 6.79e-08 *** ## gendermales 0.132756 0.154934 0.857 0.39192 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.633 on 515 degrees of freedom ## Multiple R-squared: 0.2023, Adjusted R-squared: 0.1946 ## F-statistic: 26.12 on 5 and 515 DF, p-value: &lt; 2.2e-16 ## ## Call: ## lm(formula = suirisk ~ gender * subabuse + gender * hopeless + ## gender * selfesteem + gender * depression, data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.9171 -1.1597 0.0047 1.1552 4.1531 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.9862150 0.8119207 2.446 0.01477 * ## gendermales -0.8688675 1.4350193 -0.605 0.54513 ## subabuse 0.0587404 0.0149445 3.931 9.64e-05 *** ## hopeless 0.0452029 0.0444629 1.017 0.30980 ## selfesteem -0.0001569 0.0230584 -0.007 0.99458 ## depression 0.0502616 0.0157588 3.189 0.00151 ** ## gendermales:subabuse 0.0631559 0.0489630 1.290 0.19768 ## gendermales:hopeless -0.0116150 0.0787379 -0.148 0.88278 ## gendermales:selfesteem 0.0128741 0.0388335 0.332 0.74039 ## gendermales:depression 0.0651349 0.0284552 2.289 0.02248 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.62 on 511 degrees of freedom ## Multiple R-squared: 0.2208, Adjusted R-squared: 0.2071 ## F-statistic: 16.09 on 9 and 511 DF, p-value: &lt; 2.2e-16 R2 goes from .20 to .22, so small difference. This difference is significant. The only significant interaction effect is gendermales:depression. 27.0.9 Question 9 Build a basic regression model in lavaan, see the figure below. You have built this model before. Compare your lavaan results to your earlier findings. What do you conclude? Click for explanation ## lavaan 0.6-9 ended normally after 18 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 6 ## ## Number of observations 521 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## suirisk ~ ## subabuse 0.058 0.014 4.093 0.000 ## hopeless 0.046 0.037 1.254 0.210 ## selfesteem -0.004 0.018 -0.211 0.833 ## depression 0.072 0.013 5.508 0.000 ## gender 0.133 0.154 0.862 0.389 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .suirisk 2.636 0.163 16.140 0.000 Same results, except for a small difference in the standard errors, that results from the fact we use Ordinary Least Squares (OLS)-estimation in R and Maximum Likelihood (ML) in lavaan. Apart from that, we can also estimate the correlations/covariances between the independent variables in lavaan, that we cannot estimate in R. 27.0.10 Question 10 Do you have any idea why we find a Chi-square value of exactly 0.0? Click for explanation There are no degrees of freedom (the model is identical to the saturated model) left. This means we want to estimate as many paths as there are sample moments. So, all covariances between variables are accounted for in the model, and there is no room for any deviation between our model and the data. 27.0.11 Question 11 Mehta et al (1998) state that the theory of suicide risk is more complicated than we so far modeled using regression models. The effects of self-esteem and depression are mediated through hopelessness, while depression also explains self-esteem. On page 117-118 they summarize their expectations about the effects in 6 hypotheses (H1 and H2a-e). Build a mediation model in lavaan based on these hypotheses. Leave gender out of the model for now. Run the model, and see whether the model fits by looking at the Chi-square(df), its p-value, CFI and RMSEA. In case your model does not fit, can you make it fit the data by making an alteration to the model? Note that your Chi-square values might differ slightly from those presented by Mehta et al (1998), because of data simulation procedures. Click for explanation The model fits when a covariance is added between substance use and depression (see figure 1 in the article). Then, Chi-square(3) =9.4, p=.025 CFI=.992, RMSEA=.064. This is probably what Mehta et al. (1998) did as well, without showing us. ## lavaan 0.6-9 ended normally after 35 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 12 ## ## Number of observations 521 ## ## Model Test User Model: ## ## Test statistic 9.400 ## Degrees of freedom 3 ## P-value (Chi-square) 0.024 ## ## Model Test Baseline Model: ## ## Test statistic 776.507 ## Degrees of freedom 10 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.992 ## Tucker-Lewis Index (TLI) 0.972 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -6981.634 ## Loglikelihood unrestricted model (H1) -6976.934 ## ## Akaike (AIC) 13987.267 ## Bayesian (BIC) 14038.336 ## Sample-size adjusted Bayesian (BIC) 14000.246 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.064 ## 90 Percent confidence interval - lower 0.020 ## 90 Percent confidence interval - upper 0.112 ## P-value RMSEA &lt;= 0.05 0.250 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.030 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## suirisk ~ ## hopeless 0.048 0.033 1.450 0.147 ## depression 0.073 0.013 5.779 0.000 ## subabuse 0.060 0.014 4.402 0.000 ## hopeless ~ ## depression 0.155 0.014 10.985 0.000 ## selfesteem -0.194 0.020 -9.694 0.000 ## selfesteem ~ ## depression -0.423 0.025 -17.136 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## depression ~~ ## subabuse 12.498 1.910 6.542 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .suirisk 2.639 0.164 16.140 0.000 ## .hopeless 3.854 0.239 16.140 0.000 ## .selfesteem 18.561 1.150 16.140 0.000 ## depression 58.346 3.615 16.140 0.000 ## subabuse 29.912 1.853 16.140 0.000 "],["week-6-class.html", "Chapter 28 Week 6 - Class", " Chapter 28 Week 6 - Class Start with your last model from Question 11 of the THE. Note that Depression and use of narcotic substances are completely independent in the model, i.e. they are not predicted by anything. Usually we would estimate a covariance between them, otherwise the model restricts the covariance to be zero. However, to replicate the original results, it is important to NOT estimate this covariance (fix it to zero). 28.0.1 Question 1 We can modify this general model for all cases into a multi-group model with two groups (males and females). Why is this a good method to study moderation? (or in other words, what are the two research questions we can investigate with a multi-group model?) Click for explanation Because we can investigate 1) whether the model itself is different for boys and girls and 2) whether the size of regression coefficients differ 28.0.2 Question 2 Estimate a multi-group model, with gender as grouping variable. In case you forgot how to do this, see the first of the class exercise from week 4. Look at the fit of the model, what do you find? Click for explanation ## lavaan 0.6-9 ended normally after 71 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 32 ## ## Number of observations per group: ## males 192 ## females 329 ## ## Model Test User Model: ## ## Test statistic 75.329 ## Degrees of freedom 8 ## P-value (Chi-square) 0.000 ## Test statistic for each group: ## males 26.329 ## females 49.000 ## ## Model Test Baseline Model: ## ## Test statistic 829.489 ## Degrees of freedom 20 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.917 ## Tucker-Lewis Index (TLI) 0.792 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -6897.478 ## Loglikelihood unrestricted model (H1) -6859.814 ## ## Akaike (AIC) 13858.956 ## Bayesian (BIC) 13995.140 ## Sample-size adjusted Bayesian (BIC) 13893.565 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.180 ## 90 Percent confidence interval - lower 0.144 ## 90 Percent confidence interval - upper 0.218 ## P-value RMSEA &lt;= 0.05 0.000 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.124 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## ## Group 1 [males]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## suirisk ~ ## hopeless 0.025 0.056 0.454 0.650 ## depression 0.111 0.020 5.644 0.000 ## subabuse 0.121 0.041 2.977 0.003 ## hopeless ~ ## depression 0.161 0.024 6.640 0.000 ## selfesteem -0.166 0.033 -4.973 0.000 ## selfesteem ~ ## depression -0.514 0.037 -13.811 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## depression ~~ ## subabuse 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .suirisk 1.592 0.204 7.787 0.000 ## .hopeless 7.420 1.221 6.075 0.000 ## .selfesteem 36.189 0.373 97.030 0.000 ## depression 6.391 0.558 11.460 0.000 ## subabuse 3.089 0.194 15.943 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .suirisk 2.277 0.232 9.798 0.000 ## .hopeless 3.399 0.347 9.798 0.000 ## .selfesteem 15.860 1.619 9.798 0.000 ## depression 59.707 6.094 9.798 0.000 ## subabuse 7.206 0.735 9.798 0.000 ## ## ## Group 2 [females]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## suirisk ~ ## hopeless 0.045 0.041 1.104 0.270 ## depression 0.050 0.015 3.282 0.001 ## subabuse 0.059 0.014 4.138 0.000 ## hopeless ~ ## depression 0.148 0.017 8.482 0.000 ## selfesteem -0.221 0.026 -8.612 0.000 ## selfesteem ~ ## depression -0.372 0.031 -11.841 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## depression ~~ ## subabuse 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .suirisk 1.981 0.132 14.970 0.000 ## .hopeless 8.896 0.875 10.172 0.000 ## .selfesteem 33.640 0.305 110.183 0.000 ## depression 6.073 0.418 14.525 0.000 ## subabuse 0.939 0.355 2.646 0.008 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .suirisk 2.749 0.214 12.826 0.000 ## .hopeless 4.045 0.315 12.826 0.000 ## .selfesteem 18.685 1.457 12.826 0.000 ## depression 57.514 4.484 12.826 0.000 ## subabuse 41.461 3.233 12.826 0.000 28.0.3 Question 3 Mehta et al. (1998) state that their model can be improved post-hoc by adding and removing a path to this model. Follow their procedure, and first add a path for both males and females, and secondly, remove a nonsignificant path. Click for explanation ## lavaan 0.6-9 ended normally after 89 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 32 ## ## Number of observations per group: ## males 192 ## females 329 ## ## Model Test User Model: ## ## Test statistic 22.123 ## Degrees of freedom 8 ## P-value (Chi-square) 0.005 ## Test statistic for each group: ## males 1.091 ## females 21.031 ## ## Model Test Baseline Model: ## ## Test statistic 829.489 ## Degrees of freedom 20 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.983 ## Tucker-Lewis Index (TLI) 0.956 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -6870.875 ## Loglikelihood unrestricted model (H1) -6859.814 ## ## Akaike (AIC) 13805.750 ## Bayesian (BIC) 13941.934 ## Sample-size adjusted Bayesian (BIC) 13840.359 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.082 ## 90 Percent confidence interval - lower 0.042 ## 90 Percent confidence interval - upper 0.124 ## P-value RMSEA &lt;= 0.05 0.085 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.035 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## ## Group 1 [males]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## suirisk ~ ## depression 0.117 0.015 8.030 0.000 ## subabuse 0.126 0.042 2.998 0.003 ## hopeless ~ ## depression 0.161 0.024 6.640 0.000 ## selfesteem -0.166 0.033 -4.973 0.000 ## selfesteem ~ ## depression -0.514 0.037 -13.811 0.000 ## subabuse ~ ## hopeless 0.346 0.066 5.215 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## .subabuse ~~ ## depression 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .suirisk 1.616 0.177 9.127 0.000 ## .hopeless 7.420 1.221 6.075 0.000 ## .selfesteem 36.189 0.373 97.030 0.000 ## .subabuse 2.056 0.268 7.661 0.000 ## depression 6.391 0.558 11.460 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .suirisk 2.280 0.233 9.798 0.000 ## .hopeless 3.399 0.347 9.798 0.000 ## .selfesteem 15.860 1.619 9.798 0.000 ## .subabuse 6.312 0.644 9.798 0.000 ## depression 59.707 6.094 9.798 0.000 ## ## ## Group 2 [females]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## suirisk ~ ## depression 0.060 0.012 4.903 0.000 ## subabuse 0.061 0.014 4.194 0.000 ## hopeless ~ ## depression 0.148 0.017 8.482 0.000 ## selfesteem -0.221 0.026 -8.612 0.000 ## selfesteem ~ ## depression -0.372 0.031 -11.841 0.000 ## subabuse ~ ## hopeless 0.663 0.120 5.523 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## .subabuse ~~ ## depression 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .suirisk 2.049 0.117 17.461 0.000 ## .hopeless 8.896 0.875 10.172 0.000 ## .selfesteem 33.640 0.305 110.183 0.000 ## .subabuse -0.958 0.483 -1.984 0.047 ## depression 6.073 0.418 14.525 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .suirisk 2.759 0.215 12.826 0.000 ## .hopeless 4.045 0.315 12.826 0.000 ## .selfesteem 18.685 1.457 12.826 0.000 ## .subabuse 37.944 2.958 12.826 0.000 ## depression 57.514 4.484 12.826 0.000 28.0.4 Question 4 Evaluate the path coefficients of both males and females (tip: look at both the unstandardized and standardized coefficients). Can you explain how the two groups differ? Click for explanation ## lavaan 0.6-9 ended normally after 71 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 32 ## ## Number of observations per group: ## males 192 ## females 329 ## ## Model Test User Model: ## ## Test statistic 75.329 ## Degrees of freedom 8 ## P-value (Chi-square) 0.000 ## Test statistic for each group: ## males 26.329 ## females 49.000 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## ## Group 1 [males]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## suirisk ~ ## hopeless 0.025 0.056 0.454 0.650 0.025 0.039 ## depression 0.111 0.020 5.644 0.000 0.111 0.479 ## subabuse 0.121 0.041 2.977 0.003 0.121 0.181 ## hopeless ~ ## depression 0.161 0.024 6.640 0.000 0.161 0.456 ## selfesteem -0.166 0.033 -4.973 0.000 -0.166 -0.342 ## selfesteem ~ ## depression -0.514 0.037 -13.811 0.000 -0.514 -0.706 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## depression ~~ ## subabuse 0.000 0.000 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .suirisk 1.592 0.204 7.787 0.000 1.592 0.889 ## .hopeless 7.420 1.221 6.075 0.000 7.420 2.714 ## .selfesteem 36.189 0.373 97.030 0.000 36.189 6.436 ## depression 6.391 0.558 11.460 0.000 6.391 0.827 ## subabuse 3.089 0.194 15.943 0.000 3.089 1.151 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .suirisk 2.277 0.232 9.798 0.000 2.277 0.710 ## .hopeless 3.399 0.347 9.798 0.000 3.399 0.455 ## .selfesteem 15.860 1.619 9.798 0.000 15.860 0.502 ## depression 59.707 6.094 9.798 0.000 59.707 1.000 ## subabuse 7.206 0.735 9.798 0.000 7.206 1.000 ## ## ## Group 2 [females]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## suirisk ~ ## hopeless 0.045 0.041 1.104 0.270 0.045 0.073 ## depression 0.050 0.015 3.282 0.001 0.050 0.216 ## subabuse 0.059 0.014 4.138 0.000 0.059 0.214 ## hopeless ~ ## depression 0.148 0.017 8.482 0.000 0.148 0.397 ## selfesteem -0.221 0.026 -8.612 0.000 -0.221 -0.403 ## selfesteem ~ ## depression -0.372 0.031 -11.841 0.000 -0.372 -0.547 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## depression ~~ ## subabuse 0.000 0.000 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .suirisk 1.981 0.132 14.970 0.000 1.981 1.122 ## .hopeless 8.896 0.875 10.172 0.000 8.896 3.144 ## .selfesteem 33.640 0.305 110.183 0.000 33.640 6.516 ## depression 6.073 0.418 14.525 0.000 6.073 0.801 ## subabuse 0.939 0.355 2.646 0.008 0.939 0.146 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .suirisk 2.749 0.214 12.826 0.000 2.749 0.883 ## .hopeless 4.045 0.315 12.826 0.000 4.045 0.505 ## .selfesteem 18.685 1.457 12.826 0.000 18.685 0.701 ## depression 57.514 4.484 12.826 0.000 57.514 1.000 ## subabuse 41.461 3.233 12.826 0.000 41.461 1.000 28.0.5 Question 5 We can test the difference between males and females more formally in two ways: By constraining the size of the regression coefficients to be equal in both groups and doing a test for nested models/ By computing (:=) a parameter for the difference between the two groups, and looking at its p-value, or a bootstrapped confidence interval. Why are these approaches both preferrable over just comparing regression coefficients by sight? Click for explanation Even if we observe differences, we do not know whether they are significantly different. By constraining parameters to be equal, we can test two models. 1) the free model against 2) the constrained model. This is done using a Chi-square difference test. By computing a difference parameter, we can do a parameteric test or bootstrap confidence interval for the difference. 28.0.6 Question 6 Constrain the regression coefficients for males and females. Compare the unconstrained model to the model with constrained regression coefficients. What is your conclusion? Click for explanation First, estimate the constrained model. We can use the model from the first exercise: ## lavaan 0.6-9 ended normally after 49 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 32 ## Number of equality constraints 6 ## ## Number of observations per group: ## males 192 ## females 329 ## ## Model Test User Model: ## ## Test statistic 98.420 ## Degrees of freedom 14 ## P-value (Chi-square) 0.000 ## Test statistic for each group: ## males 40.746 ## females 57.674 ## ## Model Test Baseline Model: ## ## Test statistic 829.489 ## Degrees of freedom 20 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.896 ## Tucker-Lewis Index (TLI) 0.851 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -6909.024 ## Loglikelihood unrestricted model (H1) -6859.814 ## ## Akaike (AIC) 13870.048 ## Bayesian (BIC) 13980.697 ## Sample-size adjusted Bayesian (BIC) 13898.167 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.152 ## 90 Percent confidence interval - lower 0.125 ## 90 Percent confidence interval - upper 0.181 ## P-value RMSEA &lt;= 0.05 0.000 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.136 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## ## Group 1 [males]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## suirisk ~ ## hopelss (.p1.) 0.049 0.033 1.462 0.144 ## deprssn (.p2.) 0.075 0.012 6.150 0.000 ## subabus (.p3.) 0.058 0.014 4.300 0.000 ## hopeless ~ ## deprssn (.p4.) 0.151 0.014 10.681 0.000 ## selfstm (.p5.) -0.199 0.020 -9.856 0.000 ## selfesteem ~ ## deprssn (.p6.) -0.431 0.024 -17.787 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## depression ~~ ## subabuse 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .suirisk 1.945 0.142 13.735 0.000 ## .hopeless 8.576 0.737 11.640 0.000 ## .selfesteem 35.658 0.330 108.161 0.000 ## depression 6.391 0.558 11.460 0.000 ## subabuse 3.089 0.194 15.943 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .suirisk 2.379 0.243 9.798 0.000 ## .hopeless 3.420 0.349 9.798 0.000 ## .selfesteem 16.273 1.661 9.798 0.000 ## depression 59.707 6.094 9.798 0.000 ## subabuse 7.206 0.735 9.798 0.000 ## ## ## Group 2 [females]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## suirisk ~ ## hopelss (.p1.) 0.049 0.033 1.462 0.144 ## deprssn (.p2.) 0.075 0.012 6.150 0.000 ## subabus (.p3.) 0.058 0.014 4.300 0.000 ## hopeless ~ ## deprssn (.p4.) 0.151 0.014 10.681 0.000 ## selfstm (.p5.) -0.199 0.020 -9.856 0.000 ## selfesteem ~ ## deprssn (.p6.) -0.431 0.024 -17.787 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## depression ~~ ## subabuse 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .suirisk 1.821 0.119 15.352 0.000 ## .hopeless 8.199 0.700 11.719 0.000 ## .selfesteem 33.995 0.281 120.946 0.000 ## depression 6.073 0.418 14.525 0.000 ## subabuse 0.939 0.355 2.646 0.008 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .suirisk 2.786 0.217 12.826 0.000 ## .hopeless 4.056 0.316 12.826 0.000 ## .selfesteem 18.882 1.472 12.826 0.000 ## depression 57.515 4.484 12.826 0.000 ## subabuse 41.461 3.233 12.826 0.000 Then, compare the two models. I like to use semTools::compareFit(): ## The following lavaan models were compared: ## Free ## Constrained ## To view results, assign the compareFit() output to an object and use the summary() method; see the class?FitDiff help page. The model gets significantly worse. This means the regression coefficients for males and females are not equal. 28.0.7 Specific differences Just knowing that regression coefficients differ, is interesting in itself. Reflect here on the conclusion of Mehta et al. 1998. Do they test for significant moderation? After doing this omnibus (overall) test, it is interesting to know which parameters, speciffically, differ. We can do this by computing new parameters for the difference between men and women. These new parameters will be tested using Z-tests and corresponding p-values. For a non-parametric test, you will have to bootstrap your analysis (see the explanation about bootstrapping indirect effects). We use a similar approach to the one we used to compute indirect effects: Label every path in your model Define new parameters as the difference between corresponding parameters for men and women 28.0.8 Question 7 Fit this model, and inspect the results for the defined parameters. What are your conclusions? Click for explanation ## lavaan 0.6-9 ended normally after 71 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 32 ## ## Number of observations per group: ## males 192 ## females 329 ## ## Model Test User Model: ## ## Test statistic 75.329 ## Degrees of freedom 8 ## P-value (Chi-square) 0.000 ## Test statistic for each group: ## males 26.329 ## females 49.000 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## ## Group 1 [males]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## suirisk ~ ## hopeless (m1) 0.025 0.056 0.454 0.650 ## depressin (m2) 0.111 0.020 5.644 0.000 ## subabuse (m3) 0.121 0.041 2.977 0.003 ## hopeless ~ ## depressin (m4) 0.161 0.024 6.640 0.000 ## selfestem (m5) -0.166 0.033 -4.973 0.000 ## selfesteem ~ ## depressin (m6) -0.514 0.037 -13.811 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## depression ~~ ## subabuse 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .suirisk 1.592 0.204 7.787 0.000 ## .hopeless 7.420 1.221 6.075 0.000 ## .selfesteem 36.189 0.373 97.030 0.000 ## depression 6.391 0.558 11.460 0.000 ## subabuse 3.089 0.194 15.943 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .suirisk 2.277 0.232 9.798 0.000 ## .hopeless 3.399 0.347 9.798 0.000 ## .selfesteem 15.860 1.619 9.798 0.000 ## depression 59.707 6.094 9.798 0.000 ## subabuse 7.206 0.735 9.798 0.000 ## ## ## Group 2 [females]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## suirisk ~ ## hopeless (f1) 0.045 0.041 1.104 0.270 ## depressin (f2) 0.050 0.015 3.282 0.001 ## subabuse (f3) 0.059 0.014 4.138 0.000 ## hopeless ~ ## depressin (f4) 0.148 0.017 8.482 0.000 ## selfestem (f5) -0.221 0.026 -8.612 0.000 ## selfesteem ~ ## depressin (f6) -0.372 0.031 -11.841 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## depression ~~ ## subabuse 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .suirisk 1.981 0.132 14.970 0.000 ## .hopeless 8.896 0.875 10.172 0.000 ## .selfesteem 33.640 0.305 110.183 0.000 ## depression 6.073 0.418 14.525 0.000 ## subabuse 0.939 0.355 2.646 0.008 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .suirisk 2.749 0.214 12.826 0.000 ## .hopeless 4.045 0.315 12.826 0.000 ## .selfesteem 18.685 1.457 12.826 0.000 ## depression 57.514 4.484 12.826 0.000 ## subabuse 41.461 3.233 12.826 0.000 ## ## Defined Parameters: ## Estimate Std.Err z-value P(&gt;|z|) ## D1 -0.020 0.069 -0.291 0.771 ## D2 0.061 0.025 2.436 0.015 ## D3 0.062 0.043 1.443 0.149 ## D4 0.013 0.030 0.445 0.656 ## D5 0.055 0.042 1.301 0.193 ## D6 -0.142 0.049 -2.908 0.004 Only the effect of depression on suicide risk, and the effect of depression on selfesteem, are significantly different between the sexes. 28.0.9 Question 8 Is there anything we should consider when inspecting these p-values? Click for explanation You should consider the potential risk of multiple testing, and whether the assumption of normality holds. 28.0.10 Results table When you want to include your results in a paper, its a lot of work to copy-paste everything. There are many ways to get R results directly into a paper, including writing the entire paper in R and automatically updating the results. I will show you a very basic way to make a table and export it to a spreadsheet. We will use the functions parameterEstimates(fit, standardized = TRUE) to get the unstandardized and standardized estimates, and then put them into a nice table: Then, we take only the labeled parameters (which are the regression coefficients and difference parameters): 28.0.11 Question 9 Interpret the effect sizes (standardized estimates) for males and females. What are your conclusions? 28.0.12 Question 10 Evaluate R-square for suicide risk for males and females. What do you find? Click for explanation ## lavaan 0.6-9 ended normally after 71 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 32 ## ## Number of observations per group: ## males 192 ## females 329 ## ## Model Test User Model: ## ## Test statistic 75.329 ## Degrees of freedom 8 ## P-value (Chi-square) 0.000 ## Test statistic for each group: ## males 26.329 ## females 49.000 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## ## Group 1 [males]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## suirisk ~ ## hopeless 0.025 0.056 0.454 0.650 ## depression 0.111 0.020 5.644 0.000 ## subabuse 0.121 0.041 2.977 0.003 ## hopeless ~ ## depression 0.161 0.024 6.640 0.000 ## selfesteem -0.166 0.033 -4.973 0.000 ## selfesteem ~ ## depression -0.514 0.037 -13.811 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## depression ~~ ## subabuse 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .suirisk 1.592 0.204 7.787 0.000 ## .hopeless 7.420 1.221 6.075 0.000 ## .selfesteem 36.189 0.373 97.030 0.000 ## depression 6.391 0.558 11.460 0.000 ## subabuse 3.089 0.194 15.943 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .suirisk 2.277 0.232 9.798 0.000 ## .hopeless 3.399 0.347 9.798 0.000 ## .selfesteem 15.860 1.619 9.798 0.000 ## depression 59.707 6.094 9.798 0.000 ## subabuse 7.206 0.735 9.798 0.000 ## ## R-Square: ## Estimate ## suirisk 0.290 ## hopeless 0.545 ## selfesteem 0.498 ## ## ## Group 2 [females]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## suirisk ~ ## hopeless 0.045 0.041 1.104 0.270 ## depression 0.050 0.015 3.282 0.001 ## subabuse 0.059 0.014 4.138 0.000 ## hopeless ~ ## depression 0.148 0.017 8.482 0.000 ## selfesteem -0.221 0.026 -8.612 0.000 ## selfesteem ~ ## depression -0.372 0.031 -11.841 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## depression ~~ ## subabuse 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .suirisk 1.981 0.132 14.970 0.000 ## .hopeless 8.896 0.875 10.172 0.000 ## .selfesteem 33.640 0.305 110.183 0.000 ## depression 6.073 0.418 14.525 0.000 ## subabuse 0.939 0.355 2.646 0.008 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .suirisk 2.749 0.214 12.826 0.000 ## .hopeless 4.045 0.315 12.826 0.000 ## .selfesteem 18.685 1.457 12.826 0.000 ## depression 57.514 4.484 12.826 0.000 ## subabuse 41.461 3.233 12.826 0.000 ## ## R-Square: ## Estimate ## suirisk 0.117 ## hopeless 0.495 ## selfesteem 0.299 The R-square for suicide risk is .29 for males, and .12 for females. The model predicts suicide risk better for females. 28.0.13 Question 12 Calculate the total, direct and indirect effects (see practical week 5). The model we have made is a typical example of moderated mediation (i.e. the mediation effects are moderated by gender). In your own words, what are the differences in the mediation between males and females? Note: Because the paths are different for males and females, you should also calculate the total, direct and indirect effects (see practical week 5) for males and females separately. Click for explanation The total effects of depression and substance use on suicide risk are higher for females than males, but the total effect for selfesteem and hopelessness are very similar. 28.0.14 Question 13 Compare your conclusion in the previous question with that of Mehta and colleagues (1998). Are your conclusions any different? Why? Click for explanation Should be different: They do not test moderation explicitly, and report differences in all paths between males and females. In fact, the paths leading to suicide risk are different for males and females, but the mediation of depression through hopelessness is similar. "],["week-7-overview.html", "Chapter 29 Week 7 - Overview", " Chapter 29 Week 7 - Overview Putting it all together Homework for the practical Putting it all together: Read and answer the reading questions for: - Weston, R. and Gore, Paul, A. (2006) A brief guide to structural equation Modeling, The Counseling Psychologist 34, p.719-752 Perform take home exercise week 7 before coming to the practical. Practical Putting it all together: Students have time to ask questions about take home exercise Putting it all together and work on class exercise Putting it all together. "],["week-7-putting-it-all-together.html", "Chapter 30 Week 7 - Putting it all together", " Chapter 30 Week 7 - Putting it all together Path analysis on Theory of Reasoned Action data (file: toradata.sav) A popular theory in psychology to explain social behavior is the Theory of Reasoned Action (TORA) of Ajzen and Fishbein (sometimes called the Ajzen-Fishbein model). This states that behavior is predicted by behavioral intention, which is in turn predicted by the attitude toward the behavior and the subjective norm about the behavior. Ajzen and Fisbein originally proposed a complex way to measure attitude and norm, but in practice researchers usually measure the attitude by including a number of attitude questions, and the norm by including a number of questions about the perceived social norms (e.g., how many of your friends would do). The intention is usually measured by a single question on a 7 or 9-point scale and the behavior is either a dichotomous outcome (yes/no) or a frequency (how often do you). Later, a third determinant was added, perceived behavioral control. If people feel they have little control over their behavior, this will also influence their behavior. 30.0.1 Loading the data The TORA data are an artificial data set following results found by Reinecke (1998). The behavior under investigation is condom use by 16-24 year adolescents. The dependent variable condom use is measured on a 5-point frequency scale (How often do you), and the behavioral intention on a similar 5-point scale (In general do you intend to). There are three attitude items about condom use (e.g., using a condom is awkward), three normative items (e.g., I think most of my friends would use), and three control items (e.g., I know well how to use a condom), all measured on a 5-point Likert-type scale. Click for explanation 30.0.2 Question 1 We have 3 indicators for attitude, norm and control, plus the variables intention and behavior. Carry out a factor analysis for the latent variables attitude, norm and control, and interpret the factor loadings of the indicators for each factor. Click for explanation ## lavaan 0.6-9 ended normally after 29 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 21 ## ## Number of observations 250 ## ## Model Test User Model: ## ## Test statistic 35.611 ## Degrees of freedom 24 ## P-value (Chi-square) 0.060 ## ## Model Test Baseline Model: ## ## Test statistic 910.621 ## Degrees of freedom 36 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.987 ## Tucker-Lewis Index (TLI) 0.980 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -2998.290 ## Loglikelihood unrestricted model (H1) -2980.484 ## ## Akaike (AIC) 6038.580 ## Bayesian (BIC) 6112.530 ## Sample-size adjusted Bayesian (BIC) 6045.959 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.044 ## 90 Percent confidence interval - lower 0.000 ## 90 Percent confidence interval - upper 0.073 ## P-value RMSEA &lt;= 0.05 0.599 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.037 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## attit =~ ## attit_1 1.000 ## attit_2 1.036 0.068 15.308 0.000 ## attit_3 -1.002 0.067 -14.856 0.000 ## norm =~ ## norm_1 1.000 ## norm_2 1.031 0.098 10.574 0.000 ## norm_3 0.932 0.093 10.013 0.000 ## control =~ ## control_1 1.000 ## control_2 0.862 0.129 6.699 0.000 ## control_3 0.968 0.133 7.290 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## attit ~~ ## norm 0.340 0.069 4.957 0.000 ## control 0.475 0.073 6.468 0.000 ## norm ~~ ## control 0.338 0.064 5.254 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .attit_1 0.418 0.052 8.047 0.000 ## .attit_2 0.310 0.047 6.633 0.000 ## .attit_3 0.369 0.049 7.577 0.000 ## .norm_1 0.504 0.071 7.130 0.000 ## .norm_2 0.469 0.071 6.591 0.000 ## .norm_3 0.635 0.075 8.465 0.000 ## .control_1 0.614 0.078 7.905 0.000 ## .control_2 0.865 0.091 9.520 0.000 ## .control_3 0.762 0.087 8.758 0.000 ## attit 0.885 0.116 7.620 0.000 ## norm 0.743 0.116 6.423 0.000 ## control 0.497 0.099 5.002 0.000 30.0.3 Question 2 Set up a TORA model with attitude and norms as latent variables both predicting behavorial intention, and intention predicting behavior. Analyze it. Interpret the model fit. If you find the model to fit, look at the results. How much variance does the model explain? Click for explanation ## lavaan 0.6-9 ended normally after 24 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 18 ## ## Number of observations 250 ## ## Model Test User Model: ## ## Test statistic 27.890 ## Degrees of freedom 18 ## P-value (Chi-square) 0.064 ## ## Model Test Baseline Model: ## ## Test statistic 1089.407 ## Degrees of freedom 28 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.991 ## Tucker-Lewis Index (TLI) 0.986 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -2533.616 ## Loglikelihood unrestricted model (H1) -2519.671 ## ## Akaike (AIC) 5103.232 ## Bayesian (BIC) 5166.618 ## Sample-size adjusted Bayesian (BIC) 5109.557 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.047 ## 90 Percent confidence interval - lower 0.000 ## 90 Percent confidence interval - upper 0.079 ## P-value RMSEA &lt;= 0.05 0.523 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.036 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## attit =~ ## attit_1 1.000 ## attit_2 1.039 0.068 15.365 0.000 ## attit_3 -1.002 0.067 -14.850 0.000 ## norm =~ ## norm_1 1.000 ## norm_2 0.983 0.087 11.333 0.000 ## norm_3 0.935 0.087 10.778 0.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## intent ~ ## attit 0.439 0.063 6.990 0.000 ## norm 0.693 0.077 8.977 0.000 ## behavior ~ ## intent 0.746 0.045 16.443 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## attit ~~ ## norm 0.347 0.069 5.027 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .attit_1 0.420 0.052 8.103 0.000 ## .attit_2 0.306 0.046 6.604 0.000 ## .attit_3 0.372 0.049 7.651 0.000 ## .norm_1 0.483 0.064 7.581 0.000 ## .norm_2 0.521 0.065 7.954 0.000 ## .norm_3 0.610 0.070 8.713 0.000 ## .intent 0.423 0.048 8.769 0.000 ## .behavior 0.603 0.054 11.180 0.000 ## attit 0.884 0.116 7.614 0.000 ## norm 0.765 0.113 6.767 0.000 ## ## R-Square: ## Estimate ## attit_1 0.678 ## attit_2 0.757 ## attit_3 0.705 ## norm_1 0.613 ## norm_2 0.587 ## norm_3 0.523 ## intent 0.639 ## behavior 0.520 30.0.4 Question 3 Add control as a latent variable. Assume control has an effect on intention. Analyze this model and interpret the results. How much variance does the model explain? Click for explanation The option rsquare = TRUE tells us how much variance is explained in each dependent variable: ## lavaan 0.6-9 ended normally after 33 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 27 ## ## Number of observations 250 ## ## Model Test User Model: ## ## Test statistic 62.797 ## Degrees of freedom 39 ## P-value (Chi-square) 0.009 ## ## Model Test Baseline Model: ## ## Test statistic 1333.695 ## Degrees of freedom 55 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.981 ## Tucker-Lewis Index (TLI) 0.974 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -3558.180 ## Loglikelihood unrestricted model (H1) -3526.782 ## ## Akaike (AIC) 7170.360 ## Bayesian (BIC) 7265.439 ## Sample-size adjusted Bayesian (BIC) 7179.847 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.049 ## 90 Percent confidence interval - lower 0.025 ## 90 Percent confidence interval - upper 0.071 ## P-value RMSEA &lt;= 0.05 0.492 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.043 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## attit =~ ## attit_1 1.000 ## attit_2 1.033 0.068 15.295 0.000 ## attit_3 -1.018 0.068 -15.087 0.000 ## norm =~ ## norm_1 1.000 ## norm_2 0.985 0.087 11.305 0.000 ## norm_3 0.947 0.087 10.845 0.000 ## control =~ ## control_1 1.000 ## control_2 0.864 0.126 6.855 0.000 ## control_3 0.958 0.129 7.417 0.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## intent ~ ## attit 0.352 0.096 3.669 0.000 ## norm 0.644 0.088 7.347 0.000 ## control 0.207 0.163 1.268 0.205 ## behavior ~ ## intent 0.746 0.045 16.443 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## attit ~~ ## norm 0.345 0.069 5.023 0.000 ## control 0.476 0.073 6.513 0.000 ## norm ~~ ## control 0.346 0.065 5.361 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .attit_1 0.427 0.051 8.295 0.000 ## .attit_2 0.325 0.046 7.101 0.000 ## .attit_3 0.349 0.047 7.477 0.000 ## .norm_1 0.490 0.064 7.702 0.000 ## .norm_2 0.524 0.065 8.025 0.000 ## .norm_3 0.600 0.069 8.652 0.000 ## .control_1 0.610 0.076 8.015 0.000 ## .control_2 0.861 0.090 9.580 0.000 ## .control_3 0.769 0.086 8.938 0.000 ## .intent 0.412 0.046 8.890 0.000 ## .behavior 0.603 0.054 11.180 0.000 ## attit 0.877 0.115 7.596 0.000 ## norm 0.757 0.112 6.733 0.000 ## control 0.500 0.098 5.076 0.000 ## ## R-Square: ## Estimate ## attit_1 0.673 ## attit_2 0.742 ## attit_3 0.723 ## norm_1 0.607 ## norm_2 0.584 ## norm_3 0.531 ## control_1 0.450 ## control_2 0.303 ## control_3 0.374 ## intent 0.649 ## behavior 0.520 30.0.5 Question 4 The TORA model forbids direct paths between attitude and norm and actual behavior; the effect should be mediated totally by the behavioral intention. The effect of control can be either direct or indirect; the TORA does not specify which. Test a model with both a direct and indirect effect of control on TORA and decide whether you want to keep or remove them. Decide which model you accept as the best model for these data, and explain how you decided to keep this model. Click for explanation To compare the models, we can use a \\(\\chi^2\\)-difference test, using the anova() function or `semTools::compareFits: ## The following lavaan models were compared: ## Direct ## Indirect ## To view results, assign the compareFit() output to an object and use the summary() method; see the class?FitDiff help page. 30.0.6 Question 5 Use tidySEM::graph_sem() to plot both models, and check whether the picture corresponds with theory and with the way you intended to specify the model. Click for explanation 30.0.7 Question 6 Before you learned about latent variables, you might have analyzed these data by computing sum or mean scores for attitude, norms, and control, and using these as observed variables in a path model. It is possible to obtain mean scale scores using tidySEM, as follows: The scales object contains a table with scale descriptive statistics: Use the mean scores of the variables to set up a TORA model, and compare the results with the previous analysis. Which model would you prefer, and why? Hint: Use cbind() to add the scale scores to df Click for explanation ## [1] &quot;respnr&quot; &quot;attit_1&quot; &quot;attit_2&quot; &quot;attit_3&quot; &quot;norm_1&quot; &quot;norm_2&quot; ## [7] &quot;norm_3&quot; &quot;intent&quot; &quot;behavior&quot; &quot;control_1&quot; &quot;control_2&quot; &quot;control_3&quot; ## [13] &quot;sex&quot; The fit of this new model is worse than the model that included latent variables. However, note that these models are not nested, so we cannot directly compare fit indices. They are estimated on different variables. We will get a warning to emphasize this point. We can only interpret the Model Fit Indices table, and the Differences in Fit Indices, but not the Nested Model Comparison. ## The following lavaan models were compared: ## Observed ## Latent ## To view results, assign the compareFit() output to an object and use the summary() method; see the class?FitDiff help page. We can also inspect the regression coefficients in both models: 30.0.8 Moderated mediation We now want to investigate whether the Theory of Reasoned Action for condom use is different for boys and girls. This is a typical case of a moderated mediation model. 30.0.9 Question 7 Estimate the sex moderated model. What happened to the fit of the model when you compare it to your earlier model that didnt include sex? Click for explanation ## lavaan 0.6-9 ended normally after 71 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 76 ## ## Number of observations per group: ## woman 161 ## man 89 ## ## Model Test User Model: ## ## Test statistic 134.940 ## Degrees of freedom 78 ## P-value (Chi-square) 0.000 ## Test statistic for each group: ## woman 91.538 ## man 43.402 ## ## Model Test Baseline Model: ## ## Test statistic 1378.913 ## Degrees of freedom 110 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.955 ## Tucker-Lewis Index (TLI) 0.937 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -3467.397 ## Loglikelihood unrestricted model (H1) -3399.927 ## ## Akaike (AIC) 7086.794 ## Bayesian (BIC) 7354.425 ## Sample-size adjusted Bayesian (BIC) 7113.498 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.076 ## 90 Percent confidence interval - lower 0.054 ## 90 Percent confidence interval - upper 0.098 ## P-value RMSEA &lt;= 0.05 0.028 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.054 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## ## Group 1 [woman]: ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## attit =~ ## attit_1 1.000 ## attit_2 0.992 0.076 13.026 0.000 ## attit_3 -1.003 0.076 -13.213 0.000 ## norm =~ ## norm_1 1.000 ## norm_2 0.944 0.098 9.674 0.000 ## norm_3 0.915 0.099 9.222 0.000 ## control =~ ## control_1 1.000 ## control_2 0.819 0.143 5.727 0.000 ## control_3 0.968 0.148 6.536 0.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## intent ~ ## attit 0.389 0.105 3.695 0.000 ## norm 0.536 0.119 4.495 0.000 ## control 0.116 0.185 0.630 0.529 ## behavior ~ ## intent 0.744 0.054 13.665 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## attit ~~ ## norm 0.439 0.085 5.164 0.000 ## control 0.470 0.089 5.292 0.000 ## norm ~~ ## control 0.387 0.078 4.958 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .attit_1 2.839 0.090 31.702 0.000 ## .attit_2 2.907 0.084 34.728 0.000 ## .attit_3 3.174 0.084 37.969 0.000 ## .norm_1 2.832 0.080 35.342 0.000 ## .norm_2 2.832 0.079 35.775 0.000 ## .norm_3 2.795 0.081 34.694 0.000 ## .control_1 2.851 0.082 34.755 0.000 ## .control_2 2.857 0.081 35.104 0.000 ## .control_3 2.888 0.081 35.877 0.000 ## .intent 2.677 0.078 34.159 0.000 ## .behavior 0.536 0.155 3.448 0.001 ## attit 0.000 ## norm 0.000 ## control 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .attit_1 0.415 0.059 6.986 0.000 ## .attit_2 0.267 0.046 5.862 0.000 ## .attit_3 0.245 0.044 5.523 0.000 ## .norm_1 0.360 0.061 5.874 0.000 ## .norm_2 0.408 0.062 6.539 0.000 ## .norm_3 0.481 0.068 7.049 0.000 ## .control_1 0.587 0.089 6.608 0.000 ## .control_2 0.733 0.095 7.746 0.000 ## .control_3 0.578 0.086 6.729 0.000 ## .intent 0.382 0.050 7.716 0.000 ## .behavior 0.472 0.053 8.972 0.000 ## attit 0.875 0.141 6.199 0.000 ## norm 0.674 0.118 5.737 0.000 ## control 0.497 0.118 4.212 0.000 ## ## ## Group 2 [man]: ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## attit =~ ## attit_1 1.000 ## attit_2 1.200 0.147 8.137 0.000 ## attit_3 -1.043 0.141 -7.375 0.000 ## norm =~ ## norm_1 1.000 ## norm_2 0.931 0.160 5.829 0.000 ## norm_3 0.879 0.158 5.571 0.000 ## control =~ ## control_1 1.000 ## control_2 0.914 0.267 3.430 0.001 ## control_3 0.960 0.271 3.546 0.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## intent ~ ## attit 0.380 0.183 2.072 0.038 ## norm 0.666 0.135 4.924 0.000 ## control 0.299 0.299 0.999 0.318 ## behavior ~ ## intent 0.453 0.065 6.990 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## attit ~~ ## norm 0.080 0.108 0.741 0.459 ## control 0.389 0.112 3.474 0.001 ## norm ~~ ## control 0.219 0.108 2.037 0.042 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .attit_1 3.270 0.117 28.063 0.000 ## .attit_2 3.180 0.128 24.905 0.000 ## .attit_3 2.787 0.126 22.187 0.000 ## .norm_1 3.236 0.131 24.692 0.000 ## .norm_2 3.337 0.132 25.293 0.000 ## .norm_3 3.303 0.131 25.136 0.000 ## .control_1 3.157 0.111 28.415 0.000 ## .control_2 3.135 0.129 24.249 0.000 ## .control_3 3.213 0.130 24.805 0.000 ## .intent 3.427 0.113 30.233 0.000 ## .behavior 2.234 0.233 9.600 0.000 ## attit 0.000 ## norm 0.000 ## control 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .attit_1 0.449 0.093 4.844 0.000 ## .attit_2 0.357 0.103 3.480 0.001 ## .attit_3 0.578 0.112 5.160 0.000 ## .norm_1 0.640 0.145 4.402 0.000 ## .norm_2 0.779 0.154 5.062 0.000 ## .norm_3 0.851 0.158 5.373 0.000 ## .control_1 0.658 0.142 4.618 0.000 ## .control_2 1.119 0.195 5.724 0.000 ## .control_3 1.087 0.194 5.587 0.000 ## .intent 0.383 0.084 4.546 0.000 ## .behavior 0.428 0.064 6.671 0.000 ## attit 0.759 0.180 4.223 0.000 ## norm 0.889 0.235 3.781 0.000 ## control 0.441 0.167 2.639 0.008 30.0.10 Measurement invariance Before conducting this analysis, you should check for measurement invariance. There are different levels of measurement invariance: Configural: The same model in both groups Metric: Same factor loadings Scalar: Same factor loadings, and intercepts for the indicators. We can specify these models with groups.equal constraints and then use compareFit(): ## The following lavaan models were compared: ## Configural ## Metric ## Scalar ## To view results, assign the compareFit() output to an object and use the summary() method; see the class?FitDiff help page. You can see that imposing increasingly strict constraints does not significantly deteriorate the fit. So, scalar measurement invariance is supported. 30.0.11 Question 8 Going back to the multi-group model, impose scalar invariance, and then determine whether it makes sense to constrain all the regression coefficients to be equal. Does it? Click for explanation ## The following lavaan models were compared: ## Multigroup ## Constrain_regressions ## To view results, assign the compareFit() output to an object and use the summary() method; see the class?FitDiff help page. 30.0.12 Question 9 Depending on your answer to the previous question, investigate which regression coefficients of the TORA-model is the same or different for boys and girls. Decide on a final model and report how you choose your model. With such a model, there are many ways to interpret the results. For example, you can look at the direct effects, indirect effects, explained variance, etc. Look at your final model and report on what you think are the most interesting results. "]]
